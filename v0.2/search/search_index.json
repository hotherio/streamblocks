{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Streamblocks","text":""},{"location":"#streamblocks","title":"Streamblocks","text":"<p>Real-time extraction of structured blocks from AI text streams</p> <p>Streamblocks is a Python library for detecting and extracting structured content blocks from streaming text. Extract semantic blocks as they stream\u2014not after completion\u2014enabling reactive AI agents and real-time processing.</p> <ul> <li> <p> Stream Processing</p> <p>Extract blocks in real-time as text streams, enabling immediate reactions and feedback loops with LLMs.</p> <p> Getting Started</p> </li> <li> <p> Multiple Syntaxes</p> <p>Choose from delimiter-based, Markdown frontmatter, or create custom syntaxes for your use case.</p> <p> Syntaxes Guide</p> </li> <li> <p> Provider Adapters</p> <p>Works with Gemini, OpenAI, Anthropic out of the box. Easy to add custom adapters.</p> <p> Adapters Guide</p> </li> <li> <p> Type Safe</p> <p>Full Pydantic model support with validation. Define your block metadata and content with type safety.</p> <p> Block Types</p> </li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import asyncio\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\n\nasync def main():\n    # Create registry and processor\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(registry, syntax=Syntax.DELIMITER_PREAMBLE)\n\n    # Simulate a text stream\n    async def text_stream():\n        chunks = [\n            \"Here's the file operations:\\n\",\n            \"!!file01:files_operations\\n\",\n            \"src/main.py:C\\n\",\n            \"src/utils.py:E\\n\",\n            \"!!end\\n\",\n            \"Done!\"\n        ]\n        for chunk in chunks:\n            yield chunk\n\n    # Process and react to blocks in real-time\n    async for event in processor.process_stream(text_stream()):\n        if event.type.name == \"BLOCK_EXTRACTED\":\n            print(f\"Extracted: {event.block.metadata.id}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"#why-streamblocks","title":"Why Streamblocks?","text":"Feature Benefit LLM Agnostic Works with any text stream\u2014no vendor lock-in Real-time Processing React to blocks as they stream, don't wait for completion Type Safety Pydantic models for metadata and content validation Extensible Custom syntaxes, adapters, and block types Framework Compatible Integrates with LangGraph, Pydantic AI, and others"},{"location":"#installation","title":"Installation","text":"uvpip <pre><code>uv add streamblocks\n</code></pre> <pre><code>pip install streamblocks\n</code></pre> <p>With provider support:</p> uvpip <pre><code>uv add streamblocks[gemini]      # Google Gemini\nuv add streamblocks[openai]      # OpenAI\nuv add streamblocks[anthropic]   # Anthropic Claude\nuv add streamblocks[all-providers]  # All providers\n</code></pre> <pre><code>pip install streamblocks[gemini]\npip install streamblocks[openai]\npip install streamblocks[anthropic]\npip install streamblocks[all-providers]\n</code></pre> <p>Get Started  View Examples</p>"},{"location":"adapters/","title":"Adapters","text":""},{"location":"adapters/#adapters","title":"Adapters","text":"<p>Adapters normalize provider-specific streams into text chunks that Streamblocks can process. This guide covers the built-in adapters and how to work with different LLM providers.</p>"},{"location":"adapters/#overview","title":"Overview","text":"<pre><code>flowchart LR\n    subgraph Providers[\"LLM Providers\"]\n        Gemini[Gemini API]\n        OpenAI[OpenAI API]\n        Anthropic[Anthropic API]\n    end\n\n    subgraph Adapters[\"Input Adapters\"]\n        GeminiAdapt[Gemini Adapter]\n        OpenAIAdapt[OpenAI Adapter]\n        AnthropicAdapt[Anthropic Adapter]\n    end\n\n    subgraph Processing[\"Streamblocks\"]\n        Processor[StreamBlockProcessor]\n    end\n\n    Gemini --&gt; GeminiAdapt\n    OpenAI --&gt; OpenAIAdapt\n    Anthropic --&gt; AnthropicAdapt\n\n    GeminiAdapt --&gt; Processor\n    OpenAIAdapt --&gt; Processor\n    AnthropicAdapt --&gt; Processor</code></pre>"},{"location":"adapters/#installation","title":"Installation","text":"<p>Install provider-specific extras:</p> <pre><code>pip install streamblocks[gemini]      # Google Gemini\npip install streamblocks[openai]      # OpenAI\npip install streamblocks[anthropic]   # Anthropic\npip install streamblocks[all]         # All providers\n</code></pre>"},{"location":"adapters/#auto-detection","title":"Auto-Detection","text":"<p>The simplest approach is auto-detection:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=\"auto\",  # Detect from first event\n)\n\nasync for event in processor.process_stream(any_provider_stream):\n    handle_event(event)\n</code></pre> <p>Auto-detection tries adapters in order until one matches:</p> <ol> <li>Gemini adapter (if installed)</li> <li>OpenAI adapter (if installed)</li> <li>Anthropic adapter (if installed)</li> <li>Identity adapter (plain text fallback)</li> </ol>"},{"location":"adapters/#google-gemini","title":"Google Gemini","text":""},{"location":"adapters/#setup","title":"Setup","text":"<pre><code>import google.generativeai as genai\n\ngenai.configure(api_key=\"your-api-key\")  # pragma: allowlist secret  # pragma: allowlist secret\nmodel = genai.GenerativeModel(\"gemini-pro\")\n</code></pre>"},{"location":"adapters/#with-auto-detection","title":"With Auto-Detection","text":"<pre><code>response = model.generate_content(prompt, stream=True)\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=\"auto\",\n)\n\nasync for event in processor.process_stream(response):\n    handle_event(event)\n</code></pre>"},{"location":"adapters/#with-explicit-adapter","title":"With Explicit Adapter","text":"<pre><code>from streamblocks.ext.gemini import GeminiInputAdapter\n\nadapter = GeminiInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n</code></pre>"},{"location":"adapters/#full-example","title":"Full Example","text":"<pre><code>import asyncio\nimport google.generativeai as genai\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\n\nasync def main():\n    genai.configure(api_key=\"your-api-key\")  # pragma: allowlist secret  # pragma: allowlist secret\n    model = genai.GenerativeModel(\"gemini-pro\")\n\n    prompt = \"\"\"\n    Create a task list:\n\n    !!task01:task\n    Review pull requests\n    !!end\n\n    !!task02:task\n    Update documentation\n    !!end\n    \"\"\"\n\n    response = model.generate_content(prompt, stream=True)\n\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=\"auto\",\n    )\n\n    async for event in processor.process_stream(response):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            print(f\"Task: {event.block.content.raw_content}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"adapters/#openai","title":"OpenAI","text":""},{"location":"adapters/#setup_1","title":"Setup","text":"<pre><code>from openai import OpenAI\n\nclient = OpenAI(api_key=\"your-api-key\")  # pragma: allowlist secret\n</code></pre>"},{"location":"adapters/#with-explicit-adapter_1","title":"With Explicit Adapter","text":"<pre><code>from streamblocks.ext.openai import OpenAIInputAdapter\n\nadapter = OpenAIInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    stream=True,\n)\n\nasync for event in processor.process_stream(stream):\n    handle_event(event)\n</code></pre>"},{"location":"adapters/#full-example_1","title":"Full Example","text":"<pre><code>import asyncio\nfrom openai import OpenAI\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\nfrom streamblocks.ext.openai import OpenAIInputAdapter\n\nasync def main():\n    client = OpenAI(api_key=\"your-api-key\")  # pragma: allowlist secret\n\n    prompt = \"\"\"\n    Create a task list using this format:\n    !!id:task\n    content\n    !!end\n    \"\"\"\n\n    stream = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        stream=True,\n    )\n\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=OpenAIInputAdapter(),\n    )\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            print(f\"Extracted: {event.block.metadata.id}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"adapters/#anthropic","title":"Anthropic","text":""},{"location":"adapters/#setup_2","title":"Setup","text":"<pre><code>import anthropic\n\nclient = anthropic.Anthropic(api_key=\"your-api-key\")  # pragma: allowlist secret\n</code></pre>"},{"location":"adapters/#with-explicit-adapter_2","title":"With Explicit Adapter","text":"<pre><code>from streamblocks.ext.anthropic import AnthropicInputAdapter\n\nadapter = AnthropicInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n\nwith client.messages.stream(\n    model=\"claude-3-opus\",\n    max_tokens=1024,\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n) as stream:\n    async for event in processor.process_stream(stream):\n        handle_event(event)\n</code></pre>"},{"location":"adapters/#full-example_2","title":"Full Example","text":"<pre><code>import asyncio\nimport anthropic\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\nfrom streamblocks.ext.anthropic import AnthropicInputAdapter\n\nasync def main():\n    client = anthropic.Anthropic(api_key=\"your-api-key\")  # pragma: allowlist secret\n\n    prompt = \"\"\"\n    Create tasks in this format:\n    !!id:task\n    content\n    !!end\n    \"\"\"\n\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=AnthropicInputAdapter(),\n    )\n\n    with client.messages.stream(\n        model=\"claude-3-opus\",\n        max_tokens=1024,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    ) as stream:\n        async for event in processor.process_stream(stream):\n            if event.type == EventType.BLOCK_EXTRACTED:\n                print(f\"Extracted: {event.block.metadata.id}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"adapters/#identity-adapter","title":"Identity Adapter","text":"<p>For plain text streams (no LLM provider):</p> <pre><code>from streamblocks.adapters import IdentityAdapter\n\n# Explicit\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=IdentityAdapter(),\n)\n\n# Or just use a string stream\nasync def string_stream():\n    yield \"!!task01:task\\n\"\n    yield \"Do something\\n\"\n    yield \"!!end\\n\"\n\nasync for event in processor.process_stream(string_stream()):\n    handle_event(event)\n</code></pre>"},{"location":"adapters/#callable-adapters","title":"Callable Adapters","text":"<p>Use a simple function as an adapter:</p> <pre><code>def my_adapter(event):\n    \"\"\"Extract text from custom events.\"\"\"\n    if hasattr(event, \"text\"):\n        return event.text\n    if hasattr(event, \"content\"):\n        return event.content\n    return str(event)\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=my_adapter,\n)\n</code></pre>"},{"location":"adapters/#custom-adapters","title":"Custom Adapters","text":"<p>Create adapters for custom providers:</p> <pre><code>from streamblocks.adapters import EventCategory\n\nclass MyProviderAdapter:\n    \"\"\"Adapter for MyProvider API.\"\"\"\n\n    def categorize(self, event) -&gt; EventCategory:\n        \"\"\"Categorize incoming events.\"\"\"\n        if hasattr(event, \"type\"):\n            match event.type:\n                case \"content\":\n                    return EventCategory.TEXT_CONTENT\n                case \"start\":\n                    return EventCategory.STREAM_START\n                case \"end\":\n                    return EventCategory.STREAM_END\n                case \"metadata\":\n                    return EventCategory.PASSTHROUGH\n        return EventCategory.SKIP\n\n    def extract_text(self, event) -&gt; str:\n        \"\"\"Extract text from TEXT_CONTENT events.\"\"\"\n        return event.content if hasattr(event, \"content\") else \"\"\n</code></pre>"},{"location":"adapters/#event-categories","title":"Event Categories","text":"Category Description <code>TEXT_CONTENT</code> Contains text to process <code>STREAM_START</code> Stream is starting <code>STREAM_END</code> Stream is ending <code>PASSTHROUGH</code> Pass through unchanged <code>SKIP</code> Ignore this event"},{"location":"adapters/#output-adapters","title":"Output Adapters","text":"<p>Transform Streamblocks events to other formats:</p> <pre><code>from streamblocks.ext.agui import AGUIOutputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    output_adapter=AGUIOutputAdapter(),\n)\n</code></pre>"},{"location":"adapters/#custom-output-adapter","title":"Custom Output Adapter","text":"<pre><code>class JSONOutputAdapter:\n    \"\"\"Convert events to JSON.\"\"\"\n\n    def to_protocol_event(self, event):\n        return {\n            \"type\": event.type.name,\n            \"timestamp\": event.timestamp.isoformat(),\n            \"data\": self._serialize(event),\n        }\n\n    def _serialize(self, event):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            return {\n                \"id\": event.block.metadata.id,\n                \"type\": event.block.metadata.block_type,\n                \"content\": event.block.content.raw_content,\n            }\n        return {}\n\n    def passthrough(self, event):\n        return {\"type\": \"passthrough\", \"data\": str(event)}\n</code></pre>"},{"location":"adapters/#comparison","title":"Comparison","text":"Feature Gemini OpenAI Anthropic Identity Auto-detect Yes Yes Yes Yes Streaming Yes Yes Yes Yes Event types Multiple Chunk Multiple String Extra needed gemini openai anthropic None"},{"location":"adapters/#best-practices","title":"Best Practices","text":"<p>Use Auto-Detection for Flexibility</p> <p>Auto-detection makes your code work with any supported provider.</p> <p>Explicit Adapters for Control</p> <p>Use explicit adapters when you need specific behavior or optimization.</p> <p>Handle Provider Errors</p> <p>Wrap provider calls in try-except to handle API errors gracefully.</p> <p>Test with Mock Streams</p> <p>Use identity adapter with string streams for testing without API calls.</p>"},{"location":"adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture: Adapters - Adapter internals</li> <li>Events - Event system details</li> <li>Examples: Adapters - More examples</li> </ul>"},{"location":"basics/","title":"Basics","text":""},{"location":"basics/#basics","title":"Basics","text":"<p>This guide covers the fundamental concepts of Streamblocks. Understanding these concepts is essential for effectively using the library.</p>"},{"location":"basics/#core-components","title":"Core Components","text":"<p>Streamblocks is built around four core components that work together:</p> <pre><code>flowchart TB\n    subgraph Core[\"Core Components\"]\n        Processor[StreamBlockProcessor]\n        Registry[BlockRegistry]\n        Syntax[Syntax]\n        Events[Events]\n    end\n\n    Stream[Text Stream] --&gt; Processor\n    Processor --&gt; Registry\n    Registry --&gt; Syntax\n    Processor --&gt; Events\n    Events --&gt; Application[Your Application]</code></pre>"},{"location":"basics/#streamblockprocessor","title":"StreamBlockProcessor","text":"<p>The central engine that processes text streams and extracts blocks:</p> <pre><code>from streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\n\n# Create a processor\nregistry = BlockRegistry()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=Syntax.DELIMITER_PREAMBLE,\n)\n\n# Process a stream\nasync for event in processor.process_stream(stream):\n    handle_event(event)\n</code></pre> <p>Key responsibilities:</p> <ul> <li>Receives text chunks from adapted streams</li> <li>Accumulates lines for block detection</li> <li>Manages block state transitions</li> <li>Emits events for each processing stage</li> <li>Coordinates validation and output</li> </ul>"},{"location":"basics/#blockregistry","title":"BlockRegistry","text":"<p>Manages registered block types and their handlers:</p> <pre><code>from streamblocks import BlockRegistry\nfrom streamblocks.blocks import TaskBlock, CodeBlock, MessageBlock\n\n# Create registry with built-in blocks\nregistry = BlockRegistry()\n\n# Register custom blocks\nregistry.register(TaskBlock)\nregistry.register(CodeBlock, priority=10)  # Higher priority\nregistry.register(MessageBlock)\n\n# Look up block by type\nblock_class = registry.get_block(\"task\")\n</code></pre> <p>Key responsibilities:</p> <ul> <li>Stores metadata and content class mappings</li> <li>Provides priority-based type resolution</li> <li>Supports custom block type registration</li> <li>Handles default block fallback</li> </ul>"},{"location":"basics/#syntax","title":"Syntax","text":"<p>Defines how blocks are detected and parsed from text:</p> <pre><code>from streamblocks import Syntax\n\n# Built-in syntaxes\nSyntax.DELIMITER_PREAMBLE      # !!id:type\\ncontent\\n!!end\nSyntax.DELIMITER_FRONTMATTER   # !!id\\n---\\nyaml\\n---\\ncontent\\n!!end\nSyntax.MARKDOWN_FRONTMATTER    # ```id\\n---\\nyaml\\n---\\ncontent\\n```\n</code></pre>"},{"location":"basics/#events","title":"Events","text":"<p>Real-time notifications about processing state:</p> <pre><code>from streamblocks import EventType\n\nasync for event in processor.process_stream(stream):\n    match event.type:\n        case EventType.STREAM_START:\n            print(\"Stream started\")\n        case EventType.TEXT_DELTA:\n            print(f\"Text: {event.text}\")\n        case EventType.BLOCK_OPENED:\n            print(f\"Block started: {event.block_id}\")\n        case EventType.BLOCK_EXTRACTED:\n            print(f\"Block complete: {event.block}\")\n        case EventType.STREAM_END:\n            print(\"Stream ended\")\n</code></pre>"},{"location":"basics/#block-model","title":"Block Model","text":"<p>A block represents a structured unit of content extracted from a text stream.</p>"},{"location":"basics/#block-structure","title":"Block Structure","text":"<pre><code>from streamblocks import Block, BaseMetadata, BaseContent\n\n# A block consists of:\n# - metadata: Parsed from header/frontmatter\n# - content: The block body\n\nblock = Block(\n    metadata=TaskMetadata(\n        id=\"task01\",\n        block_type=\"task\",\n        priority=\"high\",\n    ),\n    content=TaskContent(\n        raw_content=\"Implement the feature\",\n    ),\n)\n\n# Access block data\nprint(block.metadata.id)          # \"task01\"\nprint(block.metadata.block_type)  # \"task\"\nprint(block.content.raw_content)  # \"Implement the feature\"\n</code></pre>"},{"location":"basics/#metadata","title":"Metadata","text":"<p>Block metadata is parsed from the header or frontmatter:</p> <pre><code>from streamblocks import BaseMetadata\nfrom typing import Literal\n\nclass TaskMetadata(BaseMetadata):\n    \"\"\"Metadata for task blocks.\"\"\"\n\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n    assignee: str | None = None\n    due_date: str | None = None\n</code></pre> <p>Required fields:</p> <ul> <li><code>id</code>: Unique identifier for the block</li> <li><code>block_type</code>: Type discriminator for routing</li> </ul> <p>Optional fields:</p> <ul> <li>Any additional fields you define</li> <li>Validated by Pydantic</li> </ul>"},{"location":"basics/#content","title":"Content","text":"<p>Block content holds the parsed body:</p> <pre><code>from streamblocks import BaseContent\n\nclass TaskContent(BaseContent):\n    \"\"\"Content for task blocks.\"\"\"\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"TaskContent\":\n        \"\"\"Parse raw text into content.\"\"\"\n        # Custom parsing logic\n        return cls(raw_content=raw_text.strip())\n</code></pre>"},{"location":"basics/#processing-pipeline","title":"Processing Pipeline","text":"<p>Understanding the processing pipeline helps you build effective applications:</p> <pre><code>flowchart LR\n    subgraph Input[\"1. Input\"]\n        Stream[Provider Stream]\n        Adapter[Input Adapter]\n    end\n\n    subgraph Accumulation[\"2. Accumulation\"]\n        Chunks[Text Chunks]\n        Lines[Complete Lines]\n    end\n\n    subgraph Detection[\"3. Detection\"]\n        Searching[Searching]\n        Detected[Block Detected]\n    end\n\n    subgraph Extraction[\"4. Extraction\"]\n        Parsing[Parsing]\n        Validation[Validation]\n    end\n\n    subgraph Output[\"5. Output\"]\n        Events[Events]\n        Blocks[Blocks]\n    end\n\n    Stream --&gt; Adapter --&gt; Chunks --&gt; Lines\n    Lines --&gt; Searching --&gt; Detected\n    Detected --&gt; Parsing --&gt; Validation\n    Validation --&gt; Events\n    Validation --&gt; Blocks</code></pre>"},{"location":"basics/#step-1-input-adaptation","title":"Step 1: Input Adaptation","text":"<p>Provider-specific streams are normalized to text chunks:</p> <pre><code># Raw Gemini stream\nasync for chunk in gemini_response:\n    # chunk is GenerateContentResponse\n\n# Adapted to text\nasync for text in adapted_stream:\n    # text is a string\n</code></pre>"},{"location":"basics/#step-2-line-accumulation","title":"Step 2: Line Accumulation","text":"<p>Text chunks are accumulated into complete lines:</p> <pre><code># Chunks may split across lines\nchunk1 = \"Hello, wo\"\nchunk2 = \"rld!\\nHow are\"\nchunk3 = \" you?\\n\"\n\n# Accumulated into lines\nline1 = \"Hello, world!\"\nline2 = \"How are you?\"\n</code></pre>"},{"location":"basics/#step-3-block-detection","title":"Step 3: Block Detection","text":"<p>Lines are scanned for block start/end markers:</p> <pre><code># Delimiter Preamble syntax\n\"!!task01:task\"      # Start detected\n\"Do something\"       # Content\n\"!!end\"              # End detected\n</code></pre>"},{"location":"basics/#step-4-block-extraction","title":"Step 4: Block Extraction","text":"<p>Complete blocks are parsed and validated:</p> <pre><code># Parsing\nmetadata = parse_metadata(header_line)\ncontent = parse_content(content_lines)\n\n# Validation\nvalidate_metadata(metadata)\nvalidate_content(content)\n\n# Block creation\nblock = Block(metadata=metadata, content=content)\n</code></pre>"},{"location":"basics/#step-5-event-emission","title":"Step 5: Event Emission","text":"<p>Events are emitted for each stage:</p> <pre><code># Events throughout processing\nSTREAM_START      # Stream begins\nTEXT_DELTA        # Text chunk received\nBLOCK_OPENED      # Block start detected\nBLOCK_CONTENT     # Content accumulated\nBLOCK_EXTRACTED   # Block complete and valid\nBLOCK_REJECTED    # Block failed validation\nSTREAM_END        # Stream complete\n</code></pre>"},{"location":"basics/#configuration-options","title":"Configuration Options","text":""},{"location":"basics/#processor-configuration","title":"Processor Configuration","text":"<pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=Syntax.DELIMITER_PREAMBLE,\n\n    # Event emission\n    emit_text_deltas=True,       # Emit TEXT_DELTA events\n    emit_block_content=True,     # Emit BLOCK_CONTENT events\n    emit_original_events=False,  # Emit original provider events\n\n    # Limits\n    max_block_size=100_000,      # Max content size in chars\n\n    # Adapters\n    input_adapter=\"auto\",        # Auto-detect adapter\n    output_adapter=None,         # Optional output transformation\n\n    # Logging\n    logger=my_logger,            # Custom logger\n)\n</code></pre>"},{"location":"basics/#registry-configuration","title":"Registry Configuration","text":"<pre><code>registry = BlockRegistry()\n\n# Register with priority (higher = checked first)\nregistry.register(HighPriorityBlock, priority=100)\nregistry.register(NormalBlock, priority=50)\nregistry.register(FallbackBlock, priority=1)\n\n# Set default block for unknown types\nregistry.set_default(GenericBlock)\n</code></pre>"},{"location":"basics/#basic-usage-patterns","title":"Basic Usage Patterns","text":""},{"location":"basics/#pattern-1-simple-extraction","title":"Pattern 1: Simple Extraction","text":"<p>Extract all blocks from a stream:</p> <pre><code>from streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\n\nasync def extract_blocks(stream):\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n    )\n\n    blocks = []\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            blocks.append(event.block)\n\n    return blocks\n</code></pre>"},{"location":"basics/#pattern-2-real-time-processing","title":"Pattern 2: Real-time Processing","text":"<p>Process blocks as they complete:</p> <pre><code>async def process_realtime(stream):\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        emit_text_deltas=True,\n    )\n\n    async for event in processor.process_stream(stream):\n        match event.type:\n            case EventType.TEXT_DELTA:\n                # Show text as it arrives\n                display_text(event.text)\n\n            case EventType.BLOCK_OPENED:\n                # Block started - prepare UI\n                show_block_placeholder(event.block_id)\n\n            case EventType.BLOCK_EXTRACTED:\n                # Block complete - render it\n                render_block(event.block)\n\n            case EventType.BLOCK_REJECTED:\n                # Block failed - show error\n                show_error(event.rejection.message)\n</code></pre>"},{"location":"basics/#pattern-3-type-specific-handling","title":"Pattern 3: Type-Specific Handling","text":"<p>Route blocks by type:</p> <pre><code>async def handle_by_type(stream):\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n    )\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            block = event.block\n\n            match block.metadata.block_type:\n                case \"task\":\n                    await handle_task(block)\n                case \"code\":\n                    await handle_code(block)\n                case \"message\":\n                    await handle_message(block)\n                case _:\n                    await handle_unknown(block)\n</code></pre>"},{"location":"basics/#pattern-4-error-handling","title":"Pattern 4: Error Handling","text":"<p>Handle errors gracefully:</p> <pre><code>async def process_with_errors(stream):\n    registry = BlockRegistry()\n    processor = StreamBlockProcessor(\n        registry=registry,\n        syntax=Syntax.DELIMITER_PREAMBLE,\n    )\n\n    extracted = 0\n    rejected = 0\n\n    async for event in processor.process_stream(stream):\n        match event.type:\n            case EventType.BLOCK_EXTRACTED:\n                extracted += 1\n                await process_block(event.block)\n\n            case EventType.BLOCK_REJECTED:\n                rejected += 1\n                await log_rejection(event.rejection)\n\n            case EventType.STREAM_END:\n                print(f\"Complete: {extracted} extracted, {rejected} rejected\")\n</code></pre>"},{"location":"basics/#text-vs-blocks","title":"Text vs Blocks","text":"<p>Streamblocks distinguishes between regular text and structured blocks:</p> <pre><code>This is regular text that passes through.\n\n!!task01:task\nThis is block content that gets extracted.\n!!end\n\nMore regular text here.\n</code></pre> <p>With <code>emit_text_deltas=True</code>:</p> <pre><code># Events emitted:\nTEXT_DELTA: \"This is regular text that passes through.\\n\"\nTEXT_DELTA: \"\\n\"\nBLOCK_OPENED: block_id=\"task01\"\nBLOCK_CONTENT: \"This is block content that gets extracted.\"\nBLOCK_EXTRACTED: Block(...)\nTEXT_DELTA: \"\\n\"\nTEXT_DELTA: \"More regular text here.\\n\"\n</code></pre>"},{"location":"basics/#memory-considerations","title":"Memory Considerations","text":"<p>Streamblocks is designed for efficient streaming:</p> <ul> <li>No full buffering: Text is processed line-by-line</li> <li>Events emitted immediately: As soon as detection is complete</li> <li>Block size limits: Configurable maximum to prevent memory issues</li> </ul> <pre><code># Limit block size\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    max_block_size=50_000,  # Reject blocks larger than 50KB\n)\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        if event.rejection.reason == BlockErrorCode.MAX_SIZE_EXCEEDED:\n            print(\"Block too large, skipping\")\n</code></pre>"},{"location":"basics/#next-steps","title":"Next Steps","text":"<ul> <li>Stream Processing - Deep dive into processing</li> <li>Syntaxes - Syntax formats in detail</li> <li>Adapters - Working with LLM providers</li> <li>Block Types - Creating custom blocks</li> <li>Events - Event system details</li> </ul>"},{"location":"blocks/","title":"Block Types","text":""},{"location":"blocks/#block-types","title":"Block Types","text":"<p>Blocks are structured units of content extracted from text streams. This guide covers the block model, built-in types, and creating custom blocks.</p>"},{"location":"blocks/#block-structure","title":"Block Structure","text":"<p>Every block has two components:</p> <pre><code>flowchart TB\n    Block[Block] --&gt; Metadata[Metadata]\n    Block --&gt; Content[Content]\n\n    Metadata --&gt; ID[id: str]\n    Metadata --&gt; Type[block_type: str]\n    Metadata --&gt; Custom[Custom fields...]\n\n    Content --&gt; Raw[raw_content: str]\n    Content --&gt; Parsed[Parsed data...]</code></pre>"},{"location":"blocks/#block-class","title":"Block Class","text":"<pre><code>from streamblocks import Block\n\nblock = Block(\n    metadata=TaskMetadata(id=\"task01\", block_type=\"task\"),\n    content=TaskContent(raw_content=\"Implement feature\"),\n)\n\n# Access data\nblock.metadata.id          # \"task01\"\nblock.metadata.block_type  # \"task\"\nblock.content.raw_content  # \"Implement feature\"\n</code></pre>"},{"location":"blocks/#metadata","title":"Metadata","text":"<p>Metadata is parsed from the block header or frontmatter.</p>"},{"location":"blocks/#basemetadata","title":"BaseMetadata","text":"<p>All metadata classes inherit from <code>BaseMetadata</code>:</p> <pre><code>from streamblocks import BaseMetadata\nfrom typing import Literal\n\nclass BaseMetadata:\n    \"\"\"Base class for block metadata.\"\"\"\n\n    id: str              # Required: unique identifier\n    block_type: str      # Required: type discriminator\n</code></pre>"},{"location":"blocks/#custom-metadata","title":"Custom Metadata","text":"<p>Create custom metadata with additional fields:</p> <pre><code>from streamblocks import BaseMetadata\nfrom typing import Literal\n\nclass TaskMetadata(BaseMetadata):\n    \"\"\"Metadata for task blocks.\"\"\"\n\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n    assignee: str | None = None\n    due_date: str | None = None\n    tags: list[str] = []\n\nclass CodeMetadata(BaseMetadata):\n    \"\"\"Metadata for code blocks.\"\"\"\n\n    block_type: Literal[\"code\"] = \"code\"\n    language: str = \"python\"\n    filename: str | None = None\n    line_start: int | None = None\n</code></pre>"},{"location":"blocks/#metadata-validation","title":"Metadata Validation","text":"<p>Pydantic validates metadata automatically:</p> <pre><code>from pydantic import field_validator\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\n    @field_validator(\"priority\")\n    @classmethod\n    def validate_priority(cls, v: str) -&gt; str:\n        valid = {\"low\", \"normal\", \"high\", \"critical\"}\n        if v not in valid:\n            raise ValueError(f\"priority must be one of {valid}\")\n        return v\n</code></pre>"},{"location":"blocks/#content","title":"Content","text":"<p>Content holds the parsed block body.</p>"},{"location":"blocks/#basecontent","title":"BaseContent","text":"<p>All content classes inherit from <code>BaseContent</code>:</p> <pre><code>from streamblocks import BaseContent\n\nclass BaseContent:\n    \"\"\"Base class for block content.\"\"\"\n\n    raw_content: str  # The raw text content\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"BaseContent\":\n        \"\"\"Parse raw text into content.\"\"\"\n        return cls(raw_content=raw_text)\n</code></pre>"},{"location":"blocks/#custom-content","title":"Custom Content","text":"<p>Create content classes with custom parsing:</p> <pre><code>from streamblocks import BaseContent\nimport json\n\nclass JSONContent(BaseContent):\n    \"\"\"Content parsed as JSON.\"\"\"\n\n    data: dict | list | None = None\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"JSONContent\":\n        try:\n            data = json.loads(raw_text)\n        except json.JSONDecodeError:\n            data = None\n\n        return cls(raw_content=raw_text, data=data)\n\nclass MarkdownContent(BaseContent):\n    \"\"\"Content with Markdown parsing.\"\"\"\n\n    title: str | None = None\n    sections: list[str] = []\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"MarkdownContent\":\n        lines = raw_text.strip().split(\"\\n\")\n\n        # Extract title (first # heading)\n        title = None\n        for line in lines:\n            if line.startswith(\"# \"):\n                title = line[2:].strip()\n                break\n\n        # Extract sections (## headings)\n        sections = [\n            line[3:].strip()\n            for line in lines\n            if line.startswith(\"## \")\n        ]\n\n        return cls(raw_content=raw_text, title=title, sections=sections)\n</code></pre>"},{"location":"blocks/#block-definition","title":"Block Definition","text":"<p>Combine metadata and content into a block type:</p> <pre><code>from streamblocks import Block, BaseMetadata, BaseContent\nfrom typing import Literal\n\n# 1. Define metadata\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n    assignee: str | None = None\n\n# 2. Define content\nclass TaskContent(BaseContent):\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"TaskContent\":\n        return cls(raw_content=raw_text.strip())\n\n# 3. Define block type alias\nTaskBlock = Block[TaskMetadata, TaskContent]\n</code></pre>"},{"location":"blocks/#block-registry","title":"Block Registry","text":"<p>The registry maps block types to their definitions:</p> <pre><code>from streamblocks import BlockRegistry\n\nregistry = BlockRegistry()\n\n# Register block types\nregistry.register(TaskBlock)\nregistry.register(CodeBlock, priority=10)  # Higher priority\nregistry.register(MessageBlock)\n\n# With custom type name\nregistry.register(TaskBlock, type_name=\"todo\")\n</code></pre>"},{"location":"blocks/#priority","title":"Priority","text":"<p>Higher priority blocks are matched first:</p> <pre><code>registry.register(HighPriorityBlock, priority=100)\nregistry.register(NormalBlock, priority=50)\nregistry.register(FallbackBlock, priority=1)\n\n# If multiple blocks match, HighPriorityBlock is used\n</code></pre>"},{"location":"blocks/#default-block","title":"Default Block","text":"<p>Set a fallback for unknown types:</p> <pre><code>registry.set_default(GenericBlock)\n\n# Now unknown types use GenericBlock instead of being rejected\n</code></pre>"},{"location":"blocks/#built-in-block-types","title":"Built-in Block Types","text":"<p>Streamblocks provides common block types:</p>"},{"location":"blocks/#genericblock","title":"GenericBlock","text":"<p>Default block for any content:</p> <pre><code>from streamblocks.blocks import GenericBlock\n\n# Works with any metadata\nblock = GenericBlock(\n    metadata=BaseMetadata(id=\"gen01\", block_type=\"unknown\"),\n    content=BaseContent(raw_content=\"Any content\"),\n)\n</code></pre>"},{"location":"blocks/#textblock","title":"TextBlock","text":"<p>Plain text content:</p> <pre><code>from streamblocks.blocks import TextBlock\n\nblock = TextBlock(\n    metadata=TextMetadata(id=\"text01\", block_type=\"text\"),\n    content=TextContent(raw_content=\"Plain text here\"),\n)\n</code></pre>"},{"location":"blocks/#creating-custom-blocks","title":"Creating Custom Blocks","text":""},{"location":"blocks/#step-by-step","title":"Step-by-Step","text":"<pre><code>from streamblocks import Block, BaseMetadata, BaseContent, BlockRegistry\nfrom typing import Literal\nfrom pydantic import field_validator\n\n# Step 1: Define metadata\nclass ReviewMetadata(BaseMetadata):\n    \"\"\"Metadata for code review blocks.\"\"\"\n\n    block_type: Literal[\"review\"] = \"review\"\n    file_path: str\n    line_start: int\n    line_end: int | None = None\n    severity: str = \"info\"\n\n    @field_validator(\"severity\")\n    @classmethod\n    def validate_severity(cls, v: str) -&gt; str:\n        valid = {\"info\", \"warning\", \"error\"}\n        if v not in valid:\n            raise ValueError(f\"severity must be one of {valid}\")\n        return v\n\n# Step 2: Define content\nclass ReviewContent(BaseContent):\n    \"\"\"Content for code review blocks.\"\"\"\n\n    suggestion: str | None = None\n    code_snippet: str | None = None\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"ReviewContent\":\n        lines = raw_text.strip().split(\"\\n\")\n\n        suggestion = None\n        code_lines = []\n\n        in_code = False\n        for line in lines:\n            if line.startswith(\"```\"):\n                in_code = not in_code\n            elif in_code:\n                code_lines.append(line)\n            else:\n                if suggestion is None:\n                    suggestion = line\n\n        return cls(\n            raw_content=raw_text,\n            suggestion=suggestion,\n            code_snippet=\"\\n\".join(code_lines) if code_lines else None,\n        )\n\n# Step 3: Create block type\nReviewBlock = Block[ReviewMetadata, ReviewContent]\n\n# Step 4: Register\nregistry = BlockRegistry()\nregistry.register(ReviewBlock)\n</code></pre>"},{"location":"blocks/#using-the-custom-block","title":"Using the Custom Block","text":"<pre><code>!!review01\n---\ntype: review\nfile_path: src/main.py\nline_start: 42\nseverity: warning\n---\nConsider using a context manager here.\n\n```python\n# Instead of:\nf = open(\"file.txt\")\nf.close()\n\n# Use:\nwith open(\"file.txt\") as f:\n    ...\n</code></pre> !!end <pre><code>## Block Lifecycle\n\n```mermaid\nsequenceDiagram\n    participant Stream\n    participant Processor\n    participant Registry\n    participant Block\n\n    Stream-&gt;&gt;Processor: Text chunk\n    Processor-&gt;&gt;Processor: Detect block start\n    Processor-&gt;&gt;Processor: Accumulate content\n    Processor-&gt;&gt;Processor: Detect block end\n    Processor-&gt;&gt;Registry: Get block type\n    Registry-&gt;&gt;Processor: Block class\n    Processor-&gt;&gt;Block: Create with metadata + content\n    Block-&gt;&gt;Processor: Validated block\n    Processor-&gt;&gt;Stream: BLOCK_EXTRACTED event\n</code></pre>"},{"location":"blocks/#block-validation","title":"Block Validation","text":"<p>Blocks are validated during creation:</p>"},{"location":"blocks/#metadata-validation_1","title":"Metadata Validation","text":"<pre><code>class TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\n    @field_validator(\"priority\")\n    @classmethod\n    def validate_priority(cls, v: str) -&gt; str:\n        if v not in {\"low\", \"normal\", \"high\"}:\n            raise ValueError(\"Invalid priority\")\n        return v\n</code></pre>"},{"location":"blocks/#content-validation","title":"Content Validation","text":"<pre><code>class JSONContent(BaseContent):\n    data: dict | None = None\n\n    @model_validator(mode=\"after\")\n    def validate_json(self) -&gt; \"JSONContent\":\n        if self.raw_content and self.data is None:\n            raise ValueError(\"Content must be valid JSON\")\n        return self\n</code></pre>"},{"location":"blocks/#handling-validation-failures","title":"Handling Validation Failures","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n\n        if rejection.reason == BlockErrorCode.VALIDATION_FAILED:\n            print(f\"Validation error: {rejection.message}\")\n</code></pre>"},{"location":"blocks/#block-serialization","title":"Block Serialization","text":""},{"location":"blocks/#to-dictionary","title":"To Dictionary","text":"<pre><code>block_dict = block.model_dump()\n# {\n#     \"metadata\": {\"id\": \"task01\", \"block_type\": \"task\", ...},\n#     \"content\": {\"raw_content\": \"...\", ...}\n# }\n</code></pre>"},{"location":"blocks/#to-json","title":"To JSON","text":"<pre><code>block_json = block.model_dump_json()\n# '{\"metadata\": {...}, \"content\": {...}}'\n</code></pre>"},{"location":"blocks/#from-dictionary","title":"From Dictionary","text":"<pre><code>block = Block.model_validate(block_dict)\n</code></pre>"},{"location":"blocks/#best-practices","title":"Best Practices","text":"<p>Keep Metadata Simple</p> <p>Put complex data in content, not metadata. Metadata should be quick to parse.</p> <p>Validate Early</p> <p>Use Pydantic validators to catch errors during parsing, not later.</p> <p>Use Literal Types</p> <p>Use <code>Literal[\"type\"]</code> for block_type to enable type checking.</p> <p>Document Block Formats</p> <p>Include examples in your block class docstrings.</p>"},{"location":"blocks/#next-steps","title":"Next Steps","text":"<ul> <li>Validation - Validation system details</li> <li>Events - Block events</li> <li>Patterns - Common usage patterns</li> </ul>"},{"location":"community/","title":"Community","text":""},{"location":"community/#community-support","title":"Community &amp; Support","text":""},{"location":"community/#getting-help","title":"Getting Help","text":""},{"location":"community/#github-issues","title":"GitHub Issues","text":"<p>For bug reports and feature requests, please use GitHub Issues.</p> <p>When reporting a bug, please include:</p> <ul> <li>Streamblocks version (<code>pip show streamblocks</code>)</li> <li>Python version</li> <li>Minimal reproducible example</li> <li>Expected vs actual behavior</li> </ul>"},{"location":"community/#discussions","title":"Discussions","text":"<p>For questions and general discussion, use GitHub Discussions.</p>"},{"location":"community/#contributing","title":"Contributing","text":"<p>We welcome contributions! See our Contributing Guide for details.</p>"},{"location":"community/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Report bugs: Open an issue with a minimal reproducible example</li> <li>Suggest features: Open an issue describing the use case</li> <li>Improve documentation: Submit PRs for docs improvements</li> <li>Add examples: Share your Streamblocks usage patterns</li> <li>Write code: Fix bugs or implement features</li> </ul>"},{"location":"community/#development-setup","title":"Development Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/hotherio/streamblocks.git\ncd streamblocks\n\n# Install development dependencies\nuv sync --all-extras\n\n# Run tests\nuv run pytest\n\n# Run linting\nuv run lefthook run pre-commit --all-files\n</code></pre>"},{"location":"community/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inclusive environment. Please read our Code of Conduct.</p>"},{"location":"community/#license","title":"License","text":"<p>Streamblocks is released under the MIT License. See LICENSE for details.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Thank you for your interest in contributing to Streamblocks!</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository:    </p><pre><code>git clone https://github.com/hotherio/streamblocks.git\ncd streamblocks\n</code></pre><p></p> </li> <li> <p>Install dependencies:    </p><pre><code>uv sync --all-extras\n</code></pre><p></p> </li> <li> <p>Install pre-commit hooks:    </p><pre><code>uv run lefthook install\n</code></pre><p></p> </li> </ol>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov\n\n# Run specific test file\nuv run pytest tests/test_processor.py\n</code></pre>"},{"location":"contributing/#running-examples","title":"Running Examples","text":"<pre><code># Run all examples\nuv run python examples/run_examples.py --skip-api\n\n# Run specific category\nuv run python examples/run_examples.py --category 01_basics\n</code></pre>"},{"location":"contributing/#code-quality","title":"Code Quality","text":"<pre><code># Run all pre-commit checks\nuv run lefthook run pre-commit --all-files -- --no-stash\n\n# Format code\nuv run ruff format\n\n# Lint code\nuv run ruff check --fix\n\n# Type check\nuv run basedpyright\n</code></pre>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li> <p>Create a branch:    </p><pre><code>git checkout -b feat/my-feature\n</code></pre><p></p> </li> <li> <p>Make your changes:    - Write tests for new functionality    - Update documentation if needed    - Follow existing code style</p> </li> <li> <p>Run checks:    </p><pre><code>uv run lefthook run pre-commit --all-files -- --no-stash\nuv run pytest\n</code></pre><p></p> </li> <li> <p>Commit with conventional commits:    </p><pre><code>git commit -m \"feat: add new feature\"\n</code></pre><p></p> </li> </ol>"},{"location":"contributing/#conventional-commits","title":"Conventional Commits","text":"<p>We use Conventional Commits:</p> <ul> <li><code>feat:</code> - New features</li> <li><code>fix:</code> - Bug fixes</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Test changes</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>perf:</code> - Performance improvements</li> <li><code>chore:</code> - Maintenance tasks</li> </ul>"},{"location":"contributing/#pr-title","title":"PR Title","text":"<p>PR titles must follow conventional commit format:</p> <pre><code>feat: add Anthropic adapter support\nfix: handle empty stream correctly\ndocs: update getting started guide\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Line length: 120 characters</li> <li>Quotes: Double quotes</li> <li>Type hints: Required for all public APIs</li> <li>Docstrings: Google style</li> </ul>"},{"location":"contributing/#adding-examples","title":"Adding Examples","text":"<p>When adding new examples:</p> <ol> <li>Place in the appropriate category folder (e.g., <code>examples/03_adapters/</code>)</li> <li>Use numbered prefix (e.g., <code>14_new_feature.py</code>)</li> <li>Include a docstring explaining the example</li> <li>Add <code>if __name__ == \"__main__\":</code> block</li> <li>Test with the example runner</li> </ol>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Documentation is in <code>docs/</code></li> <li>Uses MkDocs with Material theme</li> <li>Build locally: <code>uv run mkdocs serve</code></li> </ul>"},{"location":"contributing/#questions","title":"Questions?","text":"<p>Open a GitHub Discussion for questions.</p>"},{"location":"errors/","title":"Error Handling","text":""},{"location":"errors/#error-handling","title":"Error Handling","text":"<p>Streamblocks provides comprehensive error handling for stream processing and block validation. This guide covers error types, handling patterns, and recovery strategies.</p>"},{"location":"errors/#error-categories","title":"Error Categories","text":"<pre><code>flowchart TB\n    Errors[Errors] --&gt; Stream[Stream Errors]\n    Errors --&gt; Block[Block Errors]\n    Errors --&gt; Validation[Validation Errors]\n    Errors --&gt; Adapter[Adapter Errors]\n\n    Stream --&gt; StreamClosed[Stream Closed]\n    Stream --&gt; StreamTimeout[Timeout]\n\n    Block --&gt; InvalidHeader[Invalid Header]\n    Block --&gt; InvalidMeta[Invalid Metadata]\n    Block --&gt; InvalidContent[Invalid Content]\n    Block --&gt; TooLarge[Size Exceeded]\n    Block --&gt; Unclosed[Unclosed Block]\n\n    Validation --&gt; MetaValidation[Metadata Validation]\n    Validation --&gt; ContentValidation[Content Validation]\n\n    Adapter --&gt; AdapterMismatch[Adapter Mismatch]\n    Adapter --&gt; ProviderError[Provider Error]</code></pre>"},{"location":"errors/#blockerrorcode","title":"BlockErrorCode","text":"<p>Error codes for block rejection:</p> <pre><code>from streamblocks import BlockErrorCode\n\nclass BlockErrorCode(Enum):\n    \"\"\"Error codes for block rejection.\"\"\"\n\n    # Header errors\n    INVALID_HEADER = \"invalid_header\"\n\n    # Metadata errors\n    INVALID_METADATA = \"invalid_metadata\"\n\n    # Content errors\n    INVALID_CONTENT = \"invalid_content\"\n\n    # Validation errors\n    VALIDATION_FAILED = \"validation_failed\"\n\n    # Size errors\n    MAX_SIZE_EXCEEDED = \"max_size_exceeded\"\n\n    # State errors\n    UNCLOSED_BLOCK = \"unclosed_block\"\n\n    # Registry errors\n    UNKNOWN_BLOCK_TYPE = \"unknown_block_type\"\n</code></pre>"},{"location":"errors/#blockrejection","title":"BlockRejection","text":"<p>Information about rejected blocks:</p> <pre><code>from streamblocks import BlockRejection\n\n@dataclass\nclass BlockRejection:\n    \"\"\"Details about a rejected block.\"\"\"\n\n    reason: BlockErrorCode      # Error code\n    message: str                # Human-readable message\n    partial_content: str | None # Content accumulated before rejection\n    line_number: int | None     # Line where error occurred\n</code></pre>"},{"location":"errors/#handling-block-rejections","title":"Handling Block Rejections","text":""},{"location":"errors/#basic-handling","title":"Basic Handling","text":"<pre><code>from streamblocks import EventType, BlockErrorCode\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n        print(f\"Block rejected: {rejection.reason.value}\")\n        print(f\"Message: {rejection.message}\")\n</code></pre>"},{"location":"errors/#detailed-handling","title":"Detailed Handling","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n\n        match rejection.reason:\n            case BlockErrorCode.INVALID_HEADER:\n                logger.warning(f\"Invalid header at line {rejection.line_number}\")\n\n            case BlockErrorCode.INVALID_METADATA:\n                logger.warning(f\"Metadata error: {rejection.message}\")\n\n            case BlockErrorCode.INVALID_CONTENT:\n                logger.warning(f\"Content error: {rejection.message}\")\n\n            case BlockErrorCode.VALIDATION_FAILED:\n                logger.warning(f\"Validation failed: {rejection.message}\")\n\n            case BlockErrorCode.MAX_SIZE_EXCEEDED:\n                logger.warning(\"Block exceeded size limit\")\n\n            case BlockErrorCode.UNCLOSED_BLOCK:\n                logger.warning(\"Block not closed before stream end\")\n\n            case BlockErrorCode.UNKNOWN_BLOCK_TYPE:\n                logger.warning(f\"Unknown type: {rejection.message}\")\n</code></pre>"},{"location":"errors/#recovery-with-partial-content","title":"Recovery with Partial Content","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n\n        if rejection.partial_content:\n            # Try to salvage something from the failed block\n            logger.info(f\"Partial content: {rejection.partial_content[:100]}...\")\n\n            # Maybe parse as plain text\n            await handle_as_text(rejection.partial_content)\n</code></pre>"},{"location":"errors/#stream-errors","title":"Stream Errors","text":""},{"location":"errors/#handling-stream-exceptions","title":"Handling Stream Exceptions","text":"<pre><code>async def process_safely(stream):\n    try:\n        async for event in processor.process_stream(stream):\n            await handle_event(event)\n\n    except ConnectionError as e:\n        logger.error(f\"Connection lost: {e}\")\n        await reconnect_and_retry()\n\n    except TimeoutError as e:\n        logger.error(f\"Stream timeout: {e}\")\n        await handle_timeout()\n\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        raise\n</code></pre>"},{"location":"errors/#retry-pattern","title":"Retry Pattern","text":"<pre><code>import asyncio\n\nasync def process_with_retry(stream_factory, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            stream = stream_factory()\n            async for event in processor.process_stream(stream):\n                await handle_event(event)\n            return  # Success\n\n        except ConnectionError as e:\n            if attempt &lt; max_retries - 1:\n                wait = 2 ** attempt  # Exponential backoff\n                logger.warning(f\"Retry {attempt + 1} in {wait}s: {e}\")\n                await asyncio.sleep(wait)\n            else:\n                logger.error(\"Max retries exceeded\")\n                raise\n</code></pre>"},{"location":"errors/#validation-errors","title":"Validation Errors","text":""},{"location":"errors/#pydantic-validation","title":"Pydantic Validation","text":"<pre><code>from pydantic import ValidationError\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str\n\n    @field_validator(\"priority\")\n    @classmethod\n    def validate_priority(cls, v: str) -&gt; str:\n        if v not in {\"low\", \"normal\", \"high\"}:\n            raise ValueError(f\"Invalid priority: {v}\")\n        return v\n\n# When validation fails, BLOCK_REJECTED is emitted\n# with reason=VALIDATION_FAILED\n</code></pre>"},{"location":"errors/#custom-validation-errors","title":"Custom Validation Errors","text":"<pre><code>class StrictContent(BaseContent):\n    @model_validator(mode=\"after\")\n    def validate_content(self) -&gt; \"StrictContent\":\n        if len(self.raw_content) &lt; 10:\n            raise ValueError(\"Content too short (minimum 10 chars)\")\n\n        if not self.raw_content.strip():\n            raise ValueError(\"Content cannot be empty\")\n\n        return self\n</code></pre>"},{"location":"errors/#adapter-errors","title":"Adapter Errors","text":""},{"location":"errors/#handling-provider-errors","title":"Handling Provider Errors","text":"<pre><code>async def process_gemini_stream(prompt):\n    try:\n        response = model.generate_content(prompt, stream=True)\n\n        async for event in processor.process_stream(response):\n            await handle_event(event)\n\n    except google.api_core.exceptions.ResourceExhausted:\n        logger.error(\"Gemini rate limit exceeded\")\n        await asyncio.sleep(60)\n        # Retry...\n\n    except google.api_core.exceptions.InvalidArgument as e:\n        logger.error(f\"Invalid request: {e}\")\n        raise\n</code></pre>"},{"location":"errors/#adapter-mismatch","title":"Adapter Mismatch","text":"<pre><code>from streamblocks.ext.gemini import GeminiInputAdapter\n\n# Using wrong adapter for stream type\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=GeminiInputAdapter(),  # Wrong for OpenAI stream\n)\n\n# Will fail to extract text from events\n# Use input_adapter=\"auto\" to avoid this\n</code></pre>"},{"location":"errors/#error-logging","title":"Error Logging","text":""},{"location":"errors/#structured-logging","title":"Structured Logging","text":"<pre><code>import structlog\n\nlogger = structlog.get_logger()\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        logger.warning(\n            \"block_rejected\",\n            reason=event.rejection.reason.value,\n            message=event.rejection.message,\n            line_number=event.rejection.line_number,\n            has_partial=event.rejection.partial_content is not None,\n        )\n</code></pre>"},{"location":"errors/#error-statistics","title":"Error Statistics","text":"<pre><code>from collections import Counter\n\nerror_counts = Counter()\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        error_counts[event.rejection.reason] += 1\n\n# Summary\nfor reason, count in error_counts.most_common():\n    print(f\"{reason.value}: {count}\")\n</code></pre>"},{"location":"errors/#graceful-degradation","title":"Graceful Degradation","text":""},{"location":"errors/#continue-on-error","title":"Continue on Error","text":"<pre><code>async def resilient_process(stream):\n    blocks = []\n    errors = []\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            try:\n                processed = await process_block(event.block)\n                blocks.append(processed)\n            except ProcessingError as e:\n                errors.append(e)\n                # Continue with next block\n\n        elif event.type == EventType.BLOCK_REJECTED:\n            errors.append(event.rejection)\n            # Continue processing\n\n    return blocks, errors\n</code></pre>"},{"location":"errors/#fallback-processing","title":"Fallback Processing","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        block = event.block\n\n        try:\n            await primary_handler(block)\n        except PrimaryError:\n            try:\n                await fallback_handler(block)\n            except FallbackError:\n                await last_resort_handler(block)\n</code></pre>"},{"location":"errors/#error-recovery-strategies","title":"Error Recovery Strategies","text":""},{"location":"errors/#1-skip-and-continue","title":"1. Skip and Continue","text":"<pre><code># Skip failed blocks, process the rest\nerrors = []\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        errors.append(event.rejection)\n        continue  # Skip to next\n\n    if event.type == EventType.BLOCK_EXTRACTED:\n        await process(event.block)\n</code></pre>"},{"location":"errors/#2-retry-failed-blocks","title":"2. Retry Failed Blocks","text":"<pre><code># Collect failed blocks for retry\nfailed_blocks = []\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        if event.rejection.partial_content:\n            failed_blocks.append(event.rejection)\n\n# Later: retry with more lenient settings\nfor rejection in failed_blocks:\n    await retry_parse(rejection.partial_content)\n</code></pre>"},{"location":"errors/#3-alert-and-stop","title":"3. Alert and Stop","text":"<pre><code># Stop on critical errors\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        if is_critical(event.rejection):\n            await alert_operators(event.rejection)\n            raise CriticalError(event.rejection.message)\n\n    if event.type == EventType.BLOCK_EXTRACTED:\n        await process(event.block)\n</code></pre>"},{"location":"errors/#best-practices","title":"Best Practices","text":"<p>Log All Rejections</p> <p>Always log block rejections for debugging.</p> <p>Use Structured Logging</p> <p>Include context (reason, line number, partial content) in logs.</p> <p>Graceful Degradation</p> <p>Design for partial success\u2014one failed block shouldn't stop processing.</p> <p>Monitor Error Rates</p> <p>Track rejection rates to detect problems early.</p> <p>Test Error Paths</p> <p>Test with invalid input to ensure error handling works.</p>"},{"location":"errors/#next-steps","title":"Next Steps","text":"<ul> <li>Events - Event handling</li> <li>Validation - Validation system</li> <li>Troubleshooting - Common issues</li> </ul>"},{"location":"events/","title":"Events","text":""},{"location":"events/#events","title":"Events","text":"<p>Streamblocks uses an event-driven architecture to notify your application about processing state. This guide covers the event system, event types, and handling patterns.</p>"},{"location":"events/#overview","title":"Overview","text":"<pre><code>flowchart LR\n    subgraph Processing[\"StreamBlockProcessor\"]\n        Stream[Text Stream]\n        Detect[Block Detection]\n        Parse[Block Parsing]\n    end\n\n    subgraph Events[\"Event Types\"]\n        Start[STREAM_START]\n        Text[TEXT_DELTA]\n        Open[BLOCK_OPENED]\n        Content[BLOCK_CONTENT]\n        Extract[BLOCK_EXTRACTED]\n        Reject[BLOCK_REJECTED]\n        End[STREAM_END]\n    end\n\n    subgraph Application[\"Your Application\"]\n        Handler[Event Handler]\n    end\n\n    Stream --&gt; Detect --&gt; Parse\n    Parse --&gt; Start &amp; Text &amp; Open &amp; Content &amp; Extract &amp; Reject &amp; End\n    Start &amp; Text &amp; Open &amp; Content &amp; Extract &amp; Reject &amp; End --&gt; Handler</code></pre>"},{"location":"events/#event-types","title":"Event Types","text":""},{"location":"events/#eventtype-enum","title":"EventType Enum","text":"<pre><code>from streamblocks import EventType\n\nclass EventType(Enum):\n    \"\"\"Types of events emitted during processing.\"\"\"\n\n    # Lifecycle events\n    STREAM_START = \"stream_start\"\n    STREAM_END = \"stream_end\"\n\n    # Text events\n    TEXT_DELTA = \"text_delta\"\n\n    # Block events\n    BLOCK_OPENED = \"block_opened\"\n    BLOCK_CONTENT = \"block_content\"\n    BLOCK_EXTRACTED = \"block_extracted\"\n    BLOCK_REJECTED = \"block_rejected\"\n\n    # Original events (passthrough)\n    ORIGINAL_EVENT = \"original_event\"\n</code></pre>"},{"location":"events/#event-categories","title":"Event Categories","text":"Category Events Description Lifecycle <code>STREAM_START</code>, <code>STREAM_END</code> Stream boundaries Text <code>TEXT_DELTA</code> Non-block text Block <code>BLOCK_OPENED</code>, <code>BLOCK_CONTENT</code>, <code>BLOCK_EXTRACTED</code>, <code>BLOCK_REJECTED</code> Block processing Original <code>ORIGINAL_EVENT</code> Passthrough events"},{"location":"events/#streamevent","title":"StreamEvent","text":"<p>All events are instances of <code>StreamEvent</code>:</p> <pre><code>from streamblocks import StreamEvent\n\n@dataclass\nclass StreamEvent:\n    \"\"\"Event emitted during stream processing.\"\"\"\n\n    type: EventType\n    timestamp: datetime\n\n    # Optional fields (depend on event type)\n    text: str | None = None\n    block: Block | None = None\n    block_id: str | None = None\n    rejection: BlockRejection | None = None\n    original_event: Any | None = None\n</code></pre>"},{"location":"events/#lifecycle-events","title":"Lifecycle Events","text":""},{"location":"events/#stream_start","title":"STREAM_START","text":"<p>Emitted when processing begins:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.STREAM_START:\n        print(\"Processing started\")\n        start_time = event.timestamp\n</code></pre>"},{"location":"events/#stream_end","title":"STREAM_END","text":"<p>Emitted when processing completes:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.STREAM_END:\n        print(\"Processing complete\")\n        end_time = event.timestamp\n</code></pre>"},{"location":"events/#text-events","title":"Text Events","text":""},{"location":"events/#text_delta","title":"TEXT_DELTA","text":"<p>Emitted for non-block text when <code>emit_text_deltas=True</code>:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_text_deltas=True,\n)\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.TEXT_DELTA:\n        print(event.text, end=\"\", flush=True)\n</code></pre> <p>Event fields:</p> <ul> <li><code>text</code>: The text chunk received</li> </ul>"},{"location":"events/#block-events","title":"Block Events","text":""},{"location":"events/#block_opened","title":"BLOCK_OPENED","text":"<p>Emitted when a block start is detected:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_OPENED:\n        print(f\"Block started: {event.block_id}\")\n        # Prepare UI for incoming block\n</code></pre> <p>Event fields:</p> <ul> <li><code>block_id</code>: The block identifier from the header</li> </ul>"},{"location":"events/#block_content","title":"BLOCK_CONTENT","text":"<p>Emitted for each content line when <code>emit_block_content=True</code>:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_block_content=True,\n)\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_CONTENT:\n        print(f\"Content: {event.text}\")\n</code></pre> <p>Event fields:</p> <ul> <li><code>text</code>: The content line</li> <li><code>block_id</code>: The current block ID</li> </ul>"},{"location":"events/#block_extracted","title":"BLOCK_EXTRACTED","text":"<p>Emitted when a block is successfully parsed and validated:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        block = event.block\n        print(f\"Block: {block.metadata.id} ({block.metadata.block_type})\")\n        print(f\"Content: {block.content.raw_content}\")\n</code></pre> <p>Event fields:</p> <ul> <li><code>block</code>: The complete <code>Block</code> instance</li> </ul>"},{"location":"events/#block_rejected","title":"BLOCK_REJECTED","text":"<p>Emitted when a block fails validation:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n        print(f\"Rejected: {rejection.reason.value}\")\n        print(f\"Message: {rejection.message}\")\n</code></pre> <p>Event fields:</p> <ul> <li><code>rejection</code>: <code>BlockRejection</code> with error details</li> </ul>"},{"location":"events/#original-events","title":"Original Events","text":""},{"location":"events/#original_event","title":"ORIGINAL_EVENT","text":"<p>Emitted for passthrough events when <code>emit_original_events=True</code>:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_original_events=True,\n)\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.ORIGINAL_EVENT:\n        # Handle provider-specific event\n        handle_original(event.original_event)\n</code></pre>"},{"location":"events/#event-handling-patterns","title":"Event Handling Patterns","text":""},{"location":"events/#match-statement","title":"Match Statement","text":"<pre><code>async for event in processor.process_stream(stream):\n    match event.type:\n        case EventType.STREAM_START:\n            on_start()\n        case EventType.TEXT_DELTA:\n            on_text(event.text)\n        case EventType.BLOCK_OPENED:\n            on_block_open(event.block_id)\n        case EventType.BLOCK_EXTRACTED:\n            on_block(event.block)\n        case EventType.BLOCK_REJECTED:\n            on_rejected(event.rejection)\n        case EventType.STREAM_END:\n            on_end()\n</code></pre>"},{"location":"events/#filtered-handling","title":"Filtered Handling","text":"<pre><code># Only handle block events\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        await process_block(event.block)\n    elif event.type == EventType.BLOCK_REJECTED:\n        await log_rejection(event.rejection)\n</code></pre>"},{"location":"events/#callback-based","title":"Callback-Based","text":"<pre><code>class EventHandler:\n    def __init__(self):\n        self.handlers = {\n            EventType.STREAM_START: self.on_start,\n            EventType.TEXT_DELTA: self.on_text,\n            EventType.BLOCK_EXTRACTED: self.on_block,\n            EventType.STREAM_END: self.on_end,\n        }\n\n    async def handle(self, event: StreamEvent):\n        handler = self.handlers.get(event.type)\n        if handler:\n            await handler(event)\n\n    async def on_start(self, event):\n        print(\"Started\")\n\n    async def on_text(self, event):\n        print(event.text, end=\"\")\n\n    async def on_block(self, event):\n        print(f\"\\nBlock: {event.block.metadata.id}\")\n\n    async def on_end(self, event):\n        print(\"\\nDone\")\n\nhandler = EventHandler()\nasync for event in processor.process_stream(stream):\n    await handler.handle(event)\n</code></pre>"},{"location":"events/#event-timeline","title":"Event Timeline","text":"<pre><code>sequenceDiagram\n    participant Stream\n    participant Processor\n    participant App as Application\n\n    Stream-&gt;&gt;Processor: Start\n    Processor-&gt;&gt;App: STREAM_START\n\n    Stream-&gt;&gt;Processor: \"Hello, \"\n    Processor-&gt;&gt;App: TEXT_DELTA(\"Hello, \")\n\n    Stream-&gt;&gt;Processor: \"World!\\n\"\n    Processor-&gt;&gt;App: TEXT_DELTA(\"World!\\n\")\n\n    Stream-&gt;&gt;Processor: \"!!task01:task\\n\"\n    Processor-&gt;&gt;App: BLOCK_OPENED(id=\"task01\")\n\n    Stream-&gt;&gt;Processor: \"Do something\\n\"\n    Note over Processor: Accumulating...\n\n    Stream-&gt;&gt;Processor: \"!!end\\n\"\n    Processor-&gt;&gt;App: BLOCK_EXTRACTED(block)\n\n    Stream-&gt;&gt;Processor: \"Bye!\\n\"\n    Processor-&gt;&gt;App: TEXT_DELTA(\"Bye!\\n\")\n\n    Stream-&gt;&gt;Processor: EOF\n    Processor-&gt;&gt;App: STREAM_END</code></pre>"},{"location":"events/#configuration","title":"Configuration","text":""},{"location":"events/#controlling-event-emission","title":"Controlling Event Emission","text":"<pre><code># Minimal events\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_text_deltas=False,     # No TEXT_DELTA\n    emit_block_content=False,    # No BLOCK_CONTENT\n    emit_original_events=False,  # No ORIGINAL_EVENT\n)\n# Only emits: STREAM_START, BLOCK_OPENED, BLOCK_EXTRACTED, BLOCK_REJECTED, STREAM_END\n\n# Full events\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_text_deltas=True,       # TEXT_DELTA for non-block text\n    emit_block_content=True,     # BLOCK_CONTENT during accumulation\n    emit_original_events=True,   # ORIGINAL_EVENT for passthrough\n)\n</code></pre>"},{"location":"events/#statistics-tracking","title":"Statistics Tracking","text":"<pre><code>from dataclasses import dataclass, field\nfrom collections import Counter\n\n@dataclass\nclass ProcessingStats:\n    text_chunks: int = 0\n    text_chars: int = 0\n    blocks_opened: int = 0\n    blocks_extracted: int = 0\n    blocks_rejected: int = 0\n    block_types: Counter = field(default_factory=Counter)\n\nstats = ProcessingStats()\n\nasync for event in processor.process_stream(stream):\n    match event.type:\n        case EventType.TEXT_DELTA:\n            stats.text_chunks += 1\n            stats.text_chars += len(event.text)\n        case EventType.BLOCK_OPENED:\n            stats.blocks_opened += 1\n        case EventType.BLOCK_EXTRACTED:\n            stats.blocks_extracted += 1\n            stats.block_types[event.block.metadata.block_type] += 1\n        case EventType.BLOCK_REJECTED:\n            stats.blocks_rejected += 1\n\nprint(f\"Text: {stats.text_chunks} chunks, {stats.text_chars} chars\")\nprint(f\"Blocks: {stats.blocks_extracted} extracted, {stats.blocks_rejected} rejected\")\nprint(f\"Types: {dict(stats.block_types)}\")\n</code></pre>"},{"location":"events/#error-handling","title":"Error Handling","text":"<pre><code>async def process_with_errors(stream):\n    try:\n        async for event in processor.process_stream(stream):\n            try:\n                await handle_event(event)\n            except EventHandlingError as e:\n                logger.error(f\"Error handling {event.type}: {e}\")\n                # Continue processing\n    except StreamError as e:\n        logger.error(f\"Stream error: {e}\")\n        raise\n</code></pre>"},{"location":"events/#next-steps","title":"Next Steps","text":"<ul> <li>Error Handling - Error patterns</li> <li>Patterns - Common patterns</li> <li>API Reference - Event API details</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Common questions about Streamblocks.</p>"},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-streamblocks","title":"What is Streamblocks?","text":"<p>Streamblocks is a Python library for extracting structured blocks from text streams in real-time. It's designed to work with LLM output streams, enabling reactive applications that process content as it's generated.</p>"},{"location":"faq/#how-is-this-different-from-just-parsing-json","title":"How is this different from just parsing JSON?","text":"<p>Streamblocks extracts blocks while streaming, not after completion. This enables:</p> <ul> <li>Real-time reactions - Respond to content immediately</li> <li>Feedback loops - Provide input to LLMs mid-generation</li> <li>Progress tracking - Show users what's happening</li> <li>Early termination - Stop processing when needed</li> </ul> <p>JSON parsing requires waiting for the complete response.</p>"},{"location":"faq/#what-llm-providers-are-supported","title":"What LLM providers are supported?","text":"<p>Streamblocks includes adapters for:</p> <ul> <li>Google Gemini - <code>streamblocks[gemini]</code></li> <li>OpenAI - <code>streamblocks[openai]</code></li> <li>Anthropic Claude - <code>streamblocks[anthropic]</code></li> </ul> <p>Any text stream can be processed\u2014adapters just normalize the format.</p>"},{"location":"faq/#can-i-use-streamblocks-with-langchainlanggraph","title":"Can I use Streamblocks with LangChain/LangGraph?","text":"<p>Yes! Streamblocks is framework-agnostic. Process any text stream:</p> <pre><code># Works with any async iterator\nasync for event in processor.process_stream(langchain_stream):\n    ...\n</code></pre>"},{"location":"faq/#blocks-syntaxes","title":"Blocks &amp; Syntaxes","text":""},{"location":"faq/#what-block-formats-are-supported","title":"What block formats are supported?","text":"<p>Three built-in syntaxes:</p> <ol> <li>Delimiter Preamble - <code>!!id:type\\ncontent\\n!!end</code></li> <li>Delimiter Frontmatter - YAML frontmatter with delimiters</li> <li>Markdown Frontmatter - Code fences with YAML frontmatter</li> </ol> <p>You can also create custom syntaxes.</p>"},{"location":"faq/#can-i-define-custom-block-types","title":"Can I define custom block types?","text":"<p>Yes! Create Pydantic models for metadata and content:</p> <pre><code>from streamblocks import Block, BaseMetadata, BaseContent\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\nclass TaskContent(BaseContent):\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"TaskContent\":\n        return cls(raw_content=raw_text)\n\nclass Task(Block[TaskMetadata, TaskContent]):\n    pass\n</code></pre>"},{"location":"faq/#how-do-i-handle-malformed-blocks","title":"How do I handle malformed blocks?","text":"<p>Malformed blocks emit <code>BLOCK_REJECTED</code> events:</p> <pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        print(f\"Rejected: {event.rejection.reason}\")\n</code></pre>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#whats-the-performance-overhead","title":"What's the performance overhead?","text":"<p>Streamblocks adds minimal overhead:</p> <ul> <li>Line-by-line processing with efficient buffering</li> <li>No regex compilation per-line (patterns are pre-compiled)</li> <li>Async-native design for non-blocking I/O</li> </ul> <p>For most applications, the LLM API latency dominates.</p>"},{"location":"faq/#can-i-process-multiple-streams-concurrently","title":"Can I process multiple streams concurrently?","text":"<p>Yes, each <code>StreamBlockProcessor</code> instance is independent:</p> <pre><code>async def process_multiple():\n    processors = [StreamBlockProcessor(registry, syntax) for _ in range(3)]\n    tasks = [process_stream(p, stream) for p, stream in zip(processors, streams)]\n    await asyncio.gather(*tasks)\n</code></pre>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#blocks-arent-being-detected","title":"Blocks aren't being detected","text":"<ol> <li>Check syntax - Ensure block format matches the configured syntax</li> <li>Check delimiters - Verify start/end markers are correct</li> <li>Enable logging - Use <code>DEBUG</code> level to see processing details</li> </ol> <pre><code>import logging\nlogging.getLogger(\"streamblocks\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"faq/#import-errors","title":"Import errors","text":"<p>Install the appropriate extras:</p> <pre><code>uv add streamblocks[gemini]   # For Gemini\nuv add streamblocks[openai]   # For OpenAI\nuv add streamblocks[anthropic]  # For Anthropic\n</code></pre>"},{"location":"faq/#type-errors-with-pydantic","title":"Type errors with Pydantic","text":"<p>Ensure your metadata/content classes inherit correctly:</p> <pre><code>from streamblocks import BaseMetadata, BaseContent\n\nclass MyMetadata(BaseMetadata):  # Must inherit BaseMetadata\n    ...\n\nclass MyContent(BaseContent):   # Must inherit BaseContent\n    ...\n</code></pre>"},{"location":"faq/#more-help","title":"More Help","text":"<ul> <li>Troubleshooting Guide - Detailed solutions</li> <li>Community - Get help from the community</li> <li>GitHub Issues - Report bugs</li> </ul>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#getting-started","title":"Getting Started","text":"<p>This guide will help you get up and running with Streamblocks in just a few minutes.</p>"},{"location":"getting_started/#quick-example","title":"Quick Example","text":"<p>Here's a minimal example showing how to process a text stream and extract structured blocks:</p> <pre><code>import asyncio\nfrom hother.streamblocks import StreamBlockProcessor\nfrom hother.streamblocks.syntaxes import MarkdownFrontmatterSyntax\n\nasync def main():\n    # Create a processor with markdown frontmatter syntax\n    processor = StreamBlockProcessor(\n        syntaxes=[MarkdownFrontmatterSyntax()]\n    )\n\n    # Simulate a text stream\n    text_chunks = [\n        \"# Hello World\\n\",\n        \"---\\n\",\n        \"type: message\\n\",\n        \"---\\n\",\n        \"This is the content.\\n\",\n    ]\n\n    # Process the stream\n    async for event in processor.process_stream(iter(text_chunks)):\n        print(f\"Event: {event.type} - {event}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting_started/#core-concepts","title":"Core Concepts","text":""},{"location":"getting_started/#blocks","title":"Blocks","text":"<p>A block is a structured unit of content extracted from a text stream. Blocks have:</p> <ul> <li>Type: What kind of content it contains (message, code, tool call, etc.)</li> <li>Metadata: Key-value pairs describing the block</li> <li>Content: The actual content of the block</li> </ul>"},{"location":"getting_started/#syntaxes","title":"Syntaxes","text":"<p>Syntaxes define how blocks are detected and parsed from text streams. Streamblocks provides several built-in syntaxes:</p> <ul> <li><code>MarkdownFrontmatterSyntax</code>: Blocks with YAML frontmatter</li> <li><code>DelimiterFrontmatterSyntax</code>: Blocks with custom delimiters</li> <li><code>FencedCodeSyntax</code>: Markdown code blocks</li> </ul>"},{"location":"getting_started/#events","title":"Events","text":"<p>The processor emits events as it processes the stream:</p> <ul> <li><code>TEXT_DELTA</code>: Raw text chunks</li> <li><code>BLOCK_OPENED</code>: A new block was detected</li> <li><code>BLOCK_UPDATED</code>: Block content was updated</li> <li><code>BLOCK_CLOSED</code>: Block parsing completed</li> </ul>"},{"location":"getting_started/#next-steps","title":"Next Steps","text":"<ul> <li>Basics - Learn core concepts in depth</li> <li>Examples - Explore working examples</li> <li>API Reference - Detailed API documentation</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>Streamblocks can be installed using pip or uv.</p>"},{"location":"installation/#basic-installation","title":"Basic Installation","text":"uvpip <pre><code>uv add streamblocks\n</code></pre> <pre><code>pip install streamblocks\n</code></pre>"},{"location":"installation/#with-ai-provider-support","title":"With AI Provider Support","text":"<p>Install with specific AI provider support:</p> <pre><code># Gemini support\npip install streamblocks[gemini]\n\n# OpenAI support\npip install streamblocks[openai]\n\n# Anthropic support\npip install streamblocks[anthropic]\n\n# All providers\npip install streamblocks[all-providers]\n</code></pre>"},{"location":"installation/#with-enhanced-logging","title":"With Enhanced Logging","text":"<pre><code># Structlog integration\npip install streamblocks[structlog]\n\n# Loguru integration\npip install streamblocks[loguru]\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For development, clone the repository and install with all dependencies:</p> <pre><code>git clone https://github.com/hotherio/streamblocks.git\ncd streamblocks\nuv sync --all-extras\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.13 or higher</li> <li>pydantic &gt;= 2.0</li> <li>pyyaml &gt;= 6.0</li> </ul>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<pre><code>from hother.streamblocks import StreamBlockProcessor\n\nprint(\"Streamblocks installed successfully!\")\n</code></pre>"},{"location":"patterns/","title":"Common Patterns","text":""},{"location":"patterns/#common-patterns","title":"Common Patterns","text":"<p>This guide covers common usage patterns with Streamblocks.</p>"},{"location":"patterns/#processing-llm-responses","title":"Processing LLM Responses","text":"<p>The most common use case is extracting structured blocks from LLM responses:</p> <pre><code>async def process_llm_response(response_stream):\n    processor = StreamBlockProcessor(\n        syntaxes=[MarkdownFrontmatterSyntax()]\n    )\n\n    blocks = []\n    async for event in processor.process_stream(response_stream):\n        if event.type == EventType.BLOCK_CLOSED:\n            blocks.append(event.block)\n\n    return blocks\n</code></pre>"},{"location":"patterns/#real-time-block-updates","title":"Real-time Block Updates","text":"<p>Display blocks as they're being streamed:</p> <pre><code>async def stream_with_updates(stream):\n    processor = StreamBlockProcessor(\n        syntaxes=[MarkdownFrontmatterSyntax()],\n        emit_block_events=True,\n    )\n\n    current_block = None\n    async for event in processor.process_stream(stream):\n        match event.type:\n            case EventType.BLOCK_OPENED:\n                current_block = event.block\n                print(f\"Started: {current_block.block_type}\")\n            case EventType.BLOCK_UPDATED:\n                print(f\"Content: {event.block.content[-50:]}\")\n            case EventType.BLOCK_CLOSED:\n                print(f\"Finished: {event.block.block_type}\")\n                current_block = None\n</code></pre>"},{"location":"patterns/#multiple-syntax-support","title":"Multiple Syntax Support","text":"<p>Combine multiple syntaxes for flexible parsing:</p> <pre><code>processor = StreamBlockProcessor(\n    syntaxes=[\n        MarkdownFrontmatterSyntax(),  # YAML frontmatter\n        FencedCodeSyntax(),           # Code blocks\n        DelimiterFrontmatterSyntax(), # Custom delimiters\n    ]\n)\n</code></pre>"},{"location":"patterns/#filtering-events","title":"Filtering Events","text":"<p>Process only specific event types:</p> <pre><code>async def get_text_only(stream):\n    processor = StreamBlockProcessor(\n        emit_text_delta=True,\n        emit_block_events=False,  # Skip block events\n    )\n\n    text = \"\"\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.TEXT_DELTA:\n            text += event.data\n\n    return text\n</code></pre>"},{"location":"patterns/#block-type-routing","title":"Block Type Routing","text":"<p>Route blocks to different handlers:</p> <pre><code>handlers = {\n    \"message\": handle_message,\n    \"tool_call\": handle_tool_call,\n    \"code\": handle_code,\n}\n\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_CLOSED:\n        block = event.block\n        handler = handlers.get(block.block_type)\n        if handler:\n            await handler(block)\n</code></pre>"},{"location":"patterns/#error-recovery","title":"Error Recovery","text":"<p>Continue processing after errors:</p> <pre><code>async def process_with_recovery(stream):\n    processor = StreamBlockProcessor(syntaxes=[MarkdownFrontmatterSyntax()])\n\n    async for event in processor.process_stream(stream):\n        try:\n            if event.type == EventType.BLOCK_CLOSED:\n                process_block(event.block)\n        except Exception as e:\n            logger.error(f\"Error processing block: {e}\")\n            continue  # Continue with next event\n</code></pre>"},{"location":"patterns/#chaining-processors","title":"Chaining Processors","text":"<p>Use multiple processors for different stages:</p> <pre><code># First pass: extract raw blocks\nraw_processor = StreamBlockProcessor(syntaxes=[MarkdownFrontmatterSyntax()])\n\n# Second pass: validate and transform\nasync def process_pipeline(stream):\n    async for event in raw_processor.process_stream(stream):\n        if event.type == EventType.BLOCK_CLOSED:\n            validated = validate_block(event.block)\n            if validated:\n                yield transform_block(validated)\n</code></pre>"},{"location":"performance/","title":"Performance","text":""},{"location":"performance/#performance","title":"Performance","text":"<p>This guide covers performance optimization for Streamblocks.</p>"},{"location":"performance/#event-filtering","title":"Event Filtering","text":"<p>Disable events you don't need:</p> <pre><code># Only emit block events (skip text deltas)\nprocessor = StreamBlockProcessor(\n    emit_text_delta=False,\n    emit_block_events=True,\n)\n\n# Only emit final blocks (skip updates)\nprocessor = StreamBlockProcessor(\n    emit_block_opened=False,\n    emit_block_updated=False,\n    emit_block_closed=True,\n)\n</code></pre>"},{"location":"performance/#buffer-management","title":"Buffer Management","text":"<p>Configure buffer sizes for your use case:</p> <pre><code>from hother.streamblocks.core.processor import ProcessorConfig\n\nconfig = ProcessorConfig(max_block_size=1_000_000)  # Maximum block content size\nprocessor = StreamBlockProcessor(registry, config=config)\n</code></pre>"},{"location":"performance/#async-processing","title":"Async Processing","text":"<p>Use async for I/O-bound operations:</p> <pre><code>async def process_multiple_streams(streams):\n    tasks = [process_stream(s) for s in streams]\n    results = await asyncio.gather(*tasks)\n    return results\n</code></pre>"},{"location":"performance/#memory-efficiency","title":"Memory Efficiency","text":"<p>For large streams, process events immediately:</p> <pre><code>async for event in processor.process_stream(stream):\n    # Process and discard - don't accumulate\n    handle_event(event)\n</code></pre>"},{"location":"performance/#profiling","title":"Profiling","text":"<p>Profile your Streamblocks usage:</p> <pre><code>import cProfile\nimport pstats\n\nwith cProfile.Profile() as pr:\n    asyncio.run(process_stream(stream))\n\nstats = pstats.Stats(pr)\nstats.sort_stats('cumulative')\nstats.print_stats(10)\n</code></pre>"},{"location":"performance/#benchmarks","title":"Benchmarks","text":"<p>Typical performance characteristics:</p> Scenario Throughput Plain text pass-through ~100 MB/s Simple block extraction ~50 MB/s Complex nested parsing ~10 MB/s <p>Actual performance depends on syntax complexity and hardware.</p>"},{"location":"processing/","title":"Stream Processing","text":""},{"location":"processing/#stream-processing","title":"Stream Processing","text":"<p>This guide covers the stream processing system in depth, including line accumulation, chunk handling, and processing configuration.</p>"},{"location":"processing/#overview","title":"Overview","text":"<pre><code>flowchart TB\n    subgraph Input[\"Input Stage\"]\n        Stream[Provider Stream]\n        Adapter[Input Adapter]\n        Chunks[Text Chunks]\n    end\n\n    subgraph Processing[\"Processing Stage\"]\n        Accumulator[Line Accumulator]\n        StateMachine[State Machine]\n        Parser[Block Parser]\n    end\n\n    subgraph Validation[\"Validation Stage\"]\n        MetaValid[Metadata Validation]\n        ContentValid[Content Validation]\n    end\n\n    subgraph Output[\"Output Stage\"]\n        Events[Stream Events]\n        Blocks[Extracted Blocks]\n    end\n\n    Stream --&gt; Adapter\n    Adapter --&gt; Chunks\n    Chunks --&gt; Accumulator\n    Accumulator --&gt; StateMachine\n    StateMachine --&gt; Parser\n    Parser --&gt; MetaValid\n    MetaValid --&gt; ContentValid\n    ContentValid --&gt; Events\n    ContentValid --&gt; Blocks</code></pre>"},{"location":"processing/#line-accumulation","title":"Line Accumulation","text":"<p>Text arrives as chunks that may not align with line boundaries. The line accumulator handles this:</p>"},{"location":"processing/#chunk-splitting","title":"Chunk Splitting","text":"<pre><code># Example: chunks don't align with lines\nchunk1 = \"Hello, wo\"      # Partial line\nchunk2 = \"rld!\\nHow are\"  # End of line + partial\nchunk3 = \" you?\\n\"        # End of second line\n\n# Accumulator produces complete lines:\n# Line 1: \"Hello, world!\"\n# Line 2: \"How are you?\"\n</code></pre>"},{"location":"processing/#accumulation-process","title":"Accumulation Process","text":"<pre><code>sequenceDiagram\n    participant Stream\n    participant Accumulator\n    participant Processor\n\n    Stream-&gt;&gt;Accumulator: \"Hello, wo\"\n    Note over Accumulator: Buffer: \"Hello, wo\"\n\n    Stream-&gt;&gt;Accumulator: \"rld!\\nHow are\"\n    Accumulator-&gt;&gt;Processor: Line: \"Hello, world!\"\n    Note over Accumulator: Buffer: \"How are\"\n\n    Stream-&gt;&gt;Accumulator: \" you?\\n\"\n    Accumulator-&gt;&gt;Processor: Line: \"How are you?\"\n    Note over Accumulator: Buffer: \"\"\n\n    Stream-&gt;&gt;Accumulator: [EOF]\n    Note over Accumulator: Flush remaining (if any)</code></pre>"},{"location":"processing/#implementation","title":"Implementation","text":"<pre><code>class LineAccumulator:\n    \"\"\"Accumulates text chunks into complete lines.\"\"\"\n\n    def __init__(self):\n        self.buffer = \"\"\n\n    def add_chunk(self, chunk: str) -&gt; list[str]:\n        \"\"\"Add a chunk and return any complete lines.\"\"\"\n        self.buffer += chunk\n        lines = []\n\n        while \"\\n\" in self.buffer:\n            line, self.buffer = self.buffer.split(\"\\n\", 1)\n            lines.append(line)\n\n        return lines\n\n    def flush(self) -&gt; str | None:\n        \"\"\"Flush remaining buffer at stream end.\"\"\"\n        if self.buffer:\n            remaining = self.buffer\n            self.buffer = \"\"\n            return remaining\n        return None\n</code></pre>"},{"location":"processing/#processing-configuration","title":"Processing Configuration","text":""},{"location":"processing/#basic-configuration","title":"Basic Configuration","text":"<pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=Syntax.DELIMITER_PREAMBLE,\n)\n</code></pre>"},{"location":"processing/#event-emission-options","title":"Event Emission Options","text":"<p>Control which events are emitted:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n\n    # TEXT_DELTA events for non-block text\n    emit_text_deltas=True,\n\n    # BLOCK_CONTENT events during accumulation\n    emit_block_content=True,\n\n    # Original provider events (passthrough)\n    emit_original_events=False,\n)\n</code></pre> Option Default Description <code>emit_text_deltas</code> <code>True</code> Emit TEXT_DELTA for regular text <code>emit_block_content</code> <code>False</code> Emit BLOCK_CONTENT during accumulation <code>emit_original_events</code> <code>False</code> Pass through original provider events"},{"location":"processing/#size-limits","title":"Size Limits","text":"<p>Prevent memory issues with large blocks:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    max_block_size=100_000,  # Characters\n)\n</code></pre> <p>When exceeded: - Block is rejected with <code>MAX_SIZE_EXCEEDED</code> - BLOCK_REJECTED event is emitted - Processing continues with next content</p>"},{"location":"processing/#adapter-configuration","title":"Adapter Configuration","text":"<pre><code># Auto-detect adapter\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=\"auto\",\n)\n\n# Explicit adapter\nfrom streamblocks.ext.gemini import GeminiInputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=GeminiInputAdapter(),\n)\n\n# Output adapter\nfrom streamblocks.ext.agui import AGUIOutputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    output_adapter=AGUIOutputAdapter(),\n)\n</code></pre>"},{"location":"processing/#processing-lifecycle","title":"Processing Lifecycle","text":""},{"location":"processing/#stream-lifecycle","title":"Stream Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Idle\n    Idle --&gt; Processing: process_stream() called\n\n    state Processing {\n        [*] --&gt; Searching\n\n        Searching --&gt; BlockDetected: Start marker\n        Searching --&gt; Searching: Regular line\n\n        BlockDetected --&gt; Accumulating: Valid header\n        BlockDetected --&gt; Searching: Invalid header\n\n        Accumulating --&gt; Closing: End marker\n        Accumulating --&gt; Accumulating: Content line\n\n        Closing --&gt; Searching: Block complete\n    }\n\n    Processing --&gt; Complete: Stream ends\n    Complete --&gt; [*]</code></pre>"},{"location":"processing/#event-flow","title":"Event Flow","text":"<pre><code>async for event in processor.process_stream(stream):\n    # Events in order:\n    # 1. STREAM_START (once)\n    # 2. TEXT_DELTA (0+ times, for non-block text)\n    # 3. BLOCK_OPENED (when block starts)\n    # 4. BLOCK_CONTENT (0+ times, if emit_block_content=True)\n    # 5. BLOCK_EXTRACTED or BLOCK_REJECTED (when block ends)\n    # 6. More TEXT_DELTA, BLOCK_* as needed\n    # 7. STREAM_END (once)\n    pass\n</code></pre>"},{"location":"processing/#processing-modes","title":"Processing Modes","text":""},{"location":"processing/#batch-processing","title":"Batch Processing","text":"<p>Collect all blocks after stream completes:</p> <pre><code>async def batch_process(stream):\n    blocks = []\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            blocks.append(event.block)\n\n    return blocks\n</code></pre>"},{"location":"processing/#real-time-processing","title":"Real-time Processing","text":"<p>Handle events as they arrive:</p> <pre><code>async def realtime_process(stream):\n    async for event in processor.process_stream(stream):\n        match event.type:\n            case EventType.TEXT_DELTA:\n                await display_text(event.text)\n            case EventType.BLOCK_OPENED:\n                await show_block_placeholder(event.block_id)\n            case EventType.BLOCK_EXTRACTED:\n                await render_block(event.block)\n</code></pre>"},{"location":"processing/#filtered-processing","title":"Filtered Processing","text":"<p>Only process specific event types:</p> <pre><code>async def filtered_process(stream):\n    async for event in processor.process_stream(stream):\n        # Only handle block events\n        if event.type in (EventType.BLOCK_EXTRACTED, EventType.BLOCK_REJECTED):\n            await handle_block_event(event)\n</code></pre>"},{"location":"processing/#error-handling","title":"Error Handling","text":""},{"location":"processing/#stream-errors","title":"Stream Errors","text":"<pre><code>async def process_with_error_handling(stream):\n    try:\n        async for event in processor.process_stream(stream):\n            await handle_event(event)\n    except StreamError as e:\n        logger.error(f\"Stream error: {e}\")\n        await handle_stream_error(e)\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        raise\n</code></pre>"},{"location":"processing/#block-rejections","title":"Block Rejections","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n\n        match rejection.reason:\n            case BlockErrorCode.INVALID_METADATA:\n                logger.warning(f\"Invalid metadata: {rejection.message}\")\n            case BlockErrorCode.MAX_SIZE_EXCEEDED:\n                logger.warning(f\"Block too large\")\n            case BlockErrorCode.VALIDATION_FAILED:\n                logger.warning(f\"Validation failed: {rejection.message}\")\n</code></pre>"},{"location":"processing/#graceful-degradation","title":"Graceful Degradation","text":"<p>Continue processing after errors:</p> <pre><code>async def resilient_process(stream):\n    extracted = 0\n    rejected = 0\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            extracted += 1\n            try:\n                await process_block(event.block)\n            except ProcessingError:\n                rejected += 1  # Count as rejected but continue\n\n        elif event.type == EventType.BLOCK_REJECTED:\n            rejected += 1\n            # Log but continue\n\n    return extracted, rejected\n</code></pre>"},{"location":"processing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"processing/#memory-efficiency","title":"Memory Efficiency","text":"<pre><code># Process large streams without memory issues\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    max_block_size=50_000,       # Limit individual blocks\n    emit_block_content=False,    # Don't emit content events\n)\n\n# Process events immediately, don't accumulate\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        await process_and_forget(event.block)  # Don't store\n</code></pre>"},{"location":"processing/#throughput-optimization","title":"Throughput Optimization","text":"<pre><code># Minimal event emission for speed\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    emit_text_deltas=False,      # Skip text events\n    emit_block_content=False,    # Skip content events\n    emit_original_events=False,  # Skip original events\n)\n</code></pre>"},{"location":"processing/#concurrent-processing","title":"Concurrent Processing","text":"<pre><code>import asyncio\n\nasync def process_multiple_streams(streams):\n    async def process_one(stream):\n        processor = StreamBlockProcessor(\n            registry=BlockRegistry(),\n            syntax=syntax,\n        )\n\n        blocks = []\n        async for event in processor.process_stream(stream):\n            if event.type == EventType.BLOCK_EXTRACTED:\n                blocks.append(event.block)\n        return blocks\n\n    # Process streams concurrently\n    results = await asyncio.gather(*[process_one(s) for s in streams])\n    return results\n</code></pre>"},{"location":"processing/#debugging","title":"Debugging","text":""},{"location":"processing/#enable-logging","title":"Enable Logging","text":"<pre><code>import logging\n\n# Enable debug logging\nlogging.basicConfig(level=logging.DEBUG)\nlogging.getLogger(\"streamblocks\").setLevel(logging.DEBUG)\n\n# Or use structlog\nimport structlog\n\nlogger = structlog.get_logger(\"my_app\")\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    logger=logger,\n)\n</code></pre>"},{"location":"processing/#trace-events","title":"Trace Events","text":"<pre><code>async def trace_process(stream):\n    async for event in processor.process_stream(stream):\n        print(f\"Event: {event.type.name}\")\n        if hasattr(event, \"text\"):\n            print(f\"  Text: {event.text[:50]}...\")\n        if hasattr(event, \"block\"):\n            print(f\"  Block: {event.block.metadata.id}\")\n        if hasattr(event, \"rejection\"):\n            print(f\"  Rejection: {event.rejection.reason}\")\n</code></pre>"},{"location":"processing/#next-steps","title":"Next Steps","text":"<ul> <li>Syntaxes - Block format syntaxes</li> <li>Adapters - Input/output adapters</li> <li>Events - Event system details</li> <li>Performance - Optimization tips</li> </ul>"},{"location":"syntaxes/","title":"Syntaxes","text":""},{"location":"syntaxes/#syntaxes","title":"Syntaxes","text":"<p>Syntaxes define how blocks are detected and parsed from text streams. This guide covers the built-in syntaxes and how to create custom ones.</p>"},{"location":"syntaxes/#overview","title":"Overview","text":"<p>Streamblocks includes three built-in syntaxes:</p> Syntax Format Use Case <code>DELIMITER_PREAMBLE</code> <code>!!id:type\\n...\\n!!end</code> Simple, compact blocks <code>DELIMITER_FRONTMATTER</code> <code>!!id\\n---\\nyaml\\n---\\n...\\n!!end</code> Rich metadata <code>MARKDOWN_FRONTMATTER</code> <code>```id\\n---\\nyaml\\n---\\n...\\n```</code> Markdown compatibility"},{"location":"syntaxes/#delimiter-preamble","title":"Delimiter Preamble","text":"<p>The simplest syntax with inline metadata:</p> <pre><code>!!task01:task\nImplement the authentication feature\n!!end\n</code></pre>"},{"location":"syntaxes/#structure","title":"Structure","text":"<pre><code>!!&lt;id&gt;:&lt;type&gt;\n&lt;content&gt;\n!!end\n</code></pre> <ul> <li>Start marker: <code>!!</code> + block ID + <code>:</code> + block type</li> <li>Content: Any text between markers</li> <li>End marker: <code>!!end</code></li> </ul>"},{"location":"syntaxes/#example","title":"Example","text":"<pre><code>from streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\n\ntext = \"\"\"\nHere's what needs to be done:\n\n!!task01:task\nImplement user authentication\n!!end\n\n!!task02:task\nAdd password reset flow\n!!end\n\"\"\"\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n)\n\n# Extracts:\n# Block 1: id=\"task01\", type=\"task\", content=\"Implement user authentication\"\n# Block 2: id=\"task02\", type=\"task\", content=\"Add password reset flow\"\n</code></pre>"},{"location":"syntaxes/#use-cases","title":"Use Cases","text":"<ul> <li>Simple task lists</li> <li>Quick annotations</li> <li>Minimal overhead</li> <li>When metadata is simple (just type)</li> </ul>"},{"location":"syntaxes/#delimiter-frontmatter","title":"Delimiter Frontmatter","text":"<p>Extended format with YAML frontmatter:</p> <pre><code>!!task01\n---\ntype: task\npriority: high\nassignee: alice\ndue_date: 2024-03-15\n---\nImplement the authentication feature with OAuth support.\n!!end\n</code></pre>"},{"location":"syntaxes/#structure_1","title":"Structure","text":"<pre><code>!!&lt;id&gt;\n---\n&lt;yaml frontmatter&gt;\n---\n&lt;content&gt;\n!!end\n</code></pre> <ul> <li>Start marker: <code>!!</code> + block ID</li> <li>Frontmatter: YAML between <code>---</code> markers</li> <li>Content: Any text after frontmatter</li> <li>End marker: <code>!!end</code></li> </ul>"},{"location":"syntaxes/#example_1","title":"Example","text":"<pre><code>text = \"\"\"\n!!feature01\n---\ntype: feature\npriority: high\ntags:\n  - authentication\n  - security\n---\nImplement OAuth 2.0 authentication with support for:\n- Google\n- GitHub\n- Microsoft\n!!end\n\"\"\"\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_FRONTMATTER,\n)\n\n# Extracts:\n# Block: id=\"feature01\", type=\"feature\", priority=\"high\", ...\n</code></pre>"},{"location":"syntaxes/#use-cases_1","title":"Use Cases","text":"<ul> <li>Complex metadata requirements</li> <li>Nested metadata (YAML structures)</li> <li>When you need more than just type</li> </ul>"},{"location":"syntaxes/#markdown-frontmatter","title":"Markdown Frontmatter","text":"<p>Compatible with Markdown code fences:</p> <pre><code>```task01\n---\ntype: task\nlanguage: python\n---\ndef authenticate(user, password):\n    # Implement authentication logic\n    pass\n```\n</code></pre>"},{"location":"syntaxes/#structure_2","title":"Structure","text":"<pre><code>```&lt;id&gt;\n---\n&lt;yaml frontmatter&gt;\n---\n&lt;content&gt;\n```\n</code></pre> <ul> <li>Start marker: <code>```</code> + block ID</li> <li>Frontmatter: YAML between <code>---</code> markers</li> <li>Content: Any text after frontmatter</li> <li>End marker: <code>```</code></li> </ul>"},{"location":"syntaxes/#example_2","title":"Example","text":"<pre><code>text = \"\"\"\nHere's the implementation:\n\n```code01\n---\ntype: code\nlanguage: python\n---\ndef greet(name):\n    return f\"Hello, {name}!\"\n```\n\nAnd the tests:\n\n```test01\n---\ntype: code\nlanguage: python\n---\ndef test_greet():\n    assert greet(\"World\") == \"Hello, World!\"\n```\n\"\"\"\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.MARKDOWN_FRONTMATTER,\n)\n</code></pre>"},{"location":"syntaxes/#use-cases_2","title":"Use Cases","text":"<ul> <li>Markdown documents</li> <li>Code blocks with metadata</li> <li>Documentation with embedded blocks</li> </ul>"},{"location":"syntaxes/#syntax-selection","title":"Syntax Selection","text":"<p>Choose the right syntax for your use case:</p> <pre><code>flowchart TB\n    Start[Choose Syntax] --&gt; Q1{Need YAML metadata?}\n\n    Q1 --&gt;|No| Preamble[DELIMITER_PREAMBLE]\n    Q1 --&gt;|Yes| Q2{Markdown compatibility?}\n\n    Q2 --&gt;|No| Frontmatter[DELIMITER_FRONTMATTER]\n    Q2 --&gt;|Yes| Markdown[MARKDOWN_FRONTMATTER]</code></pre>"},{"location":"syntaxes/#decision-factors","title":"Decision Factors","text":"Factor Preamble Frontmatter Markdown Simplicity Best Good Good Metadata richness Minimal Full Full Markdown compat No No Yes Visual clarity Good Good Best Parse complexity Low Medium Medium"},{"location":"syntaxes/#custom-syntaxes","title":"Custom Syntaxes","text":"<p>Create custom syntaxes for specific formats.</p>"},{"location":"syntaxes/#basic-custom-syntax","title":"Basic Custom Syntax","text":"<pre><code>from streamblocks.syntaxes import BaseSyntax\nfrom streamblocks.core.types import DetectionResult, ParseResult\n\nclass XMLSyntax(BaseSyntax):\n    \"\"\"Custom XML-style syntax.\"\"\"\n\n    def detect_start(self, line: str) -&gt; DetectionResult | None:\n        \"\"\"Detect block start.\"\"\"\n        if line.strip().startswith(\"&lt;block\"):\n            # Parse attributes from &lt;block id=\"...\" type=\"...\"&gt;\n            import re\n            match = re.match(r'&lt;block\\s+id=\"(\\w+)\"\\s+type=\"(\\w+)\"&gt;', line.strip())\n            if match:\n                return DetectionResult(\n                    block_id=match.group(1),\n                    block_type=match.group(2),\n                )\n        return None\n\n    def detect_end(self, line: str) -&gt; bool:\n        \"\"\"Detect block end.\"\"\"\n        return line.strip() == \"&lt;/block&gt;\"\n\n    def parse_block(self, candidate) -&gt; ParseResult:\n        \"\"\"Parse complete block.\"\"\"\n        # Content is lines between start and end\n        content = \"\\n\".join(candidate.content_lines)\n        return ParseResult(\n            metadata={\"id\": candidate.block_id, \"type\": candidate.block_type},\n            content=content,\n            success=True,\n        )\n</code></pre>"},{"location":"syntaxes/#using-custom-syntax","title":"Using Custom Syntax","text":"<pre><code>syntax = XMLSyntax()\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=syntax,\n)\n\ntext = \"\"\"\n&lt;block id=\"greeting\" type=\"message\"&gt;\nHello, World!\n&lt;/block&gt;\n\"\"\"\n</code></pre>"},{"location":"syntaxes/#syntax-with-yaml-frontmatter","title":"Syntax with YAML Frontmatter","text":"<pre><code>import yaml\nfrom streamblocks.syntaxes import BaseSyntax\n\nclass CustomFrontmatterSyntax(BaseSyntax):\n    \"\"\"Custom syntax with YAML frontmatter.\"\"\"\n\n    START_PATTERN = \"=== BEGIN ===\"\n    END_PATTERN = \"=== END ===\"\n    FRONTMATTER_DELIMITER = \"---\"\n\n    def detect_start(self, line: str) -&gt; DetectionResult | None:\n        if line.strip() == self.START_PATTERN:\n            return DetectionResult(block_id=\"pending\", block_type=\"pending\")\n        return None\n\n    def detect_end(self, line: str) -&gt; bool:\n        return line.strip() == self.END_PATTERN\n\n    def parse_block(self, candidate) -&gt; ParseResult:\n        lines = candidate.content_lines\n\n        # Find frontmatter bounds\n        fm_start = None\n        fm_end = None\n\n        for i, line in enumerate(lines):\n            if line.strip() == self.FRONTMATTER_DELIMITER:\n                if fm_start is None:\n                    fm_start = i\n                else:\n                    fm_end = i\n                    break\n\n        # Parse frontmatter\n        if fm_start is not None and fm_end is not None:\n            fm_lines = lines[fm_start + 1:fm_end]\n            metadata = yaml.safe_load(\"\\n\".join(fm_lines))\n            content_lines = lines[fm_end + 1:]\n        else:\n            metadata = {}\n            content_lines = lines\n\n        return ParseResult(\n            metadata=metadata,\n            content=\"\\n\".join(content_lines),\n            success=True,\n        )\n</code></pre>"},{"location":"syntaxes/#multi-pattern-syntax","title":"Multi-Pattern Syntax","text":"<p>Support multiple start patterns:</p> <pre><code>class MultiPatternSyntax(BaseSyntax):\n    \"\"\"Syntax that accepts multiple start patterns.\"\"\"\n\n    START_PATTERNS = [\"&lt;&lt;BEGIN&gt;&gt;\", \"[[START]]\", \"{{BLOCK}}\"]\n    END_PATTERNS = [\"&lt;&lt;END&gt;&gt;\", \"[[END]]\", \"{{/BLOCK}}\"]\n\n    def detect_start(self, line: str) -&gt; DetectionResult | None:\n        stripped = line.strip()\n        for i, pattern in enumerate(self.START_PATTERNS):\n            if stripped.startswith(pattern):\n                # Extract ID from rest of line\n                rest = stripped[len(pattern):].strip()\n                return DetectionResult(\n                    block_id=rest or f\"block_{i}\",\n                    block_type=\"generic\",\n                )\n        return None\n\n    def detect_end(self, line: str) -&gt; bool:\n        stripped = line.strip()\n        return any(stripped == p for p in self.END_PATTERNS)\n</code></pre>"},{"location":"syntaxes/#syntax-detection-internals","title":"Syntax Detection Internals","text":""},{"location":"syntaxes/#detection-flow","title":"Detection Flow","text":"<pre><code>flowchart TB\n    Line[Incoming Line] --&gt; CheckStart{detect_start?}\n\n    CheckStart --&gt;|Yes| Header[HEADER_DETECTED]\n    CheckStart --&gt;|No| CheckEnd{In block?}\n\n    CheckEnd --&gt;|Yes| Accumulate[Add to content]\n    CheckEnd --&gt;|No| PassThrough[Regular text]\n\n    Accumulate --&gt; CheckBlockEnd{detect_end?}\n    CheckBlockEnd --&gt;|Yes| Parse[Parse block]\n    CheckBlockEnd --&gt;|No| Continue[Continue]\n\n    Parse --&gt; Validate[Validate]\n    Validate --&gt;|Pass| Extract[BLOCK_EXTRACTED]\n    Validate --&gt;|Fail| Reject[BLOCK_REJECTED]</code></pre>"},{"location":"syntaxes/#performance-considerations","title":"Performance Considerations","text":"<p>Fast Detection</p> <p>Keep <code>detect_start</code> and <code>detect_end</code> fast. They're called for every line.</p> <pre><code># Good: Simple string check\ndef detect_start(self, line: str) -&gt; DetectionResult | None:\n    if line.startswith(\"!!\"):\n        return self._parse_header(line)\n    return None\n\n# Bad: Complex regex on every line\ndef detect_start(self, line: str) -&gt; DetectionResult | None:\n    # Expensive regex compiled on every call\n    match = re.match(r'^!!(\\w+):(\\w+)(?:\\s+\\{.*\\})?\\s*$', line)\n    ...\n</code></pre> <p>Pre-compile Patterns</p> <p>Compile regex patterns once:</p> <pre><code>class MySyntax(BaseSyntax):\n    START_PATTERN = re.compile(r'^!!(\\w+):(\\w+)\\s*$')\n\n    def detect_start(self, line: str) -&gt; DetectionResult | None:\n        match = self.START_PATTERN.match(line)\n        ...\n</code></pre>"},{"location":"syntaxes/#testing-syntaxes","title":"Testing Syntaxes","text":""},{"location":"syntaxes/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\n\n@pytest.fixture\ndef processor():\n    return StreamBlockProcessor(\n        registry=BlockRegistry(),\n        syntax=Syntax.DELIMITER_PREAMBLE,\n    )\n\nasync def test_basic_extraction(processor):\n    text = \"!!test01:task\\nDo something\\n!!end\"\n\n    events = []\n    async for event in processor.process_stream(async_iter([text])):\n        events.append(event)\n\n    # Find extracted block\n    extracted = [e for e in events if e.type == EventType.BLOCK_EXTRACTED]\n    assert len(extracted) == 1\n    assert extracted[0].block.metadata.id == \"test01\"\n</code></pre>"},{"location":"syntaxes/#edge-cases","title":"Edge Cases","text":"<p>Test these edge cases:</p> <pre><code># Empty block\n\"!!empty:task\\n!!end\"\n\n# Block with only whitespace\n\"!!space:task\\n   \\n!!end\"\n\n# Nested delimiters in content\n\"!!outer:task\\n!!inner:task\\nContent\\n!!end\\n!!end\"\n\n# Unicode content\n\"!!unicode:task\\n\u3053\u3093\u306b\u3061\u306f\\n!!end\"\n\n# Very long content\n\"!!large:task\\n\" + (\"x\" * 100000) + \"\\n!!end\"\n</code></pre>"},{"location":"syntaxes/#next-steps","title":"Next Steps","text":"<ul> <li>Block Types - Custom block definitions</li> <li>Validation - Block validation</li> <li>Architecture: State Machine - Detection internals</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions for Streamblocks.</p>"},{"location":"troubleshooting/#blocks-not-detected","title":"Blocks Not Detected","text":"<p>Problem: Blocks are not being detected from the stream.</p> <p>Solutions:</p> <ol> <li> <p>Check syntax configuration: Ensure you've registered the correct syntax in the registry:    </p><pre><code>from hother.streamblocks import Registry, StreamBlockProcessor, MarkdownFrontmatterSyntax\n\nsyntax = MarkdownFrontmatterSyntax()\nregistry = Registry(syntax=syntax)\n# Register your block types...\nprocessor = StreamBlockProcessor(registry)\n</code></pre><p></p> </li> <li> <p>Verify block format: Ensure your blocks match the expected format:    </p><pre><code>---\ntype: message\n---\nContent here\n</code></pre><p></p> </li> <li> <p>Enable debug logging:    </p><pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre><p></p> </li> </ol>"},{"location":"troubleshooting/#events-not-emitted","title":"Events Not Emitted","text":"<p>Problem: Expected events are not being emitted.</p> <p>Solutions:</p> <ol> <li> <p>Check event flags: Use ProcessorConfig to control which events are emitted:    </p><pre><code>from hother.streamblocks import StreamBlockProcessor\nfrom hother.streamblocks.core.processor import ProcessorConfig\n\nconfig = ProcessorConfig(\n    emit_text_deltas=True,       # Enable text delta events\n    emit_section_end_events=True, # Enable section end events\n)\nprocessor = StreamBlockProcessor(registry, config=config)\n</code></pre><p></p> </li> <li> <p>Verify stream is being consumed:    </p><pre><code>async for event in processor.process_stream(stream):\n    print(event)  # Ensure iteration happens\n</code></pre><p></p> </li> </ol>"},{"location":"troubleshooting/#adapter-issues","title":"Adapter Issues","text":"<p>Problem: Stream adapter not working correctly.</p> <p>Solutions:</p> <ol> <li> <p>Use correct adapter:    </p><pre><code># For Gemini\nfrom hother.streamblocks.adapters import GeminiAdapter\n\n# For OpenAI\nfrom hother.streamblocks.adapters import OpenAIAdapter\n</code></pre><p></p> </li> <li> <p>Try auto-detection:    </p><pre><code>from hother.streamblocks.adapters import auto_detect_adapter\n\nadapter = auto_detect_adapter(stream)\n</code></pre><p></p> </li> </ol>"},{"location":"troubleshooting/#import-errors","title":"Import Errors","text":"<p>Problem: Cannot import Streamblocks modules.</p> <p>Solutions:</p> <ol> <li> <p>Check installation:    </p><pre><code>pip show streamblocks\n</code></pre><p></p> </li> <li> <p>Install with extras:    </p><pre><code>pip install streamblocks[gemini,openai]\n</code></pre><p></p> </li> </ol>"},{"location":"troubleshooting/#memory-issues","title":"Memory Issues","text":"<p>Problem: High memory usage with large streams.</p> <p>Solutions:</p> <ol> <li> <p>Process events immediately:    </p><pre><code>async for event in processor.process_stream(stream):\n    handle_event(event)  # Don't accumulate\n</code></pre><p></p> </li> <li> <p>Set block size limits: Use ProcessorConfig to limit block sizes:    </p><pre><code>from hother.streamblocks.core.processor import ProcessorConfig\n\nconfig = ProcessorConfig(max_block_size=100_000)\nprocessor = StreamBlockProcessor(registry, config=config)\n</code></pre><p></p> </li> </ol>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still having issues:</p> <ol> <li>Check the examples for working code</li> <li>Review the API reference</li> <li>Open an issue on GitHub</li> </ol>"},{"location":"validation/","title":"Validation","text":""},{"location":"validation/#validation","title":"Validation","text":"<p>Streamblocks provides a comprehensive validation system for block metadata and content. This guide covers the validation pipeline, built-in validators, and creating custom validation logic.</p>"},{"location":"validation/#overview","title":"Overview","text":"<pre><code>flowchart TB\n    subgraph Parse[\"Parsing Stage\"]\n        ParseMeta[Parse Metadata]\n        ParseContent[Parse Content]\n    end\n\n    subgraph Validate[\"Validation Stage\"]\n        PydanticMeta[Pydantic Metadata Validation]\n        PydanticContent[Pydantic Content Validation]\n        CustomValidators[Custom Validators]\n    end\n\n    subgraph Result[\"Result\"]\n        Success[Block Created]\n        Failure[Block Rejected]\n    end\n\n    ParseMeta --&gt; PydanticMeta\n    ParseContent --&gt; PydanticContent\n\n    PydanticMeta --&gt; CustomValidators\n    PydanticContent --&gt; CustomValidators\n\n    CustomValidators --&gt;|Pass| Success\n    CustomValidators --&gt;|Fail| Failure\n    PydanticMeta --&gt;|Fail| Failure\n    PydanticContent --&gt;|Fail| Failure</code></pre>"},{"location":"validation/#pydantic-validation","title":"Pydantic Validation","text":"<p>Streamblocks uses Pydantic for model validation:</p>"},{"location":"validation/#field-types","title":"Field Types","text":"<pre><code>from streamblocks import BaseMetadata\nfrom typing import Literal\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n\n    # Required fields\n    title: str\n\n    # Optional fields with defaults\n    priority: str = \"normal\"\n    assignee: str | None = None\n\n    # Typed fields\n    tags: list[str] = []\n    due_date: str | None = None\n</code></pre>"},{"location":"validation/#field-validators","title":"Field Validators","text":"<pre><code>from pydantic import field_validator\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\n    @field_validator(\"priority\")\n    @classmethod\n    def validate_priority(cls, v: str) -&gt; str:\n        valid_priorities = {\"low\", \"normal\", \"high\", \"critical\"}\n        if v not in valid_priorities:\n            raise ValueError(f\"priority must be one of {valid_priorities}\")\n        return v\n</code></pre>"},{"location":"validation/#model-validators","title":"Model Validators","text":"<pre><code>from pydantic import model_validator\n\nclass DateRangeMetadata(BaseMetadata):\n    block_type: Literal[\"event\"] = \"event\"\n    start_date: str\n    end_date: str\n\n    @model_validator(mode=\"after\")\n    def validate_dates(self) -&gt; \"DateRangeMetadata\":\n        if self.end_date &lt; self.start_date:\n            raise ValueError(\"end_date must be after start_date\")\n        return self\n</code></pre>"},{"location":"validation/#content-validation","title":"Content Validation","text":""},{"location":"validation/#basic-content-validation","title":"Basic Content Validation","text":"<pre><code>from streamblocks import BaseContent\nfrom pydantic import model_validator\n\nclass JSONContent(BaseContent):\n    data: dict | None = None\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"JSONContent\":\n        import json\n        try:\n            data = json.loads(raw_text)\n        except json.JSONDecodeError:\n            data = None\n        return cls(raw_content=raw_text, data=data)\n\n    @model_validator(mode=\"after\")\n    def validate_json(self) -&gt; \"JSONContent\":\n        if self.raw_content.strip() and self.data is None:\n            raise ValueError(\"Content must be valid JSON\")\n        return self\n</code></pre>"},{"location":"validation/#content-format-validation","title":"Content Format Validation","text":"<pre><code>class CodeContent(BaseContent):\n    language: str = \"text\"\n    is_valid: bool = True\n    syntax_errors: list[str] = []\n\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"CodeContent\":\n        content = cls(raw_content=raw_text)\n\n        # Validate Python syntax\n        if content.language == \"python\":\n            import ast\n            try:\n                ast.parse(raw_text)\n            except SyntaxError as e:\n                content.is_valid = False\n                content.syntax_errors.append(str(e))\n\n        return content\n</code></pre>"},{"location":"validation/#validation-errors","title":"Validation Errors","text":""},{"location":"validation/#blockerrorcode","title":"BlockErrorCode","text":"<pre><code>from streamblocks import BlockErrorCode\n\nclass BlockErrorCode(Enum):\n    \"\"\"Error codes for block rejection.\"\"\"\n\n    INVALID_HEADER = \"invalid_header\"\n    INVALID_METADATA = \"invalid_metadata\"\n    INVALID_CONTENT = \"invalid_content\"\n    VALIDATION_FAILED = \"validation_failed\"\n    MAX_SIZE_EXCEEDED = \"max_size_exceeded\"\n    UNCLOSED_BLOCK = \"unclosed_block\"\n    UNKNOWN_BLOCK_TYPE = \"unknown_block_type\"\n</code></pre>"},{"location":"validation/#blockrejection","title":"BlockRejection","text":"<pre><code>from streamblocks import BlockRejection\n\n@dataclass\nclass BlockRejection:\n    \"\"\"Information about a rejected block.\"\"\"\n\n    reason: BlockErrorCode\n    message: str\n    partial_content: str | None = None\n    line_number: int | None = None\n</code></pre>"},{"location":"validation/#handling-rejections","title":"Handling Rejections","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        rejection = event.rejection\n\n        match rejection.reason:\n            case BlockErrorCode.INVALID_METADATA:\n                logger.warning(f\"Invalid metadata: {rejection.message}\")\n            case BlockErrorCode.INVALID_CONTENT:\n                logger.warning(f\"Invalid content: {rejection.message}\")\n            case BlockErrorCode.MAX_SIZE_EXCEEDED:\n                logger.warning(\"Block too large\")\n            case BlockErrorCode.UNKNOWN_BLOCK_TYPE:\n                logger.warning(f\"Unknown type: {rejection.message}\")\n</code></pre>"},{"location":"validation/#validation-strategies","title":"Validation Strategies","text":""},{"location":"validation/#strict-validation","title":"Strict Validation","text":"<p>Reject any invalid blocks:</p> <pre><code>class StrictMetadata(BaseMetadata):\n    block_type: Literal[\"strict\"] = \"strict\"\n\n    # All required, no defaults\n    title: str\n    description: str\n    category: str\n\n    @field_validator(\"category\")\n    @classmethod\n    def validate_category(cls, v: str) -&gt; str:\n        valid = {\"bug\", \"feature\", \"task\"}\n        if v not in valid:\n            raise ValueError(f\"category must be one of {valid}\")\n        return v\n</code></pre>"},{"location":"validation/#lenient-validation","title":"Lenient Validation","text":"<p>Accept with defaults for missing fields:</p> <pre><code>class LenientMetadata(BaseMetadata):\n    block_type: Literal[\"lenient\"] = \"lenient\"\n\n    # All optional with defaults\n    title: str = \"Untitled\"\n    description: str = \"\"\n    category: str = \"general\"\n\n    @field_validator(\"category\", mode=\"before\")\n    @classmethod\n    def coerce_category(cls, v: str) -&gt; str:\n        valid = {\"bug\", \"feature\", \"task\", \"general\"}\n        return v if v in valid else \"general\"\n</code></pre>"},{"location":"validation/#coercive-validation","title":"Coercive Validation","text":"<p>Transform invalid values:</p> <pre><code>class CoerciveMetadata(BaseMetadata):\n    block_type: Literal[\"coercive\"] = \"coercive\"\n    priority: int = 0\n\n    @field_validator(\"priority\", mode=\"before\")\n    @classmethod\n    def coerce_priority(cls, v) -&gt; int:\n        if isinstance(v, int):\n            return max(0, min(10, v))  # Clamp to 0-10\n        if isinstance(v, str):\n            mapping = {\"low\": 2, \"normal\": 5, \"high\": 8}\n            return mapping.get(v.lower(), 5)\n        return 5  # Default\n</code></pre>"},{"location":"validation/#custom-validators","title":"Custom Validators","text":""},{"location":"validation/#registry-level-validation","title":"Registry-Level Validation","text":"<pre><code>from streamblocks import BlockRegistry\n\nregistry = BlockRegistry()\n\n# Add custom validator\ndef validate_unique_ids(block, context):\n    \"\"\"Ensure block IDs are unique.\"\"\"\n    seen_ids = context.get(\"seen_ids\", set())\n    if block.metadata.id in seen_ids:\n        raise ValueError(f\"Duplicate block ID: {block.metadata.id}\")\n    seen_ids.add(block.metadata.id)\n    context[\"seen_ids\"] = seen_ids\n    return block\n\nregistry.add_validator(validate_unique_ids)\n</code></pre>"},{"location":"validation/#content-type-specific-validation","title":"Content-Type Specific Validation","text":"<pre><code>def validate_code_block(block, context):\n    \"\"\"Validate code blocks have valid syntax.\"\"\"\n    if block.metadata.block_type != \"code\":\n        return block\n\n    content = block.content.raw_content\n    language = block.metadata.language\n\n    if language == \"python\":\n        import ast\n        try:\n            ast.parse(content)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\")\n\n    return block\n\nregistry.add_validator(validate_code_block)\n</code></pre>"},{"location":"validation/#size-validation","title":"Size Validation","text":""},{"location":"validation/#max-block-size","title":"Max Block Size","text":"<pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    max_block_size=100_000,  # 100KB limit\n)\n</code></pre>"},{"location":"validation/#content-length-validation","title":"Content Length Validation","text":"<pre><code>class LimitedContent(BaseContent):\n    MAX_LENGTH = 10_000\n\n    @model_validator(mode=\"after\")\n    def validate_length(self) -&gt; \"LimitedContent\":\n        if len(self.raw_content) &gt; self.MAX_LENGTH:\n            raise ValueError(f\"Content exceeds {self.MAX_LENGTH} characters\")\n        return self\n</code></pre>"},{"location":"validation/#validation-pipeline","title":"Validation Pipeline","text":"<pre><code>sequenceDiagram\n    participant Processor\n    participant Registry\n    participant MetaClass as Metadata Class\n    participant ContentClass as Content Class\n    participant Validators as Custom Validators\n\n    Processor-&gt;&gt;Registry: Get block type\n    Registry-&gt;&gt;Processor: Block classes\n\n    Processor-&gt;&gt;MetaClass: Parse metadata\n    MetaClass-&gt;&gt;MetaClass: Pydantic validation\n    alt Validation fails\n        MetaClass-&gt;&gt;Processor: ValidationError\n        Processor-&gt;&gt;Processor: BLOCK_REJECTED\n    end\n\n    Processor-&gt;&gt;ContentClass: Parse content\n    ContentClass-&gt;&gt;ContentClass: Pydantic validation\n    alt Validation fails\n        ContentClass-&gt;&gt;Processor: ValidationError\n        Processor-&gt;&gt;Processor: BLOCK_REJECTED\n    end\n\n    Processor-&gt;&gt;Validators: Run custom validators\n    alt Validation fails\n        Validators-&gt;&gt;Processor: ValidationError\n        Processor-&gt;&gt;Processor: BLOCK_REJECTED\n    end\n\n    Processor-&gt;&gt;Processor: Create block\n    Processor-&gt;&gt;Processor: BLOCK_EXTRACTED</code></pre>"},{"location":"validation/#error-messages","title":"Error Messages","text":""},{"location":"validation/#descriptive-errors","title":"Descriptive Errors","text":"<pre><code>class TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str\n\n    @field_validator(\"priority\")\n    @classmethod\n    def validate_priority(cls, v: str) -&gt; str:\n        valid = {\"low\", \"normal\", \"high\"}\n        if v not in valid:\n            raise ValueError(\n                f\"Invalid priority '{v}'. \"\n                f\"Must be one of: {', '.join(sorted(valid))}\"\n            )\n        return v\n</code></pre>"},{"location":"validation/#aggregating-errors","title":"Aggregating Errors","text":"<pre><code>from pydantic import ValidationError\n\ntry:\n    metadata = TaskMetadata(id=\"task01\", priority=\"invalid\")\nexcept ValidationError as e:\n    for error in e.errors():\n        field = error[\"loc\"][0]\n        message = error[\"msg\"]\n        print(f\"Field '{field}': {message}\")\n</code></pre>"},{"location":"validation/#best-practices","title":"Best Practices","text":"<p>Fail Fast</p> <p>Validate as early as possible to catch errors quickly.</p> <p>Descriptive Messages</p> <p>Include helpful context in error messages.</p> <p>Use Field Validators</p> <p>Prefer <code>@field_validator</code> for single-field validation.</p> <p>Use Model Validators</p> <p>Use <code>@model_validator</code> for cross-field validation.</p> <p>Test Edge Cases</p> <p>Test with empty, null, and malformed input.</p>"},{"location":"validation/#next-steps","title":"Next Steps","text":"<ul> <li>Events - Event handling</li> <li>Error Handling - Error patterns</li> <li>Blocks - Block definitions</li> </ul>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<p>Streamblocks is designed as a modular, extensible system for real-time extraction of structured blocks from text streams. This document provides a high-level overview of the architecture and how the components work together.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<pre><code>flowchart TB\n    subgraph Providers[\"LLM Providers\"]\n        Gemini[Google Gemini]\n        OpenAI[OpenAI]\n        Anthropic[Anthropic Claude]\n        Custom[Custom Sources]\n    end\n\n    subgraph Extensions[\"Extension Layer\"]\n        GeminiExt[Gemini Extension]\n        OpenAIExt[OpenAI Extension]\n        AnthropicExt[Anthropic Extension]\n        AGUIExt[AG-UI Extension]\n    end\n\n    subgraph Adapters[\"Adapter Layer\"]\n        InputAdapters[Input Adapters]\n        OutputAdapters[Output Adapters]\n    end\n\n    subgraph Core[\"Core Library\"]\n        Processor[StreamBlockProcessor]\n        Registry[BlockRegistry]\n        Syntax[Syntax System]\n        StateMachine[State Machine]\n        Events[Event System]\n        Validation[Validation]\n    end\n\n    subgraph Output[\"Output\"]\n        Blocks[Extracted Blocks]\n        StreamEvents[Stream Events]\n        TextDeltas[Text Deltas]\n    end\n\n    Gemini --&gt; GeminiExt\n    OpenAI --&gt; OpenAIExt\n    Anthropic --&gt; AnthropicExt\n    Custom --&gt; InputAdapters\n\n    GeminiExt --&gt; InputAdapters\n    OpenAIExt --&gt; InputAdapters\n    AnthropicExt --&gt; InputAdapters\n    AGUIExt --&gt; InputAdapters\n    AGUIExt --&gt; OutputAdapters\n\n    InputAdapters --&gt; Processor\n    Processor --&gt; Registry\n    Registry --&gt; Syntax\n    Processor --&gt; StateMachine\n    StateMachine --&gt; Validation\n    Processor --&gt; Events\n    Events --&gt; OutputAdapters\n\n    OutputAdapters --&gt; Blocks\n    OutputAdapters --&gt; StreamEvents\n    OutputAdapters --&gt; TextDeltas</code></pre>"},{"location":"architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/#streamblockprocessor","title":"StreamBlockProcessor","text":"<p>The central processing engine that:</p> <ul> <li>Receives text chunks from adapted streams</li> <li>Accumulates lines for block detection</li> <li>Manages block state transitions</li> <li>Emits events for each processing stage</li> <li>Coordinates validation and output</li> </ul> <pre><code>from streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\n\nregistry = BlockRegistry()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    emit_text_deltas=True,\n)\n\nasync for event in processor.process_stream(stream):\n    handle_event(event)\n</code></pre>"},{"location":"architecture/#blockregistry","title":"BlockRegistry","text":"<p>Manages registered block types and their handlers:</p> <ul> <li>Stores metadata and content class mappings</li> <li>Provides priority-based type resolution</li> <li>Supports custom block type registration</li> <li>Handles default block fallback</li> </ul>"},{"location":"architecture/#syntax-system","title":"Syntax System","text":"<p>Defines how blocks are detected and parsed:</p> <ul> <li>DelimiterPreamble: <code>!!id:type\\ncontent\\n!!end</code></li> <li>DelimiterFrontmatter: Delimiters with YAML frontmatter</li> <li>MarkdownFrontmatter: Code fences with YAML metadata</li> </ul>"},{"location":"architecture/#event-system","title":"Event System","text":"<p>Provides real-time notifications:</p> Event Type Description <code>STREAM_START</code> Stream processing begins <code>TEXT_DELTA</code> Raw text chunk received <code>BLOCK_OPENED</code> Block start detected <code>BLOCK_CONTENT</code> Block content accumulated <code>BLOCK_EXTRACTED</code> Complete block parsed <code>BLOCK_REJECTED</code> Block validation failed <code>STREAM_END</code> Stream processing complete"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<pre><code>flowchart LR\n    subgraph Input[\"Input Stage\"]\n        RawStream[Raw Stream]\n        Adapter[Input Adapter]\n        TextChunks[Text Chunks]\n    end\n\n    subgraph Processing[\"Processing Stage\"]\n        Accumulator[Line Accumulator]\n        Detector[Block Detector]\n        Parser[Block Parser]\n        Validator[Validator]\n    end\n\n    subgraph Output[\"Output Stage\"]\n        Events[Events]\n        Blocks[Blocks]\n    end\n\n    RawStream --&gt; Adapter\n    Adapter --&gt; TextChunks\n    TextChunks --&gt; Accumulator\n    Accumulator --&gt; Detector\n    Detector --&gt; Parser\n    Parser --&gt; Validator\n    Validator --&gt; Events\n    Validator --&gt; Blocks</code></pre>"},{"location":"architecture/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>Adaptation: Provider-specific streams are normalized to text chunks</li> <li>Accumulation: Text is accumulated into complete lines</li> <li>Detection: Lines are checked for block markers</li> <li>Parsing: Block content is parsed according to syntax</li> <li>Validation: Metadata and content are validated</li> <li>Emission: Events are emitted for each stage</li> </ol>"},{"location":"architecture/#extension-architecture","title":"Extension Architecture","text":"<p>Streamblocks uses an extension system for provider-specific functionality:</p> <pre><code>flowchart TB\n    subgraph Core[\"streamblocks\"]\n        BaseAdapter[BaseInputAdapter]\n        BaseOutput[BaseOutputAdapter]\n        Protocol[Adapter Protocol]\n    end\n\n    subgraph GeminiPkg[\"streamblocks.ext.gemini\"]\n        GeminiAdapter[GeminiInputAdapter]\n        GeminiTypes[Gemini Types]\n    end\n\n    subgraph OpenAIPkg[\"streamblocks.ext.openai\"]\n        OpenAIAdapter[OpenAIInputAdapter]\n        OpenAITypes[OpenAI Types]\n    end\n\n    subgraph AnthropicPkg[\"streamblocks.ext.anthropic\"]\n        AnthropicAdapter[AnthropicInputAdapter]\n        AnthropicTypes[Anthropic Types]\n    end\n\n    subgraph AGUIPkg[\"streamblocks.ext.agui\"]\n        AGUIInput[AGUIInputAdapter]\n        AGUIOutput[AGUIOutputAdapter]\n        AGUITypes[AG-UI Events]\n    end\n\n    Protocol --&gt; GeminiAdapter\n    Protocol --&gt; OpenAIAdapter\n    Protocol --&gt; AnthropicAdapter\n    Protocol --&gt; AGUIInput\n    Protocol --&gt; AGUIOutput\n\n    BaseAdapter --&gt; GeminiAdapter\n    BaseAdapter --&gt; OpenAIAdapter\n    BaseAdapter --&gt; AnthropicAdapter\n    BaseAdapter --&gt; AGUIInput\n    BaseOutput --&gt; AGUIOutput</code></pre> <p>Each extension:</p> <ul> <li>Implements the adapter protocol</li> <li>Handles provider-specific event formats</li> <li>Provides type definitions for provider events</li> <li>Can be installed independently via extras</li> </ul>"},{"location":"architecture/#configuration-layers","title":"Configuration Layers","text":"<pre><code>flowchart TB\n    subgraph Config[\"Configuration\"]\n        ProcessorConfig[Processor Config]\n        RegistryConfig[Registry Config]\n        SyntaxConfig[Syntax Config]\n        ValidationConfig[Validation Config]\n    end\n\n    subgraph Processor[\"StreamBlockProcessor\"]\n        EmitTextDeltas[emit_text_deltas]\n        EmitBlockContent[emit_block_content]\n        EmitOriginal[emit_original_events]\n        MaxBlockSize[max_block_size]\n    end\n\n    subgraph Registry[\"BlockRegistry\"]\n        BlockTypes[Block Types]\n        Priorities[Priorities]\n        DefaultBlock[Default Block]\n    end\n\n    subgraph Syntax[\"Syntax\"]\n        Delimiters[Delimiters]\n        Frontmatter[Frontmatter Format]\n        CustomParsers[Custom Parsers]\n    end\n\n    ProcessorConfig --&gt; EmitTextDeltas\n    ProcessorConfig --&gt; EmitBlockContent\n    ProcessorConfig --&gt; EmitOriginal\n    ProcessorConfig --&gt; MaxBlockSize\n\n    RegistryConfig --&gt; BlockTypes\n    RegistryConfig --&gt; Priorities\n    RegistryConfig --&gt; DefaultBlock\n\n    SyntaxConfig --&gt; Delimiters\n    SyntaxConfig --&gt; Frontmatter\n    SyntaxConfig --&gt; CustomParsers</code></pre>"},{"location":"architecture/#design-principles","title":"Design Principles","text":""},{"location":"architecture/#1-streaming-first","title":"1. Streaming-First","text":"<p>Everything is designed for real-time processing:</p> <ul> <li>Events are emitted as soon as possible</li> <li>No buffering of complete responses</li> <li>Backpressure-aware async generators</li> </ul>"},{"location":"architecture/#2-protocol-based-extensibility","title":"2. Protocol-Based Extensibility","text":"<p>Adapters follow protocols, not inheritance:</p> <pre><code>class InputAdapter(Protocol):\n    def categorize(self, event: Any) -&gt; EventCategory: ...\n    def extract_text(self, event: Any) -&gt; str: ...\n</code></pre>"},{"location":"architecture/#3-type-safety","title":"3. Type Safety","text":"<p>Full type annotations throughout:</p> <ul> <li>Generic block types</li> <li>Protocol-based adapters</li> <li>Validated Pydantic models</li> </ul>"},{"location":"architecture/#4-zero-dependencies-core","title":"4. Zero Dependencies Core","text":"<p>Core library has minimal dependencies:</p> <ul> <li><code>pydantic</code> for validation</li> <li>Standard library for everything else</li> <li>Provider SDKs are optional extras</li> </ul>"},{"location":"architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Extension System - Deep dive into extensions</li> <li>State Machine - Block detection internals</li> <li>Adapter Protocol - Creating custom adapters</li> </ul>"},{"location":"architecture/adapters/","title":"Adapter Protocol","text":""},{"location":"architecture/adapters/#adapter-protocol","title":"Adapter Protocol","text":"<p>Streamblocks uses adapters to normalize diverse input streams and transform output events. This document details the adapter protocols and how to implement custom adapters.</p>"},{"location":"architecture/adapters/#overview","title":"Overview","text":"<pre><code>flowchart LR\n    subgraph Providers[\"Provider Streams\"]\n        Gemini[Gemini Stream]\n        OpenAI[OpenAI Stream]\n        Anthropic[Anthropic Stream]\n        Custom[Custom Stream]\n    end\n\n    subgraph Input[\"Input Adapters\"]\n        GeminiIn[Gemini Adapter]\n        OpenAIIn[OpenAI Adapter]\n        AnthropicIn[Anthropic Adapter]\n        CustomIn[Custom Adapter]\n    end\n\n    subgraph Core[\"Core Processing\"]\n        Processor[StreamBlockProcessor]\n    end\n\n    subgraph Output[\"Output Adapters\"]\n        AGUI[AG-UI Adapter]\n        JSON[JSON Adapter]\n        CustomOut[Custom Adapter]\n    end\n\n    subgraph Clients[\"Clients\"]\n        AGUIClient[AG-UI Client]\n        APIClient[API Client]\n        CustomClient[Custom Client]\n    end\n\n    Gemini --&gt; GeminiIn\n    OpenAI --&gt; OpenAIIn\n    Anthropic --&gt; AnthropicIn\n    Custom --&gt; CustomIn\n\n    GeminiIn --&gt; Processor\n    OpenAIIn --&gt; Processor\n    AnthropicIn --&gt; Processor\n    CustomIn --&gt; Processor\n\n    Processor --&gt; AGUI\n    Processor --&gt; JSON\n    Processor --&gt; CustomOut\n\n    AGUI --&gt; AGUIClient\n    JSON --&gt; APIClient\n    CustomOut --&gt; CustomClient</code></pre>"},{"location":"architecture/adapters/#input-adapter-protocol","title":"Input Adapter Protocol","text":"<p>Input adapters normalize provider-specific events to text chunks:</p> <pre><code>from typing import Any, Protocol\nfrom streamblocks.adapters import EventCategory\n\nclass InputAdapter(Protocol):\n    \"\"\"Protocol for input stream adapters.\"\"\"\n\n    def categorize(self, event: Any) -&gt; EventCategory:\n        \"\"\"Categorize an incoming event.\n\n        Args:\n            event: Raw event from the provider stream\n\n        Returns:\n            EventCategory indicating how to handle the event\n        \"\"\"\n        ...\n\n    def extract_text(self, event: Any) -&gt; str:\n        \"\"\"Extract text content from a TEXT_CONTENT event.\n\n        Args:\n            event: Raw event that was categorized as TEXT_CONTENT\n\n        Returns:\n            The text content from the event\n        \"\"\"\n        ...\n</code></pre>"},{"location":"architecture/adapters/#event-categories","title":"Event Categories","text":"<pre><code>class EventCategory(Enum):\n    \"\"\"Categories for incoming events.\"\"\"\n\n    TEXT_CONTENT = \"text_content\"\n    \"\"\"Event contains text to process.\"\"\"\n\n    PASSTHROUGH = \"passthrough\"\n    \"\"\"Pass event through unchanged to output.\"\"\"\n\n    SKIP = \"skip\"\n    \"\"\"Ignore this event entirely.\"\"\"\n\n    STREAM_START = \"stream_start\"\n    \"\"\"Stream is starting.\"\"\"\n\n    STREAM_END = \"stream_end\"\n    \"\"\"Stream is ending.\"\"\"\n</code></pre>"},{"location":"architecture/adapters/#processing-flow","title":"Processing Flow","text":"<pre><code>sequenceDiagram\n    participant Provider as Provider Stream\n    participant Adapter as Input Adapter\n    participant Processor as StreamBlockProcessor\n    participant Handler as Event Handler\n\n    loop For each event\n        Provider-&gt;&gt;Adapter: Raw event\n\n        Adapter-&gt;&gt;Adapter: categorize(event)\n\n        alt TEXT_CONTENT\n            Adapter-&gt;&gt;Adapter: extract_text(event)\n            Adapter-&gt;&gt;Processor: Text chunk\n            Processor-&gt;&gt;Processor: Process lines\n            Processor-&gt;&gt;Handler: StreamEvent(s)\n        else PASSTHROUGH\n            Adapter-&gt;&gt;Handler: Original event\n        else SKIP\n            Note over Adapter: Event discarded\n        else STREAM_START\n            Processor-&gt;&gt;Handler: STREAM_START event\n        else STREAM_END\n            Processor-&gt;&gt;Processor: Flush buffers\n            Processor-&gt;&gt;Handler: STREAM_END event\n        end\n    end</code></pre>"},{"location":"architecture/adapters/#output-adapter-protocol","title":"Output Adapter Protocol","text":"<p>Output adapters transform Streamblocks events to protocol-specific formats:</p> <pre><code>from typing import Any, Protocol\nfrom streamblocks import StreamEvent\n\nclass OutputAdapter(Protocol):\n    \"\"\"Protocol for output stream adapters.\"\"\"\n\n    def to_protocol_event(self, event: StreamEvent) -&gt; Any:\n        \"\"\"Convert a Streamblocks event to protocol format.\n\n        Args:\n            event: Streamblocks event to convert\n\n        Returns:\n            Protocol-specific event representation\n        \"\"\"\n        ...\n\n    def passthrough(self, event: Any) -&gt; Any:\n        \"\"\"Handle a passthrough event.\n\n        Args:\n            event: Original event from input\n\n        Returns:\n            Event to emit (may be transformed or unchanged)\n        \"\"\"\n        ...\n</code></pre>"},{"location":"architecture/adapters/#output-flow","title":"Output Flow","text":"<pre><code>sequenceDiagram\n    participant Processor as StreamBlockProcessor\n    participant OutAdapter as Output Adapter\n    participant Client as Client\n\n    Processor-&gt;&gt;OutAdapter: StreamEvent\n    OutAdapter-&gt;&gt;OutAdapter: to_protocol_event(event)\n    OutAdapter-&gt;&gt;Client: Protocol event\n\n    Note over Processor,Client: Passthrough events\n\n    Processor-&gt;&gt;OutAdapter: Original event (passthrough)\n    OutAdapter-&gt;&gt;OutAdapter: passthrough(event)\n    OutAdapter-&gt;&gt;Client: Transformed event</code></pre>"},{"location":"architecture/adapters/#built-in-adapters","title":"Built-in Adapters","text":""},{"location":"architecture/adapters/#identity-adapter","title":"Identity Adapter","text":"<p>The default adapter for plain text streams:</p> <pre><code>class IdentityInputAdapter:\n    \"\"\"Adapter for plain text streams.\"\"\"\n\n    def categorize(self, event: Any) -&gt; EventCategory:\n        if isinstance(event, str):\n            return EventCategory.TEXT_CONTENT\n        return EventCategory.SKIP\n\n    def extract_text(self, event: Any) -&gt; str:\n        return str(event)\n</code></pre>"},{"location":"architecture/adapters/#callable-adapter","title":"Callable Adapter","text":"<p>Use a simple function as an adapter:</p> <pre><code>def my_adapter(event):\n    \"\"\"Extract text from custom events.\"\"\"\n    if hasattr(event, \"text\"):\n        return event.text\n    return \"\"\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=my_adapter,\n)\n</code></pre>"},{"location":"architecture/adapters/#attribute-adapter","title":"Attribute Adapter","text":"<p>Generic adapter that extracts from an attribute:</p> <pre><code>from streamblocks.adapters import AttributeAdapter\n\n# Extract from 'content' attribute\nadapter = AttributeAdapter(attribute=\"content\")\n\n# Extract from nested attribute\nadapter = AttributeAdapter(attribute=\"data.text\")\n</code></pre>"},{"location":"architecture/adapters/#custom-input-adapter","title":"Custom Input Adapter","text":""},{"location":"architecture/adapters/#basic-example","title":"Basic Example","text":"<pre><code>from streamblocks.adapters import EventCategory\n\nclass MyProviderAdapter:\n    \"\"\"Adapter for MyProvider streaming API.\"\"\"\n\n    def categorize(self, event) -&gt; EventCategory:\n        # Check event type\n        if hasattr(event, \"type\"):\n            if event.type == \"content\":\n                return EventCategory.TEXT_CONTENT\n            elif event.type == \"start\":\n                return EventCategory.STREAM_START\n            elif event.type == \"end\":\n                return EventCategory.STREAM_END\n            elif event.type == \"metadata\":\n                return EventCategory.PASSTHROUGH\n\n        return EventCategory.SKIP\n\n    def extract_text(self, event) -&gt; str:\n        # Extract text from content event\n        if hasattr(event, \"content\"):\n            return event.content\n        return \"\"\n</code></pre>"},{"location":"architecture/adapters/#stateful-adapter","title":"Stateful Adapter","text":"<p>For adapters that need to track state:</p> <pre><code>class StatefulAdapter:\n    \"\"\"Adapter with internal state tracking.\"\"\"\n\n    def __init__(self):\n        self.chunk_count = 0\n        self.total_chars = 0\n        self.started = False\n\n    def categorize(self, event) -&gt; EventCategory:\n        if event.type == \"delta\":\n            self.chunk_count += 1\n            return EventCategory.TEXT_CONTENT\n        elif event.type == \"done\":\n            return EventCategory.STREAM_END\n        return EventCategory.SKIP\n\n    def extract_text(self, event) -&gt; str:\n        text = event.text or \"\"\n        self.total_chars += len(text)\n        return text\n\n    def get_stats(self) -&gt; dict:\n        return {\n            \"chunks\": self.chunk_count,\n            \"total_chars\": self.total_chars,\n        }\n</code></pre>"},{"location":"architecture/adapters/#filtering-adapter","title":"Filtering Adapter","text":"<p>Filter events based on criteria:</p> <pre><code>class FilteringAdapter:\n    \"\"\"Adapter that filters events.\"\"\"\n\n    def __init__(self, include_types: set[str]):\n        self.include_types = include_types\n\n    def categorize(self, event) -&gt; EventCategory:\n        if event.type not in self.include_types:\n            return EventCategory.SKIP\n\n        if event.type == \"text\":\n            return EventCategory.TEXT_CONTENT\n\n        return EventCategory.PASSTHROUGH\n\n    def extract_text(self, event) -&gt; str:\n        return event.content\n</code></pre>"},{"location":"architecture/adapters/#custom-output-adapter","title":"Custom Output Adapter","text":""},{"location":"architecture/adapters/#json-output","title":"JSON Output","text":"<pre><code>import json\nfrom streamblocks import StreamEvent, EventType\n\nclass JSONOutputAdapter:\n    \"\"\"Convert events to JSON format.\"\"\"\n\n    def to_protocol_event(self, event: StreamEvent) -&gt; dict:\n        base = {\n            \"type\": event.type.name,\n            \"timestamp\": event.timestamp.isoformat(),\n        }\n\n        if event.type == EventType.BLOCK_EXTRACTED:\n            base[\"block\"] = {\n                \"id\": event.block.metadata.id,\n                \"type\": event.block.metadata.block_type,\n                \"content\": event.block.content.raw_content,\n            }\n        elif event.type == EventType.TEXT_DELTA:\n            base[\"text\"] = event.text\n        elif event.type == EventType.BLOCK_REJECTED:\n            base[\"rejection\"] = {\n                \"reason\": event.rejection.reason.value,\n                \"message\": event.rejection.message,\n            }\n\n        return base\n\n    def passthrough(self, event) -&gt; dict:\n        # Convert any event to JSON-serializable dict\n        return {\"type\": \"passthrough\", \"data\": str(event)}\n</code></pre>"},{"location":"architecture/adapters/#sse-output","title":"SSE Output","text":"<pre><code>class SSEOutputAdapter:\n    \"\"\"Convert events to Server-Sent Events format.\"\"\"\n\n    def to_protocol_event(self, event: StreamEvent) -&gt; str:\n        data = json.dumps(self._serialize(event))\n        return f\"event: {event.type.name}\\ndata: {data}\\n\\n\"\n\n    def _serialize(self, event: StreamEvent) -&gt; dict:\n        # Convert to JSON-serializable dict\n        ...\n\n    def passthrough(self, event) -&gt; str:\n        return f\"event: passthrough\\ndata: {event}\\n\\n\"\n</code></pre>"},{"location":"architecture/adapters/#adapter-selection","title":"Adapter Selection","text":""},{"location":"architecture/adapters/#auto-detection","title":"Auto-Detection","text":"<pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=\"auto\",  # Detect from first event\n)\n\nasync for event in processor.process_stream(stream):\n    # First event triggers adapter selection\n    ...\n</code></pre> <p>Auto-detection tries adapters in order:</p> <ol> <li>Gemini adapter (if installed)</li> <li>OpenAI adapter (if installed)</li> <li>Anthropic adapter (if installed)</li> <li>Identity adapter (fallback)</li> </ol>"},{"location":"architecture/adapters/#explicit-selection","title":"Explicit Selection","text":"<pre><code>from streamblocks.ext.gemini import GeminiInputAdapter\n\nadapter = GeminiInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n</code></pre>"},{"location":"architecture/adapters/#bidirectional-adapters","title":"Bidirectional Adapters","text":"<p>Some protocols need both input and output adaptation:</p> <pre><code>flowchart TB\n    subgraph Protocol[\"AG-UI Protocol\"]\n        Incoming[Incoming Events]\n        Outgoing[Outgoing Events]\n    end\n\n    subgraph Adapter[\"Bidirectional Adapter\"]\n        InputSide[Input Adapter]\n        OutputSide[Output Adapter]\n    end\n\n    subgraph Core[\"Streamblocks\"]\n        Processor[Processor]\n    end\n\n    Incoming --&gt; InputSide\n    InputSide --&gt; Processor\n    Processor --&gt; OutputSide\n    OutputSide --&gt; Outgoing</code></pre> <pre><code>class BidirectionalAdapter:\n    \"\"\"Combined input and output adapter.\"\"\"\n\n    def __init__(self):\n        self.input = MyInputAdapter()\n        self.output = MyOutputAdapter()\n\n    # Delegate to respective adapters\n    def categorize(self, event):\n        return self.input.categorize(event)\n\n    def extract_text(self, event):\n        return self.input.extract_text(event)\n\n    def to_protocol_event(self, event):\n        return self.output.to_protocol_event(event)\n\n    def passthrough(self, event):\n        return self.output.passthrough(event)\n</code></pre>"},{"location":"architecture/adapters/#best-practices","title":"Best Practices","text":"<p>Handle All Event Types</p> <p>Always return a valid category for any event. Use <code>SKIP</code> for unrecognized events.</p> <p>Preserve Streaming Semantics</p> <p>Don't buffer too much. Return text as soon as it's available.</p> <p>Be Defensive</p> <p>Check for <code>None</code> values and missing attributes. Provider APIs may vary.</p> <p>Log for Debugging</p> <p>Add logging to help debug adapter issues:</p> <pre><code>import structlog\nlogger = structlog.get_logger()\n\ndef categorize(self, event):\n    category = self._determine_category(event)\n    logger.debug(\"adapter.categorize\", event_type=type(event), category=category)\n    return category\n</code></pre> <p>Test with Real Streams</p> <p>Test adapters with actual provider streams, not just mock data.</p>"},{"location":"architecture/adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Extension System - Provider extensions</li> <li>State Machine - Block processing internals</li> <li>API Reference - Adapter API details</li> </ul>"},{"location":"architecture/extensions/","title":"Extension System","text":""},{"location":"architecture/extensions/#extension-system","title":"Extension System","text":"<p>Streamblocks uses a modular extension architecture to support multiple LLM providers and output protocols. This design keeps the core library lightweight while enabling rich integrations.</p>"},{"location":"architecture/extensions/#overview","title":"Overview","text":"<pre><code>flowchart TB\n    subgraph Core[\"Core Package: streamblocks\"]\n        Processor[StreamBlockProcessor]\n        Registry[BlockRegistry]\n        Syntax[Syntax]\n        Events[Events]\n        BaseAdapter[Base Adapters]\n    end\n\n    subgraph Extras[\"Optional Extras\"]\n        GeminiExt[\"streamblocks[gemini]\"]\n        OpenAIExt[\"streamblocks[openai]\"]\n        AnthropicExt[\"streamblocks[anthropic]\"]\n        AGUIExt[\"streamblocks[agui]\"]\n    end\n\n    subgraph ExtModules[\"Extension Modules\"]\n        GeminiMod[streamblocks.ext.gemini]\n        OpenAIMod[streamblocks.ext.openai]\n        AnthropicMod[streamblocks.ext.anthropic]\n        AGUIMod[streamblocks.ext.agui]\n    end\n\n    Core --&gt; GeminiExt\n    Core --&gt; OpenAIExt\n    Core --&gt; AnthropicExt\n    Core --&gt; AGUIExt\n\n    GeminiExt --&gt; GeminiMod\n    OpenAIExt --&gt; OpenAIMod\n    AnthropicExt --&gt; AnthropicMod\n    AGUIExt --&gt; AGUIMod</code></pre>"},{"location":"architecture/extensions/#extension-structure","title":"Extension Structure","text":"<p>Each extension follows a consistent structure:</p> <pre><code>streamblocks/\n\u251c\u2500\u2500 ext/\n\u2502   \u251c\u2500\u2500 gemini/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py      # Public exports\n\u2502   \u2502   \u251c\u2500\u2500 adapter.py       # Input adapter\n\u2502   \u2502   \u2514\u2500\u2500 types.py         # Provider types\n\u2502   \u251c\u2500\u2500 openai/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 adapter.py\n\u2502   \u2502   \u2514\u2500\u2500 types.py\n\u2502   \u251c\u2500\u2500 anthropic/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 adapter.py\n\u2502   \u2502   \u2514\u2500\u2500 types.py\n\u2502   \u2514\u2500\u2500 agui/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 input_adapter.py  # Input adapter\n\u2502       \u251c\u2500\u2500 output_adapter.py # Output adapter\n\u2502       \u2514\u2500\u2500 types.py\n</code></pre>"},{"location":"architecture/extensions/#adapter-protocol","title":"Adapter Protocol","text":"<p>Extensions implement the adapter protocol to integrate with the core processor:</p> <pre><code>classDiagram\n    class InputAdapter {\n        &lt;&lt;protocol&gt;&gt;\n        +categorize(event: Any) EventCategory\n        +extract_text(event: Any) str\n    }\n\n    class OutputAdapter {\n        &lt;&lt;protocol&gt;&gt;\n        +to_protocol_event(event: StreamEvent) Any\n        +passthrough(event: Any) Any\n    }\n\n    class GeminiInputAdapter {\n        +categorize(event) EventCategory\n        +extract_text(event) str\n    }\n\n    class OpenAIInputAdapter {\n        +categorize(event) EventCategory\n        +extract_text(event) str\n    }\n\n    class AnthropicInputAdapter {\n        +categorize(event) EventCategory\n        +extract_text(event) str\n    }\n\n    class AGUIInputAdapter {\n        +categorize(event) EventCategory\n        +extract_text(event) str\n    }\n\n    class AGUIOutputAdapter {\n        +to_protocol_event(event) AGUIEvent\n        +passthrough(event) AGUIEvent\n    }\n\n    InputAdapter &lt;|.. GeminiInputAdapter\n    InputAdapter &lt;|.. OpenAIInputAdapter\n    InputAdapter &lt;|.. AnthropicInputAdapter\n    InputAdapter &lt;|.. AGUIInputAdapter\n    OutputAdapter &lt;|.. AGUIOutputAdapter</code></pre>"},{"location":"architecture/extensions/#event-categories","title":"Event Categories","text":"<p>Input adapters categorize incoming events:</p> <pre><code>class EventCategory(Enum):\n    \"\"\"Categories for incoming events.\"\"\"\n\n    TEXT_CONTENT = \"text_content\"      # Contains extractable text\n    PASSTHROUGH = \"passthrough\"        # Pass through unchanged\n    SKIP = \"skip\"                      # Ignore this event\n    STREAM_START = \"stream_start\"      # Stream is starting\n    STREAM_END = \"stream_end\"          # Stream is ending\n</code></pre>"},{"location":"architecture/extensions/#categorization-flow","title":"Categorization Flow","text":"<pre><code>sequenceDiagram\n    participant Provider as LLM Provider\n    participant Adapter as Input Adapter\n    participant Processor as StreamBlockProcessor\n    participant Output as Output\n\n    Provider-&gt;&gt;Adapter: Raw event\n    Adapter-&gt;&gt;Adapter: categorize(event)\n\n    alt TEXT_CONTENT\n        Adapter-&gt;&gt;Adapter: extract_text(event)\n        Adapter-&gt;&gt;Processor: text chunk\n        Processor-&gt;&gt;Output: StreamEvent\n    else PASSTHROUGH\n        Adapter-&gt;&gt;Output: Original event\n    else SKIP\n        Note over Adapter: Event discarded\n    else STREAM_START\n        Adapter-&gt;&gt;Processor: Signal start\n        Processor-&gt;&gt;Output: STREAM_START event\n    else STREAM_END\n        Adapter-&gt;&gt;Processor: Signal end\n        Processor-&gt;&gt;Output: STREAM_END event\n    end</code></pre>"},{"location":"architecture/extensions/#provider-extensions","title":"Provider Extensions","text":""},{"location":"architecture/extensions/#gemini-extension","title":"Gemini Extension","text":"<p>Handles Google Gemini API responses:</p> <pre><code>from streamblocks.ext.gemini import GeminiInputAdapter\n\n# Automatic adapter selection\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=\"auto\",  # Detects Gemini events\n)\n\n# Explicit adapter\nadapter = GeminiInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n</code></pre> <p>Event handling:</p> Gemini Event Category Action <code>GenerateContentResponse</code> TEXT_CONTENT Extract text from candidates Stream start STREAM_START Initialize processing Stream end STREAM_END Finalize processing"},{"location":"architecture/extensions/#openai-extension","title":"OpenAI Extension","text":"<p>Handles OpenAI API streaming responses:</p> <pre><code>from streamblocks.ext.openai import OpenAIInputAdapter\n\nadapter = OpenAIInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n</code></pre> <p>Event handling:</p> OpenAI Event Category Action <code>ChatCompletionChunk</code> TEXT_CONTENT Extract delta content <code>[DONE]</code> STREAM_END Finalize processing"},{"location":"architecture/extensions/#anthropic-extension","title":"Anthropic Extension","text":"<p>Handles Anthropic Claude streaming events:</p> <pre><code>from streamblocks.ext.anthropic import AnthropicInputAdapter\n\nadapter = AnthropicInputAdapter()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=adapter,\n)\n</code></pre> <p>Event handling:</p> Anthropic Event Category Action <code>ContentBlockDelta</code> TEXT_CONTENT Extract text delta <code>MessageStart</code> STREAM_START Initialize <code>MessageStop</code> STREAM_END Finalize <code>ContentBlockStart/Stop</code> SKIP Internal events"},{"location":"architecture/extensions/#ag-ui-extension","title":"AG-UI Extension","text":"<p>Bidirectional adapter for the AG-UI protocol:</p> <pre><code>from streamblocks.ext.agui import AGUIInputAdapter, AGUIOutputAdapter\n\ninput_adapter = AGUIInputAdapter()\noutput_adapter = AGUIOutputAdapter()\n\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    input_adapter=input_adapter,\n    output_adapter=output_adapter,\n)\n</code></pre> <pre><code>flowchart LR\n    subgraph AGUI[\"AG-UI Protocol\"]\n        AGUIIn[Incoming Events]\n        AGUIOut[Outgoing Events]\n    end\n\n    subgraph Streamblocks[\"Streamblocks\"]\n        Input[AGUIInputAdapter]\n        Processor[Processor]\n        Output[AGUIOutputAdapter]\n    end\n\n    AGUIIn --&gt; Input\n    Input --&gt; Processor\n    Processor --&gt; Output\n    Output --&gt; AGUIOut</code></pre>"},{"location":"architecture/extensions/#creating-custom-extensions","title":"Creating Custom Extensions","text":""},{"location":"architecture/extensions/#step-1-define-types","title":"Step 1: Define Types","text":"<pre><code># my_extension/types.py\nfrom dataclasses import dataclass\nfrom typing import Any\n\n@dataclass\nclass MyProviderEvent:\n    \"\"\"Event from my provider.\"\"\"\n    type: str\n    content: str | None\n    metadata: dict[str, Any]\n</code></pre>"},{"location":"architecture/extensions/#step-2-implement-input-adapter","title":"Step 2: Implement Input Adapter","text":"<pre><code># my_extension/adapter.py\nfrom streamblocks.adapters import EventCategory\n\nclass MyProviderInputAdapter:\n    \"\"\"Input adapter for my provider.\"\"\"\n\n    def categorize(self, event: Any) -&gt; EventCategory:\n        \"\"\"Categorize an incoming event.\"\"\"\n        if isinstance(event, MyProviderEvent):\n            if event.type == \"content\":\n                return EventCategory.TEXT_CONTENT\n            elif event.type == \"start\":\n                return EventCategory.STREAM_START\n            elif event.type == \"end\":\n                return EventCategory.STREAM_END\n        return EventCategory.SKIP\n\n    def extract_text(self, event: Any) -&gt; str:\n        \"\"\"Extract text from a TEXT_CONTENT event.\"\"\"\n        if isinstance(event, MyProviderEvent):\n            return event.content or \"\"\n        return \"\"\n</code></pre>"},{"location":"architecture/extensions/#step-3-register-as-extra-optional","title":"Step 3: Register as Extra (Optional)","text":"<p>In <code>pyproject.toml</code>:</p> <pre><code>[project.optional-dependencies]\nmy-provider = [\"my-provider-sdk&gt;=1.0\"]\n\n[project.entry-points.\"streamblocks.adapters\"]\nmy-provider = \"my_extension:MyProviderInputAdapter\"\n</code></pre>"},{"location":"architecture/extensions/#extension-loading","title":"Extension Loading","text":"<p>Extensions are loaded on-demand:</p> <pre><code>flowchart TB\n    subgraph Import[\"Import Stage\"]\n        Core[import streamblocks]\n        CheckExtra{Extra installed?}\n        LoadExt[Load extension]\n        Skip[Skip extension]\n    end\n\n    subgraph Use[\"Usage Stage\"]\n        CreateProcessor[Create processor]\n        AutoDetect{Auto-detect?}\n        TryAdapters[Try registered adapters]\n        UseAdapter[Use matching adapter]\n        UseIdentity[Use identity adapter]\n    end\n\n    Core --&gt; CheckExtra\n    CheckExtra --&gt;|Yes| LoadExt\n    CheckExtra --&gt;|No| Skip\n\n    CreateProcessor --&gt; AutoDetect\n    AutoDetect --&gt;|Yes| TryAdapters\n    AutoDetect --&gt;|No| UseAdapter\n    TryAdapters --&gt;|Match| UseAdapter\n    TryAdapters --&gt;|No match| UseIdentity</code></pre>"},{"location":"architecture/extensions/#best-practices","title":"Best Practices","text":"<p>Keep Extensions Focused</p> <p>Each extension should handle one provider. Don't combine multiple providers in a single extension.</p> <p>Use Protocol, Not Inheritance</p> <p>Implement the adapter protocol rather than inheriting from base classes. This keeps extensions decoupled.</p> <p>Handle Unknown Events Gracefully</p> <p>Return <code>EventCategory.SKIP</code> for unrecognized events rather than raising errors.</p> <p>Document Event Mappings</p> <p>Clearly document how provider events map to Streamblocks events.</p>"},{"location":"architecture/extensions/#next-steps","title":"Next Steps","text":"<ul> <li>State Machine - Block detection internals</li> <li>Adapter Protocol - Detailed adapter documentation</li> <li>API Reference - Extension API details</li> </ul>"},{"location":"architecture/state-machine/","title":"State Machine","text":""},{"location":"architecture/state-machine/#block-state-machine","title":"Block State Machine","text":"<p>Streamblocks uses a state machine to track block detection and extraction. This document explains the states, transitions, and internal workings of the block processing system.</p>"},{"location":"architecture/state-machine/#state-overview","title":"State Overview","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; SEARCHING: Start processing\n\n    SEARCHING --&gt; HEADER_DETECTED: Start marker found\n    SEARCHING --&gt; SEARCHING: Regular text line\n\n    HEADER_DETECTED --&gt; ACCUMULATING_METADATA: Has frontmatter\n    HEADER_DETECTED --&gt; ACCUMULATING_CONTENT: No frontmatter\n    HEADER_DETECTED --&gt; REJECTED: Invalid header\n\n    ACCUMULATING_METADATA --&gt; ACCUMULATING_CONTENT: Metadata complete\n    ACCUMULATING_METADATA --&gt; REJECTED: Invalid metadata\n\n    ACCUMULATING_CONTENT --&gt; CLOSING_DETECTED: End marker found\n    ACCUMULATING_CONTENT --&gt; ACCUMULATING_CONTENT: Content line\n    ACCUMULATING_CONTENT --&gt; REJECTED: Max size exceeded\n\n    CLOSING_DETECTED --&gt; COMPLETED: Validation passed\n    CLOSING_DETECTED --&gt; REJECTED: Validation failed\n\n    COMPLETED --&gt; SEARCHING: Continue processing\n    REJECTED --&gt; SEARCHING: Continue processing\n\n    COMPLETED --&gt; [*]: Stream ends\n    REJECTED --&gt; [*]: Stream ends\n    SEARCHING --&gt; [*]: Stream ends</code></pre>"},{"location":"architecture/state-machine/#states","title":"States","text":""},{"location":"architecture/state-machine/#searching","title":"SEARCHING","text":"<p>The initial and default state. The processor scans lines looking for block start markers.</p> <pre><code># In SEARCHING state, each line is checked for block start\nif syntax.detect_start(line):\n    state = BlockState.HEADER_DETECTED\n    emit(EventType.BLOCK_OPENED)\nelse:\n    emit(EventType.TEXT_DELTA)  # Regular text\n</code></pre> <p>Transitions from SEARCHING:</p> Condition Next State Event Start marker found HEADER_DETECTED BLOCK_OPENED Regular line SEARCHING TEXT_DELTA Stream ends Terminal STREAM_END"},{"location":"architecture/state-machine/#header_detected","title":"HEADER_DETECTED","text":"<p>A block start marker has been found. The processor determines if frontmatter parsing is needed.</p> <pre><code>flowchart TB\n    HeaderDetected[HEADER_DETECTED]\n\n    HeaderDetected --&gt; CheckFrontmatter{Syntax has frontmatter?}\n    CheckFrontmatter --&gt;|Yes| AccumulatingMetadata[ACCUMULATING_METADATA]\n    CheckFrontmatter --&gt;|No| AccumulatingContent[ACCUMULATING_CONTENT]\n\n    HeaderDetected --&gt; CheckValid{Valid header?}\n    CheckValid --&gt;|No| Rejected[REJECTED]</code></pre> <p>Transitions from HEADER_DETECTED:</p> Condition Next State Event Has frontmatter ACCUMULATING_METADATA - No frontmatter ACCUMULATING_CONTENT - Invalid header REJECTED BLOCK_REJECTED"},{"location":"architecture/state-machine/#accumulating_metadata","title":"ACCUMULATING_METADATA","text":"<p>Collecting YAML frontmatter lines until the metadata section ends.</p> <pre><code># Frontmatter is collected until closing delimiter\nif line.strip() == \"---\":  # Frontmatter end\n    metadata = parse_yaml(frontmatter_lines)\n    state = BlockState.ACCUMULATING_CONTENT\nelse:\n    frontmatter_lines.append(line)\n</code></pre> <p>Transitions from ACCUMULATING_METADATA:</p> Condition Next State Event Metadata end marker ACCUMULATING_CONTENT - Invalid YAML REJECTED BLOCK_REJECTED Stream ends REJECTED BLOCK_REJECTED"},{"location":"architecture/state-machine/#accumulating_content","title":"ACCUMULATING_CONTENT","text":"<p>Collecting block content lines until an end marker is found.</p> <pre><code># Content is accumulated until end marker\nif syntax.detect_end(line):\n    state = BlockState.CLOSING_DETECTED\nelif len(content) &gt; max_block_size:\n    state = BlockState.REJECTED\nelse:\n    content_lines.append(line)\n    emit(EventType.BLOCK_CONTENT)\n</code></pre> <p>Transitions from ACCUMULATING_CONTENT:</p> Condition Next State Event End marker found CLOSING_DETECTED - Max size exceeded REJECTED BLOCK_REJECTED Regular line ACCUMULATING_CONTENT BLOCK_CONTENT Stream ends REJECTED BLOCK_REJECTED"},{"location":"architecture/state-machine/#closing_detected","title":"CLOSING_DETECTED","text":"<p>An end marker has been found. The complete block is validated.</p> <pre><code>flowchart TB\n    ClosingDetected[CLOSING_DETECTED]\n\n    ClosingDetected --&gt; Parse[Parse block]\n    Parse --&gt; Validate{Validation passes?}\n\n    Validate --&gt;|Yes| Completed[COMPLETED]\n    Validate --&gt;|No| Rejected[REJECTED]\n\n    Completed --&gt; EmitExtracted[Emit BLOCK_EXTRACTED]\n    Rejected --&gt; EmitRejected[Emit BLOCK_REJECTED]</code></pre> <p>Transitions from CLOSING_DETECTED:</p> Condition Next State Event Validation passes COMPLETED BLOCK_EXTRACTED Validation fails REJECTED BLOCK_REJECTED"},{"location":"architecture/state-machine/#completed","title":"COMPLETED","text":"<p>Block successfully extracted. Returns to searching for next block.</p> <pre><code># Block is complete and valid\nblock = Block(metadata=metadata, content=content)\nemit(EventType.BLOCK_EXTRACTED, block=block)\nstate = BlockState.SEARCHING\n</code></pre>"},{"location":"architecture/state-machine/#rejected","title":"REJECTED","text":"<p>Block was rejected due to validation failure or other error.</p> <pre><code># Block was rejected\nrejection = BlockRejection(\n    reason=error_code,\n    message=\"Validation failed\",\n    partial_content=content_so_far,\n)\nemit(EventType.BLOCK_REJECTED, rejection=rejection)\nstate = BlockState.SEARCHING\n</code></pre>"},{"location":"architecture/state-machine/#block-candidate","title":"Block Candidate","text":"<p>During accumulation, the processor builds a <code>BlockCandidate</code>:</p> <pre><code>@dataclass\nclass BlockCandidate:\n    \"\"\"Represents a block being accumulated.\"\"\"\n\n    start_line: int          # Line where block started\n    header_line: str         # The header line content\n    metadata_lines: list[str]  # Frontmatter lines (if any)\n    content_lines: list[str]  # Content lines\n    syntax: Syntax           # Syntax being used\n\n    @property\n    def total_size(self) -&gt; int:\n        \"\"\"Total accumulated size in characters.\"\"\"\n        return sum(len(line) for line in self.content_lines)\n</code></pre>"},{"location":"architecture/state-machine/#line-accumulation","title":"Line Accumulation","text":"<p>Text arrives as chunks that may not align with line boundaries:</p> <pre><code>sequenceDiagram\n    participant Stream\n    participant Accumulator\n    participant StateMachine\n\n    Stream-&gt;&gt;Accumulator: \"Hello\\nWorld\"\n    Accumulator-&gt;&gt;StateMachine: Line: \"Hello\"\n    Accumulator-&gt;&gt;StateMachine: Line: \"World\"\n\n    Stream-&gt;&gt;Accumulator: \"Partial...\"\n    Note over Accumulator: Buffer: \"Partial...\"\n\n    Stream-&gt;&gt;Accumulator: \"line\\nNext\"\n    Accumulator-&gt;&gt;StateMachine: Line: \"Partial...line\"\n    Accumulator-&gt;&gt;StateMachine: Line: \"Next\"</code></pre> <pre><code>class LineAccumulator:\n    \"\"\"Accumulates chunks into complete lines.\"\"\"\n\n    def __init__(self):\n        self.buffer = \"\"\n\n    def add_chunk(self, chunk: str) -&gt; list[str]:\n        \"\"\"Add a chunk and return complete lines.\"\"\"\n        self.buffer += chunk\n        lines = []\n\n        while \"\\n\" in self.buffer:\n            line, self.buffer = self.buffer.split(\"\\n\", 1)\n            lines.append(line)\n\n        return lines\n\n    def flush(self) -&gt; str | None:\n        \"\"\"Flush remaining buffer at stream end.\"\"\"\n        if self.buffer:\n            line = self.buffer\n            self.buffer = \"\"\n            return line\n        return None\n</code></pre>"},{"location":"architecture/state-machine/#syntax-detection","title":"Syntax Detection","text":"<p>Each syntax defines how to detect block boundaries:</p>"},{"location":"architecture/state-machine/#delimiter-preamble","title":"Delimiter Preamble","text":"<pre><code>!!block01:task\nDo something important\n!!end\n</code></pre> <pre><code>class DelimiterPreambleSyntax:\n    START_PATTERN = re.compile(r\"^!!(\\w+):(\\w+)\\s*$\")\n    END_PATTERN = re.compile(r\"^!!end\\s*$\")\n\n    def detect_start(self, line: str) -&gt; bool:\n        return bool(self.START_PATTERN.match(line))\n\n    def detect_end(self, line: str) -&gt; bool:\n        return bool(self.END_PATTERN.match(line))\n</code></pre>"},{"location":"architecture/state-machine/#delimiter-frontmatter","title":"Delimiter Frontmatter","text":"<pre><code>!!block01\n---\ntype: task\npriority: high\n---\nDo something important\n!!end\n</code></pre>"},{"location":"architecture/state-machine/#markdown-frontmatter","title":"Markdown Frontmatter","text":"<pre><code>```block01\n---\ntype: task\n---\nDo something important\n```\n</code></pre>"},{"location":"architecture/state-machine/#validation-pipeline","title":"Validation Pipeline","text":"<pre><code>flowchart TB\n    subgraph Parse[\"Parsing Stage\"]\n        ParseMetadata[Parse Metadata]\n        ParseContent[Parse Content]\n    end\n\n    subgraph Validate[\"Validation Stage\"]\n        ValidateMetadata[Validate Metadata]\n        ValidateContent[Validate Content]\n        CustomValidation[Custom Validators]\n    end\n\n    subgraph Result[\"Result\"]\n        Success[Block Created]\n        Failure[Rejection Created]\n    end\n\n    ParseMetadata --&gt; ValidateMetadata\n    ParseContent --&gt; ValidateContent\n\n    ValidateMetadata --&gt;|Pass| CustomValidation\n    ValidateContent --&gt;|Pass| CustomValidation\n    ValidateMetadata --&gt;|Fail| Failure\n    ValidateContent --&gt;|Fail| Failure\n\n    CustomValidation --&gt;|Pass| Success\n    CustomValidation --&gt;|Fail| Failure</code></pre>"},{"location":"architecture/state-machine/#metadata-validation","title":"Metadata Validation","text":"<pre><code>class MetadataValidator:\n    \"\"\"Validates block metadata.\"\"\"\n\n    def validate(self, metadata: dict) -&gt; ValidationResult:\n        # Required fields\n        if \"id\" not in metadata:\n            return ValidationResult.failure(\"Missing required field: id\")\n\n        # Type checking\n        if not isinstance(metadata.get(\"type\"), str):\n            return ValidationResult.failure(\"Field 'type' must be string\")\n\n        return ValidationResult.success()\n</code></pre>"},{"location":"architecture/state-machine/#content-validation","title":"Content Validation","text":"<pre><code>class ContentValidator:\n    \"\"\"Validates block content.\"\"\"\n\n    def validate(self, content: str, block_type: str) -&gt; ValidationResult:\n        # Type-specific validation\n        if block_type == \"json\":\n            try:\n                json.loads(content)\n            except json.JSONDecodeError as e:\n                return ValidationResult.failure(f\"Invalid JSON: {e}\")\n\n        return ValidationResult.success()\n</code></pre>"},{"location":"architecture/state-machine/#error-handling","title":"Error Handling","text":""},{"location":"architecture/state-machine/#blockerrorcode","title":"BlockErrorCode","text":"<pre><code>class BlockErrorCode(Enum):\n    \"\"\"Error codes for block rejection.\"\"\"\n\n    INVALID_HEADER = \"invalid_header\"\n    INVALID_METADATA = \"invalid_metadata\"\n    INVALID_CONTENT = \"invalid_content\"\n    VALIDATION_FAILED = \"validation_failed\"\n    MAX_SIZE_EXCEEDED = \"max_size_exceeded\"\n    UNCLOSED_BLOCK = \"unclosed_block\"\n    UNKNOWN_BLOCK_TYPE = \"unknown_block_type\"\n</code></pre>"},{"location":"architecture/state-machine/#blockrejection","title":"BlockRejection","text":"<pre><code>@dataclass\nclass BlockRejection:\n    \"\"\"Information about a rejected block.\"\"\"\n\n    reason: BlockErrorCode\n    message: str\n    partial_content: str | None = None\n    line_number: int | None = None\n</code></pre>"},{"location":"architecture/state-machine/#processing-configuration","title":"Processing Configuration","text":"<p>Configure state machine behavior:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=registry,\n    syntax=syntax,\n    max_block_size=100_000,       # Max content size\n    emit_text_deltas=True,        # Emit TEXT_DELTA events\n    emit_block_content=True,      # Emit BLOCK_CONTENT events\n    emit_original_events=False,   # Emit original provider events\n)\n</code></pre>"},{"location":"architecture/state-machine/#next-steps","title":"Next Steps","text":"<ul> <li>Adapter Protocol - Input/output adapters</li> <li>Extension System - Provider extensions</li> <li>Events - Event system details</li> </ul>"},{"location":"examples/","title":"Overview","text":""},{"location":"examples/#examples","title":"Examples","text":"<p>Streamblocks comes with a comprehensive collection of examples organized by topic.</p>"},{"location":"examples/#running-examples","title":"Running Examples","text":"<pre><code># Run all examples (skip API-dependent ones)\nuv run python examples/run_examples.py --skip-api\n\n# Run specific category\nuv run python examples/run_examples.py --category 00_basics\n\n# Dry run to see what would be executed\nuv run python examples/run_examples.py --dry-run\n</code></pre>"},{"location":"examples/#example-categories","title":"Example Categories","text":""},{"location":"examples/#00_basics-getting-started","title":"00_basics - Getting Started","text":"<p>Foundational examples covering core concepts:</p> <ul> <li>Basic usage and core concepts</li> <li>Minimal API examples</li> <li>Error handling patterns</li> <li>Structured output</li> </ul>"},{"location":"examples/#01_syntaxes-syntax-formats","title":"01_syntaxes - Syntax Formats","text":"<p>Different block syntax formats:</p> <ul> <li>Markdown frontmatter</li> <li>Delimiter frontmatter</li> <li>Parsing decorators</li> </ul>"},{"location":"examples/#02_adapters-stream-adapters","title":"02_adapters - Stream Adapters","text":"<p>Working with different AI providers:</p> <ul> <li>Identity adapter (plain text)</li> <li>Gemini adapter</li> <li>OpenAI adapter</li> <li>Anthropic adapter</li> <li>Custom adapters</li> </ul>"},{"location":"examples/#03_content-content-processing","title":"03_content - Content Processing","text":"<p>Content manipulation and processing:</p> <ul> <li>Patch content operations</li> </ul>"},{"location":"examples/#04_logging-logging","title":"04_logging - Logging","text":"<p>Different logging approaches:</p> <ul> <li>stdlib logging</li> <li>structlog integration</li> <li>Custom loggers</li> </ul>"},{"location":"examples/#05_integrations-framework-integration","title":"05_integrations - Framework Integration","text":"<p>Integration with other libraries:</p> <ul> <li>PydanticAI integration</li> </ul>"},{"location":"examples/#06_providers-ai-providers","title":"06_providers - AI Providers","text":"<p>Complete examples with AI providers:</p> <ul> <li>Gemini demos</li> <li>Multi-call examples</li> </ul>"},{"location":"examples/#07_ui-user-interface","title":"07_ui - User Interface","text":"<p>Building interactive applications:</p> <ul> <li>Interactive blocks (CLI)</li> <li>Textual TUI demo</li> </ul>"},{"location":"examples/#learning-path","title":"Learning Path","text":"<p>For the best learning experience:</p> <ol> <li>Start with 00_basics to understand core concepts</li> <li>Explore 01_syntaxes for different block formats</li> <li>Learn 02_adapters for provider integration</li> <li>See 05_integrations for framework usage</li> </ol>"},{"location":"examples/#api-keys","title":"API Keys","text":"<p>Some examples require API keys. See API Keys for setup instructions.</p>"},{"location":"examples/adapters/","title":"Adapters","text":""},{"location":"examples/adapters/#adapter-examples","title":"Adapter Examples","text":"<p>These examples demonstrate stream adapters for different AI providers.</p>"},{"location":"examples/adapters/#plain-text","title":"Plain Text","text":""},{"location":"examples/adapters/#01_identity_adapter_plain_textpy","title":"01_identity_adapter_plain_text.py","text":"<p>Processing plain text streams without adaptation:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/01_identity_adapter_plain_text.py</code></p>"},{"location":"examples/adapters/#provider-adapters","title":"Provider Adapters","text":""},{"location":"examples/adapters/#02_gemini_auto_detectpy","title":"02_gemini_auto_detect.py","text":"<p>Gemini with automatic adapter detection:</p> <p>Requires API Key</p> <p>Set <code>GEMINI_API_KEY</code> environment variable.</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/02_gemini_auto_detect.py</code></p>"},{"location":"examples/adapters/#03_openai_explicit_adapterpy","title":"03_openai_explicit_adapter.py","text":"<p>OpenAI with explicit adapter configuration:</p> <p>Requires API Key</p> <p>Set <code>OPENAI_API_KEY</code> environment variable.</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/03_openai_explicit_adapter.py</code></p>"},{"location":"examples/adapters/#04_anthropic_adapterpy","title":"04_anthropic_adapter.py","text":"<p>Anthropic event stream handling:</p> <p>Requires API Key</p> <p>Set <code>ANTHROPIC_API_KEY</code> environment variable.</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/04_anthropic_adapter.py</code></p>"},{"location":"examples/adapters/#event-handling","title":"Event Handling","text":""},{"location":"examples/adapters/#05_mixed_event_streampy","title":"05_mixed_event_stream.py","text":"<p>Working with mixed event streams:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/05_mixed_event_stream.py</code></p>"},{"location":"examples/adapters/#06_text_delta_streamingpy","title":"06_text_delta_streaming.py","text":"<p>Real-time text delta events:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/06_text_delta_streaming.py</code></p>"},{"location":"examples/adapters/#07_block_opened_eventpy","title":"07_block_opened_event.py","text":"<p>Detecting block opening:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/07_block_opened_event.py</code></p>"},{"location":"examples/adapters/#configuration","title":"Configuration","text":""},{"location":"examples/adapters/#08_configuration_flagspy","title":"08_configuration_flags.py","text":"<p>Processor configuration options:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/08_configuration_flags.py</code></p>"},{"location":"examples/adapters/#custom-adapters","title":"Custom Adapters","text":""},{"location":"examples/adapters/#09_custom_adapterpy","title":"09_custom_adapter.py","text":"<p>Creating custom adapters:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/09_custom_adapter.py</code></p>"},{"location":"examples/adapters/#10_callable_adapterpy","title":"10_callable_adapter.py","text":"<p>Using callable adapters:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/10_callable_adapter.py</code></p>"},{"location":"examples/adapters/#11_attribute_adapter_genericpy","title":"11_attribute_adapter_generic.py","text":"<p>Generic attribute adapters:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/11_attribute_adapter_generic.py</code></p>"},{"location":"examples/adapters/#advanced","title":"Advanced","text":""},{"location":"examples/adapters/#12_disable_original_eventspy","title":"12_disable_original_events.py","text":"<p>Controlling event emission:</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/12_disable_original_events.py</code></p>"},{"location":"examples/adapters/#13_manual_chunk_processingpy","title":"13_manual_chunk_processing.py","text":"<p>Manual chunk processing:</p> <p>Requires API Key</p> <p>Set <code>GEMINI_API_KEY</code> environment variable.</p> <p>Example file not found</p> <p>Could not find: <code>examples/03_adapters/13_manual_chunk_processing.py</code></p>"},{"location":"examples/basic/","title":"Basic Patterns","text":""},{"location":"examples/basic/#basic-examples","title":"Basic Examples","text":"<p>These examples cover the foundational concepts of Streamblocks.</p>"},{"location":"examples/basic/#01_basic_usagepy","title":"01_basic_usage.py","text":"<p>Basic Streamblocks usage demonstrating core concepts:</p> <p>Example file not found</p> <p>Could not find: <code>examples/01_basics/01_basic_usage.py</code></p>"},{"location":"examples/basic/#02_minimal_apipy","title":"02_minimal_api.py","text":"<p>Minimal API example for quick reference:</p> <p>Example file not found</p> <p>Could not find: <code>examples/01_basics/02_minimal_api.py</code></p>"},{"location":"examples/basic/#03_error_handlingpy","title":"03_error_handling.py","text":"<p>Error handling patterns and best practices:</p> <p>Example file not found</p> <p>Could not find: <code>examples/01_basics/03_error_handling.py</code></p>"},{"location":"examples/basic/#04_structured_outputpy","title":"04_structured_output.py","text":"<p>Working with structured output:</p> <p>Example file not found</p> <p>Could not find: <code>examples/01_basics/04_structured_output.py</code></p>"},{"location":"examples/basic/#next-steps","title":"Next Steps","text":"<ul> <li>Syntax Examples - Different block formats</li> <li>Adapter Examples - AI provider integration</li> </ul>"},{"location":"examples/integrations/","title":"Integrations","text":""},{"location":"examples/integrations/#integration-examples","title":"Integration Examples","text":"<p>These examples show integration with other libraries and frameworks.</p>"},{"location":"examples/integrations/#pydanticai","title":"PydanticAI","text":""},{"location":"examples/integrations/#01_pydantic_ai_integrationpy","title":"01_pydantic_ai_integration.py","text":"<p>Integration with PydanticAI for structured agent responses:</p> <p>Requires API Key</p> <p>Set appropriate API keys for the model you're using.</p> <p>Example file not found</p> <p>Could not find: <code>examples/06_integrations/01_pydantic_ai_integration.py</code></p>"},{"location":"examples/integrations/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - Detailed API documentation</li> <li>Patterns - Common usage patterns</li> </ul>"},{"location":"examples/providers/","title":"Provider Examples","text":""},{"location":"examples/providers/#provider-examples","title":"Provider Examples","text":"<p>Examples for working with different LLM providers.</p>"},{"location":"examples/providers/#google-gemini","title":"Google Gemini","text":""},{"location":"examples/providers/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nimport google.generativeai as genai\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\n\nasync def gemini_example():\n    genai.configure(api_key=\"your-api-key\")  # pragma: allowlist secret  # pragma: allowlist secret\n    model = genai.GenerativeModel(\"gemini-pro\")\n\n    prompt = \"\"\"\n    Create a task list:\n\n    !!task01:task\n    Review code changes\n    !!end\n\n    !!task02:task\n    Update documentation\n    !!end\n    \"\"\"\n\n    response = model.generate_content(prompt, stream=True)\n\n    processor = StreamBlockProcessor(\n        registry=BlockRegistry(),\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=\"auto\",\n    )\n\n    async for event in processor.process_stream(response):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            print(f\"Task: {event.block.content.raw_content}\")\n\nasyncio.run(gemini_example())\n</code></pre>"},{"location":"examples/providers/#with-explicit-adapter","title":"With Explicit Adapter","text":"<pre><code>from streamblocks.ext.gemini import GeminiInputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=GeminiInputAdapter(),\n)\n</code></pre>"},{"location":"examples/providers/#openai","title":"OpenAI","text":""},{"location":"examples/providers/#basic-usage_1","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom openai import OpenAI\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\nfrom streamblocks.ext.openai import OpenAIInputAdapter\n\nasync def openai_example():\n    client = OpenAI(api_key=\"your-api-key\")  # pragma: allowlist secret\n\n    prompt = \"\"\"\n    Create a task list using:\n    !!id:task\n    description\n    !!end\n    \"\"\"\n\n    stream = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        stream=True,\n    )\n\n    processor = StreamBlockProcessor(\n        registry=BlockRegistry(),\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=OpenAIInputAdapter(),\n    )\n\n    async for event in processor.process_stream(stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            print(f\"Task: {event.block.content.raw_content}\")\n\nasyncio.run(openai_example())\n</code></pre>"},{"location":"examples/providers/#streaming-text-display","title":"Streaming Text Display","text":"<pre><code>processor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=OpenAIInputAdapter(),\n    emit_text_deltas=True,\n)\n\nasync for event in processor.process_stream(stream):\n    match event.type:\n        case EventType.TEXT_DELTA:\n            print(event.text, end=\"\", flush=True)\n        case EventType.BLOCK_EXTRACTED:\n            print(f\"\\n[Block: {event.block.metadata.id}]\")\n</code></pre>"},{"location":"examples/providers/#anthropic","title":"Anthropic","text":""},{"location":"examples/providers/#basic-usage_2","title":"Basic Usage","text":"<pre><code>import asyncio\nimport anthropic\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\nfrom streamblocks.ext.anthropic import AnthropicInputAdapter\n\nasync def anthropic_example():\n    client = anthropic.Anthropic(api_key=\"your-api-key\")  # pragma: allowlist secret\n\n    prompt = \"\"\"\n    Create a task list using:\n    !!id:task\n    description\n    !!end\n    \"\"\"\n\n    processor = StreamBlockProcessor(\n        registry=BlockRegistry(),\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        input_adapter=AnthropicInputAdapter(),\n    )\n\n    with client.messages.stream(\n        model=\"claude-3-opus\",\n        max_tokens=1024,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    ) as stream:\n        async for event in processor.process_stream(stream):\n            if event.type == EventType.BLOCK_EXTRACTED:\n                print(f\"Task: {event.block.content.raw_content}\")\n\nasyncio.run(anthropic_example())\n</code></pre>"},{"location":"examples/providers/#plain-text-streams","title":"Plain Text Streams","text":""},{"location":"examples/providers/#identity-adapter","title":"Identity Adapter","text":"<p>For plain text without LLM-specific formatting:</p> <pre><code>from streamblocks.adapters import IdentityAdapter\n\nasync def plain_text_stream():\n    yield \"!!task01:task\\n\"\n    yield \"Do something\\n\"\n    yield \"!!end\\n\"\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=IdentityAdapter(),\n)\n\nasync for event in processor.process_stream(plain_text_stream()):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        print(event.block)\n</code></pre>"},{"location":"examples/providers/#no-adapter","title":"No Adapter","text":"<p>Strings work directly:</p> <pre><code>async def string_stream():\n    yield \"!!task01:task\\nDo something\\n!!end\\n\"\n\nasync for event in processor.process_stream(string_stream()):\n    if event.type == EventType.BLOCK_EXTRACTED:\n        print(event.block)\n</code></pre>"},{"location":"examples/providers/#auto-detection","title":"Auto-Detection","text":"<p>Let Streamblocks detect the provider:</p> <pre><code>processor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=\"auto\",  # Detects from first event\n)\n\n# Works with any supported provider\nasync for event in processor.process_stream(any_stream):\n    handle_event(event)\n</code></pre>"},{"location":"examples/providers/#error-handling","title":"Error Handling","text":""},{"location":"examples/providers/#provider-errors","title":"Provider Errors","text":"<pre><code>import google.api_core.exceptions\n\ntry:\n    async for event in processor.process_stream(gemini_stream):\n        handle_event(event)\nexcept google.api_core.exceptions.ResourceExhausted:\n    print(\"Rate limit exceeded\")\n    await asyncio.sleep(60)\nexcept google.api_core.exceptions.InvalidArgument as e:\n    print(f\"Invalid request: {e}\")\n</code></pre>"},{"location":"examples/providers/#block-rejections","title":"Block Rejections","text":"<pre><code>async for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_REJECTED:\n        print(f\"Block rejected: {event.rejection.reason}\")\n    elif event.type == EventType.BLOCK_EXTRACTED:\n        print(f\"Block extracted: {event.block.metadata.id}\")\n</code></pre>"},{"location":"examples/providers/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Examples - Core concepts</li> <li>Adapter Examples - Adapter details</li> <li>Integration Examples - Framework usage</li> </ul>"},{"location":"examples/setup/","title":"Setup","text":""},{"location":"examples/setup/#examples-setup","title":"Examples Setup","text":"<p>This guide explains how to set up and run the Streamblocks examples.</p>"},{"location":"examples/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> <li>uv (recommended) or pip</li> </ul>"},{"location":"examples/setup/#installation","title":"Installation","text":""},{"location":"examples/setup/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/hotherio/streamblocks.git\ncd streamblocks\n</code></pre>"},{"location":"examples/setup/#install-dependencies","title":"Install Dependencies","text":"uvpip <pre><code>uv sync --all-extras\n</code></pre> <pre><code>pip install -e \".[dev,gemini,openai,anthropic]\"\n</code></pre>"},{"location":"examples/setup/#running-examples","title":"Running Examples","text":""},{"location":"examples/setup/#quick-start","title":"Quick Start","text":"<p>Run all standalone examples (no API keys required):</p> <pre><code>uv run python examples/run_examples.py --skip-api\n</code></pre>"},{"location":"examples/setup/#with-api-keys","title":"With API Keys","text":"<p>Set your API keys and run all examples:</p> <pre><code>export GEMINI_API_KEY=\"your-key-here\"  # pragma: allowlist secret\nexport OPENAI_API_KEY=\"your-key-here\"  # pragma: allowlist secret\nexport ANTHROPIC_API_KEY=\"your-key-here\"  # pragma: allowlist secret\n\nuv run python examples/run_examples.py\n</code></pre>"},{"location":"examples/setup/#runner-options","title":"Runner Options","text":"<pre><code># Run specific category\nuv run python examples/run_examples.py --category adapters\n\n# Dry run (see what would execute)\nuv run python examples/run_examples.py --dry-run\n\n# Verbose output\nuv run python examples/run_examples.py --verbose\n\n# Run in parallel (faster)\nuv run python examples/run_examples.py --parallel\n\n# Custom timeout\nuv run python examples/run_examples.py --timeout 60\n\n# JSON output\nuv run python examples/run_examples.py --output json\n</code></pre>"},{"location":"examples/setup/#run-individual-examples","title":"Run Individual Examples","text":"<pre><code># Basic example (no API key)\nuv run python examples/01_basics/01_basic_usage.py\n\n# Gemini example (requires API key)\nexport GEMINI_API_KEY=\"your-key-here\"  # pragma: allowlist secret\nuv run python examples/03_adapters/02_gemini_auto_detect.py\n</code></pre>"},{"location":"examples/setup/#api-keys","title":"API Keys","text":""},{"location":"examples/setup/#google-gemini","title":"Google Gemini","text":"<pre><code>export GEMINI_API_KEY=\"your-key-here\"  # pragma: allowlist secret\n# or\nexport GOOGLE_API_KEY=\"your-key-here\"  # pragma: allowlist secret\n</code></pre> <p>Get your key: Google AI Studio</p>"},{"location":"examples/setup/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-key-here\"  # pragma: allowlist secret\n</code></pre> <p>Get your key: OpenAI Platform</p>"},{"location":"examples/setup/#anthropic","title":"Anthropic","text":"<pre><code>export ANTHROPIC_API_KEY=\"your-key-here\"  # pragma: allowlist secret\n</code></pre> <p>Get your key: Anthropic Console</p>"},{"location":"examples/setup/#example-categories","title":"Example Categories","text":"Directory Description Requires API <code>01_basics/</code> Core concepts No <code>02_syntaxes/</code> Syntax formats No <code>03_adapters/</code> Provider adapters Some <code>04_logging/</code> Logging options No <code>05_ui/</code> UI examples No <code>06_integrations/</code> Framework integrations Some"},{"location":"examples/setup/#pytest-integration","title":"Pytest Integration","text":"<p>Run examples as tests:</p> <pre><code># Run all\npytest tests/test_examples.py\n\n# Skip API examples\npytest tests/test_examples.py -m \"not api\"\n\n# Skip UI examples\npytest tests/test_examples.py -m \"not ui\"\n\n# Verbose\npytest tests/test_examples.py -v\n</code></pre>"},{"location":"examples/setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/setup/#timeout-issues","title":"Timeout Issues","text":"<p>Increase the timeout:</p> <pre><code>uv run python examples/run_examples.py --timeout 120\n</code></pre>"},{"location":"examples/setup/#rate-limits","title":"Rate Limits","text":"<p>Run sequentially instead of parallel:</p> <pre><code>uv run python examples/run_examples.py\n</code></pre>"},{"location":"examples/setup/#import-errors","title":"Import Errors","text":"<p>Reinstall with all extras:</p> <pre><code>uv sync --all-extras\n</code></pre>"},{"location":"examples/setup/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Examples - Start here</li> <li>Adapter Examples - Provider integration</li> <li>Integration Examples - Framework usage</li> </ul>"},{"location":"examples/syntaxes/","title":"Syntaxes","text":""},{"location":"examples/syntaxes/#syntax-examples","title":"Syntax Examples","text":"<p>These examples demonstrate different block syntax formats.</p>"},{"location":"examples/syntaxes/#01_markdown_frontmatterpy","title":"01_markdown_frontmatter.py","text":"<p>Markdown frontmatter syntax with YAML metadata:</p> <p>Example file not found</p> <p>Could not find: <code>examples/02_syntaxes/01_markdown_frontmatter.py</code></p>"},{"location":"examples/syntaxes/#02_delimiter_frontmatterpy","title":"02_delimiter_frontmatter.py","text":"<p>Delimiter-based syntax with custom boundaries:</p> <p>Example file not found</p> <p>Could not find: <code>examples/02_syntaxes/02_delimiter_frontmatter.py</code></p>"},{"location":"examples/syntaxes/#03_parsing_decoratorspy","title":"03_parsing_decorators.py","text":"<p>Using parsing decorators for custom block parsers:</p> <p>Example file not found</p> <p>Could not find: <code>examples/02_syntaxes/03_parsing_decorators.py</code></p>"},{"location":"examples/syntaxes/#next-steps","title":"Next Steps","text":"<ul> <li>Adapter Examples - AI provider integration</li> <li>Integration Examples - Framework integration</li> </ul>"},{"location":"integrations/","title":"Overview","text":""},{"location":"integrations/#integrations","title":"Integrations","text":"<p>Streamblocks integrates with popular frameworks and libraries.</p>"},{"location":"integrations/#available-integrations","title":"Available Integrations","text":""},{"location":"integrations/#pydanticai","title":"PydanticAI","text":"<p>Integration with PydanticAI for building AI agents with structured responses.</p> <ul> <li>Process agent responses as structured blocks</li> <li>Handle tool calls and messages</li> <li>Real-time streaming support</li> </ul>"},{"location":"integrations/#coming-soon","title":"Coming Soon","text":"<ul> <li>LangChain: Chain-based workflows</li> <li>FastAPI: Web application streaming</li> <li>LlamaIndex: Document processing</li> </ul>"},{"location":"integrations/#creating-custom-integrations","title":"Creating Custom Integrations","text":"<p>Streamblocks is designed to be easily integrated with other tools. The core <code>StreamBlockProcessor</code> can wrap any async iterator:</p> <pre><code>from hother.streamblocks import StreamBlockProcessor\n\nasync def process_custom_stream(stream):\n    processor = StreamBlockProcessor()\n    async for event in processor.process_stream(stream):\n        yield event\n</code></pre> <p>See Advanced Usage for more details on custom integrations.</p>"},{"location":"integrations/agui/","title":"AG-UI Protocol","text":""},{"location":"integrations/agui/#ag-ui-protocol-integration","title":"AG-UI Protocol Integration","text":"<p>Streamblocks integrates with the AG-UI protocol for streaming structured events to rich client interfaces.</p>"},{"location":"integrations/agui/#overview","title":"Overview","text":"<p>The AG-UI protocol defines a standard format for streaming AI agent events to user interfaces. Streamblocks provides bidirectional adapters for working with AG-UI.</p> <pre><code>flowchart LR\n    subgraph Server[\"Server (Streamblocks)\"]\n        LLM[LLM Provider] --&gt; Processor[StreamBlockProcessor]\n        Processor --&gt; Output[AG-UI Output Adapter]\n    end\n\n    subgraph Client[\"Client (AG-UI)\"]\n        Input[AG-UI Input] --&gt; UI[User Interface]\n    end\n\n    Output --&gt;|AG-UI Events| Input</code></pre>"},{"location":"integrations/agui/#installation","title":"Installation","text":"uvpip <pre><code>uv add streamblocks[agui]\n</code></pre> <pre><code>pip install streamblocks[agui]\n</code></pre>"},{"location":"integrations/agui/#basic-usage","title":"Basic Usage","text":""},{"location":"integrations/agui/#output-adapter","title":"Output Adapter","text":"<p>Convert Streamblocks events to AG-UI protocol:</p> <pre><code>from streamblocks import StreamBlockProcessor, BlockRegistry, Syntax, EventType\nfrom streamblocks.ext.agui import AGUIOutputAdapter\n\n# Create processor with AG-UI output\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    output_adapter=AGUIOutputAdapter(),\n)\n\nasync def stream_agui_events(llm_stream):\n    async for event in processor.process_stream(llm_stream):\n        # Events are now AG-UI formatted\n        yield event\n</code></pre>"},{"location":"integrations/agui/#input-adapter","title":"Input Adapter","text":"<p>Process incoming AG-UI events:</p> <pre><code>from streamblocks.ext.agui import AGUIInputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=AGUIInputAdapter(),\n)\n\nasync def process_agui_stream(agui_stream):\n    async for event in processor.process_stream(agui_stream):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            handle_block(event.block)\n</code></pre>"},{"location":"integrations/agui/#bidirectional","title":"Bidirectional","text":"<p>Use both adapters for full AG-UI support:</p> <pre><code>from streamblocks.ext.agui import AGUIInputAdapter, AGUIOutputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=BlockRegistry(),\n    syntax=Syntax.DELIMITER_PREAMBLE,\n    input_adapter=AGUIInputAdapter(),\n    output_adapter=AGUIOutputAdapter(),\n)\n</code></pre>"},{"location":"integrations/agui/#event-mapping","title":"Event Mapping","text":""},{"location":"integrations/agui/#streamblocks-to-ag-ui","title":"Streamblocks to AG-UI","text":"Streamblocks Event AG-UI Event <code>STREAM_START</code> <code>RunStarted</code> <code>TEXT_DELTA</code> <code>TextMessageContent</code> <code>BLOCK_OPENED</code> <code>ToolCallStart</code> / Custom <code>BLOCK_EXTRACTED</code> <code>ToolCallEnd</code> / Custom <code>STREAM_END</code> <code>RunFinished</code>"},{"location":"integrations/agui/#ag-ui-to-streamblocks","title":"AG-UI to Streamblocks","text":"AG-UI Event Streamblocks Category <code>TextMessageContent</code> <code>TEXT_CONTENT</code> <code>ToolCallStart</code> <code>PASSTHROUGH</code> <code>ToolCallEnd</code> <code>PASSTHROUGH</code> <code>RunStarted</code> <code>STREAM_START</code> <code>RunFinished</code> <code>STREAM_END</code>"},{"location":"integrations/agui/#configuration","title":"Configuration","text":""},{"location":"integrations/agui/#event-filtering","title":"Event Filtering","text":"<p>Control which events are converted:</p> <pre><code>output_adapter = AGUIOutputAdapter(\n    include_text_deltas=True,\n    include_block_content=False,\n    include_metadata=True,\n)\n</code></pre>"},{"location":"integrations/agui/#custom-event-types","title":"Custom Event Types","text":"<p>Map custom block types to AG-UI events:</p> <pre><code>output_adapter = AGUIOutputAdapter(\n    block_type_mapping={\n        \"task\": \"CustomTaskEvent\",\n        \"code\": \"CodeBlockEvent\",\n        \"message\": \"TextMessageContent\",\n    }\n)\n</code></pre>"},{"location":"integrations/agui/#fastapi-integration","title":"FastAPI Integration","text":""},{"location":"integrations/agui/#sse-endpoint","title":"SSE Endpoint","text":"<pre><code>from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nfrom streamblocks import StreamBlockProcessor, BlockRegistry, Syntax\nfrom streamblocks.ext.agui import AGUIOutputAdapter\nimport json\n\napp = FastAPI()\n\n@app.post(\"/agent/stream\")\nasync def stream_agent(request: AgentRequest):\n    async def generate():\n        processor = StreamBlockProcessor(\n            registry=BlockRegistry(),\n            syntax=Syntax.DELIMITER_PREAMBLE,\n            output_adapter=AGUIOutputAdapter(),\n        )\n\n        llm_stream = get_llm_stream(request.prompt)\n\n        async for event in processor.process_stream(llm_stream):\n            yield f\"data: {json.dumps(event)}\\n\\n\"\n\n        yield \"data: [DONE]\\n\\n\"\n\n    return StreamingResponse(\n        generate(),\n        media_type=\"text/event-stream\",\n    )\n</code></pre>"},{"location":"integrations/agui/#websocket-endpoint","title":"WebSocket Endpoint","text":"<pre><code>from fastapi import WebSocket\n\n@app.websocket(\"/agent/ws\")\nasync def websocket_agent(websocket: WebSocket):\n    await websocket.accept()\n\n    processor = StreamBlockProcessor(\n        registry=BlockRegistry(),\n        syntax=Syntax.DELIMITER_PREAMBLE,\n        output_adapter=AGUIOutputAdapter(),\n    )\n\n    # Receive prompt\n    data = await websocket.receive_json()\n    prompt = data[\"prompt\"]\n\n    # Stream response\n    llm_stream = get_llm_stream(prompt)\n\n    async for event in processor.process_stream(llm_stream):\n        await websocket.send_json(event)\n\n    await websocket.close()\n</code></pre>"},{"location":"integrations/agui/#client-integration","title":"Client Integration","text":""},{"location":"integrations/agui/#javascript-client","title":"JavaScript Client","text":"<pre><code>const eventSource = new EventSource('/agent/stream');\n\neventSource.onmessage = (event) =&gt; {\n    if (event.data === '[DONE]') {\n        eventSource.close();\n        return;\n    }\n\n    const data = JSON.parse(event.data);\n\n    switch (data.type) {\n        case 'TextMessageContent':\n            appendText(data.content);\n            break;\n        case 'ToolCallStart':\n            showToolCallStart(data.name);\n            break;\n        case 'ToolCallEnd':\n            showToolCallResult(data.result);\n            break;\n    }\n};\n</code></pre>"},{"location":"integrations/agui/#react-integration","title":"React Integration","text":"<pre><code>import { useAGUI } from '@ag-ui/react';\n\nfunction AgentChat() {\n    const { events, sendMessage, isStreaming } = useAGUI({\n        url: '/agent/stream',\n    });\n\n    return (\n        &lt;div&gt;\n            {events.map((event, i) =&gt; (\n                &lt;EventRenderer key={i} event={event} /&gt;\n            ))}\n            &lt;input\n                onSubmit={(e) =&gt; sendMessage(e.target.value)}\n                disabled={isStreaming}\n            /&gt;\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"integrations/agui/#custom-block-to-ag-ui","title":"Custom Block to AG-UI","text":"<p>Map custom block types to AG-UI events:</p> <pre><code>class CustomAGUIOutputAdapter(AGUIOutputAdapter):\n    def to_protocol_event(self, event):\n        if event.type == EventType.BLOCK_EXTRACTED:\n            block = event.block\n\n            if block.metadata.block_type == \"task\":\n                return {\n                    \"type\": \"TaskCreated\",\n                    \"id\": block.metadata.id,\n                    \"title\": block.content.raw_content[:50],\n                    \"priority\": getattr(block.metadata, \"priority\", \"normal\"),\n                }\n\n            if block.metadata.block_type == \"code\":\n                return {\n                    \"type\": \"CodeBlock\",\n                    \"language\": getattr(block.metadata, \"language\", \"text\"),\n                    \"code\": block.content.raw_content,\n                }\n\n        # Default handling\n        return super().to_protocol_event(event)\n</code></pre>"},{"location":"integrations/agui/#error-handling","title":"Error Handling","text":""},{"location":"integrations/agui/#protocol-errors","title":"Protocol Errors","text":"<pre><code>from streamblocks.ext.agui import AGUIProtocolError\n\ntry:\n    async for event in processor.process_stream(agui_stream):\n        handle_event(event)\nexcept AGUIProtocolError as e:\n    logger.error(f\"Protocol error: {e}\")\n    # Send error event to client\n    yield {\"type\": \"Error\", \"message\": str(e)}\n</code></pre>"},{"location":"integrations/agui/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>output_adapter = AGUIOutputAdapter(\n    on_error=\"skip\",  # Skip invalid events\n    # on_error=\"raise\",  # Raise exception (default)\n    # on_error=\"fallback\",  # Use fallback format\n)\n</code></pre>"},{"location":"integrations/agui/#best-practices","title":"Best Practices","text":"<p>Use Proper Event Types</p> <p>Map block types to appropriate AG-UI event types for best client experience.</p> <p>Include Metadata</p> <p>Send relevant metadata with events for rich client rendering.</p> <p>Handle Errors Gracefully</p> <p>Always send error events to clients instead of just closing connections.</p> <p>Test with AG-UI Inspector</p> <p>Use the AG-UI inspector tool to debug event streams.</p>"},{"location":"integrations/agui/#next-steps","title":"Next Steps","text":"<ul> <li>PydanticAI Integration - AI agent integration</li> <li>Adapters - Adapter details</li> <li>Architecture: Adapters - Adapter internals</li> </ul>"},{"location":"integrations/pydantic_ai/","title":"PydanticAI","text":""},{"location":"integrations/pydantic_ai/#pydanticai-integration","title":"PydanticAI Integration","text":"<p>Streamblocks integrates with PydanticAI for processing structured agent responses.</p>"},{"location":"integrations/pydantic_ai/#installation","title":"Installation","text":"uvpip <pre><code>uv add streamblocks pydantic-ai\n</code></pre> <pre><code>pip install streamblocks pydantic-ai\n</code></pre>"},{"location":"integrations/pydantic_ai/#basic-usage","title":"Basic Usage","text":"<pre><code>from pydantic_ai import Agent\nfrom hother.streamblocks.integrations.pydantic_ai import StreamblocksProcessor\n\n# Create a PydanticAI agent\nagent = Agent(\n    model=\"gemini-2.0-flash-exp\",\n    system_prompt=\"You are a helpful assistant.\"\n)\n\n# Create the processor\nprocessor = StreamblocksProcessor()\n\n# Process agent responses\nasync def run_agent(prompt: str):\n    async with agent.run_stream(prompt) as response:\n        async for event in processor.process(response):\n            if event.type == EventType.BLOCK_CLOSED:\n                print(f\"Block: {event.block.block_type}\")\n                print(f\"Content: {event.block.content}\")\n</code></pre>"},{"location":"integrations/pydantic_ai/#features","title":"Features","text":""},{"location":"integrations/pydantic_ai/#structured-block-extraction","title":"Structured Block Extraction","text":"<p>Extract structured blocks from agent responses:</p> <pre><code>async for event in processor.process(response):\n    match event.type:\n        case EventType.BLOCK_OPENED:\n            print(f\"New block: {event.block.block_type}\")\n        case EventType.BLOCK_UPDATED:\n            print(f\"Content: {event.block.content[-50:]}\")\n        case EventType.BLOCK_CLOSED:\n            handle_complete_block(event.block)\n</code></pre>"},{"location":"integrations/pydantic_ai/#tool-call-handling","title":"Tool Call Handling","text":"<p>Handle tool calls from the agent:</p> <pre><code>async for event in processor.process(response):\n    if event.type == EventType.BLOCK_CLOSED:\n        if event.block.block_type == \"tool_call\":\n            name = event.block.metadata.get(\"name\")\n            args = event.block.content\n            result = await execute_tool(name, args)\n</code></pre>"},{"location":"integrations/pydantic_ai/#real-time-streaming","title":"Real-time Streaming","text":"<p>Display content as it streams:</p> <pre><code>async for event in processor.process(response):\n    if event.type == EventType.TEXT_DELTA:\n        print(event.data, end=\"\", flush=True)\n</code></pre>"},{"location":"integrations/pydantic_ai/#example","title":"Example","text":"<p>See the full example:</p> <p>Example file not found</p> <p>Could not find: <code>examples/06_integrations/01_pydantic_ai_integration.py</code></p>"},{"location":"integrations/pydantic_ai/#api-reference","title":"API Reference","text":""},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai","title":"hother.streamblocks.integrations.pydantic_ai","text":"<p>PydanticAI integration for StreamBlocks.</p> <p>This module provides transparent integration between PydanticAI agents and StreamBlocks, allowing agents to generate structured blocks that are extracted in real-time during streaming.</p>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor","title":"AgentStreamProcessor","text":"<p>               Bases: <code>StreamBlockProcessor</code></p> <p>Enhanced processor designed to work with PydanticAI agent streaming output.</p> <p>This processor is optimized for handling streaming text from AI agents, with special handling for partial blocks and real-time extraction.</p> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/processor.py</code> <pre><code>class AgentStreamProcessor(StreamBlockProcessor):\n    \"\"\"Enhanced processor designed to work with PydanticAI agent streaming output.\n\n    This processor is optimized for handling streaming text from AI agents,\n    with special handling for partial blocks and real-time extraction.\n    \"\"\"\n\n    def __init__(\n        self,\n        registry: Registry,\n        config: ProcessorConfig | None = None,\n        *,\n        enable_partial_blocks: bool = True,\n    ) -&gt; None:\n        \"\"\"Initialize the agent stream processor.\n\n        Args:\n            registry: Registry with a single syntax\n            config: Configuration object for processor settings\n            enable_partial_blocks: Whether to emit section delta events for partial blocks\n        \"\"\"\n        super().__init__(registry, config=config)\n        self.enable_partial_blocks = enable_partial_blocks\n\n    async def process_agent_stream(self, agent_stream: AsyncIterator[str]) -&gt; AsyncGenerator[str | BaseEvent]:\n        \"\"\"Process streaming output from a PydanticAI agent.\n\n        This method is specifically designed to handle the streaming output\n        from agent.run_stream() or similar agent streaming methods.\n\n        Args:\n            agent_stream: Async iterator from agent streaming (e.g., stream_text())\n\n        Yields:\n            Mixed stream of:\n            - Original text chunks (if emit_original_events=True)\n            - Event objects as blocks are detected and extracted\n        \"\"\"\n        async for event in self.process_stream(agent_stream):\n            yield event\n\n    async def process_agent_with_events(\n        self,\n        agent_stream: AsyncIterator[str],\n        event_handler: Callable[[str | BaseEvent], Any] | None = None,\n    ) -&gt; AsyncGenerator[str | BaseEvent]:\n        \"\"\"Process agent stream with optional event handler for agent-specific events.\n\n        This allows handling both StreamBlocks events and PydanticAI events\n        in a unified manner.\n\n        Args:\n            agent_stream: Async iterator from agent streaming\n            event_handler: Optional callback for handling events (both text chunks and Events)\n\n        Yields:\n            Mixed stream of:\n            - Original text chunks (if emit_original_events=True)\n            - Event objects with enhanced metadata\n        \"\"\"\n        async for event in self.process_agent_stream(agent_stream):\n            # Call event handler if provided\n            if event_handler:\n                await event_handler(event)\n\n            # Always yield the event\n            yield event\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config or ProcessorConfig()\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.enable_partial_blocks","title":"enable_partial_blocks  <code>instance-attribute</code>","text":"<pre><code>enable_partial_blocks = enable_partial_blocks\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or StdlibLoggerAdapter(getLogger(__name__))\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.registry","title":"registry  <code>instance-attribute</code>","text":"<pre><code>registry = registry\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax = syntax\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.finalize","title":"finalize","text":"<pre><code>finalize() -&gt; list[Event]\n</code></pre> <p>Finalize processing and flush any incomplete blocks.</p> <p>Call this method after processing all chunks to get rejection events for any blocks that were opened but never closed.</p> <p>This method processes any accumulated text as a final line before flushing candidates, ensuring the last line is processed even if it doesn't end with a newline.</p> <p>Returns:</p> Type Description <code>list[Event]</code> <p>List of events including processed final line and rejection events</p> <code>list[Event]</code> <p>for incomplete blocks</p> Example <p>processor = StreamBlockProcessor(registry) async for chunk in stream: ...     events = processor.process_chunk(chunk) ...     # ... handle events ...</p> Source code in <code>src/hother/streamblocks/core/processor.py</code> <pre><code>def finalize(self) -&gt; list[Event]:\n    \"\"\"Finalize processing and flush any incomplete blocks.\n\n    Call this method after processing all chunks to get rejection events\n    for any blocks that were opened but never closed.\n\n    This method processes any accumulated text as a final line before\n    flushing candidates, ensuring the last line is processed even if it\n    doesn't end with a newline.\n\n    Returns:\n        List of events including processed final line and rejection events\n        for incomplete blocks\n\n    Example:\n        &gt;&gt;&gt; processor = StreamBlockProcessor(registry)\n        &gt;&gt;&gt; async for chunk in stream:\n        ...     events = processor.process_chunk(chunk)\n        ...     # ... handle events\n        ...\n        &gt;&gt;&gt; # Stream ended, process remaining text and flush incomplete blocks\n        &gt;&gt;&gt; final_events = processor.finalize()\n        &gt;&gt;&gt; for event in final_events:\n        ...     if isinstance(event, BlockErrorEvent):\n        ...         print(f\"Incomplete block: {event.reason}\")\n    \"\"\"\n    events: list[Event] = []\n\n    # Process any remaining accumulated text as a final line\n    final_line = self._line_accumulator.finalize()\n    if final_line:\n        line_number, line = final_line\n        line_events = self._block_machine.process_line(line, line_number)\n        self._update_stats(line_events)\n        events.extend(line_events)\n\n    # Flush remaining candidates\n    flush_events = self._block_machine.flush(self._line_accumulator.line_number)\n    self._update_stats(flush_events)\n    events.extend(flush_events)\n\n    return events\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.finalize--stream-ended-process-remaining-text-and-flush-incomplete-blocks","title":"Stream ended, process remaining text and flush incomplete blocks","text":"<p>final_events = processor.finalize() for event in final_events: ...     if isinstance(event, BlockErrorEvent): ...         print(f\"Incomplete block: {event.reason}\")</p>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.is_native_event","title":"is_native_event","text":"<pre><code>is_native_event(event: Any) -&gt; bool\n</code></pre> <p>Check if event is a native provider event (not a StreamBlocks event).</p> <p>This method provides provider-agnostic detection of native events. It checks if the event originates from the AI provider (Gemini, OpenAI, Anthropic, etc.) versus being a StreamBlocks event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>Event to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if event is from the native provider, False if it's a StreamBlocks</p> <code>bool</code> <p>event or if detection is not possible</p> Example <p>processor = StreamBlockProcessor(registry) async for event in processor.process_stream(gemini_stream): ...     if processor.is_native_event(event): ...         # Handle Gemini event (provider-agnostic!) ...         usage = getattr(event, 'usage_metadata', None) ...     elif isinstance(event, BlockEndEvent): ...         # Handle StreamBlocks event ...         print(f\"Block: {event.block_id}\")</p> Source code in <code>src/hother/streamblocks/core/processor.py</code> <pre><code>def is_native_event(self, event: Any) -&gt; bool:\n    \"\"\"Check if event is a native provider event (not a StreamBlocks event).\n\n    This method provides provider-agnostic detection of native events.\n    It checks if the event originates from the AI provider (Gemini, OpenAI,\n    Anthropic, etc.) versus being a StreamBlocks event.\n\n    Args:\n        event: Event to check\n\n    Returns:\n        True if event is from the native provider, False if it's a StreamBlocks\n        event or if detection is not possible\n\n    Example:\n        &gt;&gt;&gt; processor = StreamBlockProcessor(registry)\n        &gt;&gt;&gt; async for event in processor.process_stream(gemini_stream):\n        ...     if processor.is_native_event(event):\n        ...         # Handle Gemini event (provider-agnostic!)\n        ...         usage = getattr(event, 'usage_metadata', None)\n        ...     elif isinstance(event, BlockEndEvent):\n        ...         # Handle StreamBlocks event\n        ...         print(f\"Block: {event.block_id}\")\n    \"\"\"\n    # Check if it's a known StreamBlocks event\n    if isinstance(\n        event,\n        (\n            StreamStartedEvent,\n            StreamFinishedEvent,\n            TextContentEvent,\n            TextDeltaEvent,\n            BlockStartEvent,\n            BlockHeaderDeltaEvent,\n            BlockMetadataDeltaEvent,\n            BlockContentDeltaEvent,\n            BlockMetadataEndEvent,\n            BlockContentEndEvent,\n            BlockEndEvent,\n            BlockErrorEvent,\n        ),\n    ):\n        return False\n\n    # Check if we have an adapter with a module prefix\n    if self._adapter is None:\n        return False\n\n    # Use Protocol-based check for native module prefix\n    if not isinstance(self._adapter, HasNativeModulePrefix):\n        return False\n\n    # Check if event's module matches the adapter's prefix\n    return type(event).__module__.startswith(self._adapter.native_module_prefix)\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_agent_stream","title":"process_agent_stream  <code>async</code>","text":"<pre><code>process_agent_stream(\n    agent_stream: AsyncIterator[str],\n) -&gt; AsyncGenerator[str | BaseEvent]\n</code></pre> <p>Process streaming output from a PydanticAI agent.</p> <p>This method is specifically designed to handle the streaming output from agent.run_stream() or similar agent streaming methods.</p> <p>Parameters:</p> Name Type Description Default <code>agent_stream</code> <code>AsyncIterator[str]</code> <p>Async iterator from agent streaming (e.g., stream_text())</p> required <p>Yields:</p> Type Description <code>AsyncGenerator[str | BaseEvent]</code> <p>Mixed stream of:</p> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Original text chunks (if emit_original_events=True)</li> </ul> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Event objects as blocks are detected and extracted</li> </ul> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/processor.py</code> <pre><code>async def process_agent_stream(self, agent_stream: AsyncIterator[str]) -&gt; AsyncGenerator[str | BaseEvent]:\n    \"\"\"Process streaming output from a PydanticAI agent.\n\n    This method is specifically designed to handle the streaming output\n    from agent.run_stream() or similar agent streaming methods.\n\n    Args:\n        agent_stream: Async iterator from agent streaming (e.g., stream_text())\n\n    Yields:\n        Mixed stream of:\n        - Original text chunks (if emit_original_events=True)\n        - Event objects as blocks are detected and extracted\n    \"\"\"\n    async for event in self.process_stream(agent_stream):\n        yield event\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_agent_with_events","title":"process_agent_with_events  <code>async</code>","text":"<pre><code>process_agent_with_events(\n    agent_stream: AsyncIterator[str],\n    event_handler: Callable[[str | BaseEvent], Any]\n    | None = None,\n) -&gt; AsyncGenerator[str | BaseEvent]\n</code></pre> <p>Process agent stream with optional event handler for agent-specific events.</p> <p>This allows handling both StreamBlocks events and PydanticAI events in a unified manner.</p> <p>Parameters:</p> Name Type Description Default <code>agent_stream</code> <code>AsyncIterator[str]</code> <p>Async iterator from agent streaming</p> required <code>event_handler</code> <code>Callable[[str | BaseEvent], Any] | None</code> <p>Optional callback for handling events (both text chunks and Events)</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[str | BaseEvent]</code> <p>Mixed stream of:</p> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Original text chunks (if emit_original_events=True)</li> </ul> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Event objects with enhanced metadata</li> </ul> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/processor.py</code> <pre><code>async def process_agent_with_events(\n    self,\n    agent_stream: AsyncIterator[str],\n    event_handler: Callable[[str | BaseEvent], Any] | None = None,\n) -&gt; AsyncGenerator[str | BaseEvent]:\n    \"\"\"Process agent stream with optional event handler for agent-specific events.\n\n    This allows handling both StreamBlocks events and PydanticAI events\n    in a unified manner.\n\n    Args:\n        agent_stream: Async iterator from agent streaming\n        event_handler: Optional callback for handling events (both text chunks and Events)\n\n    Yields:\n        Mixed stream of:\n        - Original text chunks (if emit_original_events=True)\n        - Event objects with enhanced metadata\n    \"\"\"\n    async for event in self.process_agent_stream(agent_stream):\n        # Call event handler if provided\n        if event_handler:\n            await event_handler(event)\n\n        # Always yield the event\n        yield event\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_chunk","title":"process_chunk","text":"<pre><code>process_chunk(\n    chunk: TChunk,\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; list[TChunk | Event]\n</code></pre> <p>Process a single chunk and return resulting events.</p> <p>This method is stateful - it maintains internal state between calls. Call finalize() after processing all chunks to flush incomplete blocks.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>TChunk</code> <p>Single chunk to process</p> required <code>adapter</code> <code>InputProtocolAdapter[TChunk] | None</code> <p>Optional adapter for extracting text. If not provided and     auto_detect_adapter=True, will auto-detect on first chunk.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[TChunk | Event]</code> <p>List of events generated from this chunk. May be empty if chunk only</p> <code>list[TChunk | Event]</code> <p>accumulates text without completing any lines.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If adapter is not set after first chunk processing (internal state error, should not occur in normal usage).</p> Example <p>processor = StreamBlockProcessor(registry) response = await client.generate_content_stream(...) async for chunk in response: ...     events = processor.process_chunk(chunk) ...     for event in events: ...         if isinstance(event, BlockEndEvent): ...             print(f\"Block: {event.block_id}\") ...</p> Source code in <code>src/hother/streamblocks/core/processor.py</code> <pre><code>def process_chunk(\n    self,\n    chunk: TChunk,\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; list[TChunk | Event]:\n    \"\"\"Process a single chunk and return resulting events.\n\n    This method is stateful - it maintains internal state between calls.\n    Call finalize() after processing all chunks to flush incomplete blocks.\n\n    Args:\n        chunk: Single chunk to process\n        adapter: Optional adapter for extracting text. If not provided and\n                auto_detect_adapter=True, will auto-detect on first chunk.\n\n    Returns:\n        List of events generated from this chunk. May be empty if chunk only\n        accumulates text without completing any lines.\n\n    Raises:\n        RuntimeError: If adapter is not set after first chunk processing\n            (internal state error, should not occur in normal usage).\n\n    Example:\n        &gt;&gt;&gt; processor = StreamBlockProcessor(registry)\n        &gt;&gt;&gt; response = await client.generate_content_stream(...)\n        &gt;&gt;&gt; async for chunk in response:\n        ...     events = processor.process_chunk(chunk)\n        ...     for event in events:\n        ...         if isinstance(event, BlockEndEvent):\n        ...             print(f\"Block: {event.block_id}\")\n        ...\n        &gt;&gt;&gt; # Finalize at stream end\n        &gt;&gt;&gt; final_events = processor.finalize()\n        &gt;&gt;&gt; for event in final_events:\n        ...     if isinstance(event, BlockErrorEvent):\n        ...         print(f\"Incomplete block: {event.reason}\")\n    \"\"\"\n    events: list[TChunk | Event] = []\n\n    # Auto-detect adapter on first chunk\n    self._ensure_adapter(chunk, adapter)\n\n    # Emit original chunk (passthrough)\n    if self.config.emit_original_events and not isinstance(self._adapter, IdentityInputAdapter):\n        events.append(chunk)\n\n    # Extract text from chunk\n    if self._adapter is None:\n        msg = \"Adapter should be set after first chunk processing\"\n        raise RuntimeError(msg)\n    text = self._adapter.extract_text(chunk)  # type: ignore[arg-type]\n\n    if not text:\n        return events\n\n    # Log stream processing start on first chunk with text\n    if self._line_accumulator.line_number == 0 and not self._line_accumulator.has_pending_text:\n        self.logger.debug(\n            \"stream_processing_started\",\n            syntax=get_syntax_name(self.syntax),\n            lines_buffer=self.config.lines_buffer,\n            max_block_size=self.config.max_block_size,\n        )\n\n    # Emit text delta for real-time streaming\n    if self.config.emit_text_deltas:\n        events.append(self._create_text_delta_event(text))\n\n    # Process text through line accumulator and block state machine\n    for line_number, line in self._line_accumulator.add_text(text):\n        line_events = self._block_machine.process_line(line, line_number)\n        self._update_stats(line_events)\n        events.extend(line_events)\n\n    return events\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_chunk--finalize-at-stream-end","title":"Finalize at stream end","text":"<p>final_events = processor.finalize() for event in final_events: ...     if isinstance(event, BlockErrorEvent): ...         print(f\"Incomplete block: {event.reason}\")</p>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_stream","title":"process_stream  <code>async</code>","text":"<pre><code>process_stream(\n    stream: AsyncIterator[TChunk],\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; AsyncGenerator[TChunk | Event]\n</code></pre> <p>Process stream and yield mixed events.</p> <p>This method processes chunks from any stream format, extracting text via an adapter and emitting both original chunks (if enabled) and StreamBlocks events.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>AsyncIterator[TChunk]</code> <p>Async iterator yielding chunks (text or objects)</p> required <code>adapter</code> <code>InputProtocolAdapter[TChunk] | None</code> <p>Optional adapter for extracting text from chunks.     If None and auto_detect_adapter=True, will auto-detect from first chunk.</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[TChunk | Event]</code> <p>Mixed stream of:</p> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>Original chunks (if emit_original_events=True)</li> </ul> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>TextDeltaEvent (if emit_text_deltas=True)</li> </ul> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>TextContentEvent, BlockStartEvent, BlockEndEvent, BlockErrorEvent, and section delta events</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If adapter is not set after first chunk processing (internal state error, should not occur in normal usage).</p> Example Source code in <code>src/hother/streamblocks/core/processor.py</code> <pre><code>async def process_stream(\n    self,\n    stream: AsyncIterator[TChunk],\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; AsyncGenerator[TChunk | Event]:\n    \"\"\"Process stream and yield mixed events.\n\n    This method processes chunks from any stream format, extracting text\n    via an adapter and emitting both original chunks (if enabled) and\n    StreamBlocks events.\n\n    Args:\n        stream: Async iterator yielding chunks (text or objects)\n        adapter: Optional adapter for extracting text from chunks.\n                If None and auto_detect_adapter=True, will auto-detect from first chunk.\n\n    Yields:\n        Mixed stream of:\n        - Original chunks (if emit_original_events=True)\n        - TextDeltaEvent (if emit_text_deltas=True)\n        - TextContentEvent, BlockStartEvent, BlockEndEvent, BlockErrorEvent, and section delta events\n\n    Raises:\n        RuntimeError: If adapter is not set after first chunk processing\n            (internal state error, should not occur in normal usage).\n\n    Example:\n        &gt;&gt;&gt; # Plain text\n        &gt;&gt;&gt; async for event in processor.process_stream(text_stream):\n        ...     if isinstance(event, BlockEndEvent):\n        ...         print(f\"Extracted: {event.block_id}\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # With Gemini adapter (auto-detected)\n        &gt;&gt;&gt; async for event in processor.process_stream(gemini_stream):\n        ...     if hasattr(event, 'usage_metadata'):\n        ...         print(f\"Tokens: {event.usage_metadata}\")\n        ...     elif isinstance(event, BlockEndEvent):\n        ...         print(f\"Extracted: {event.block_id}\")\n    \"\"\"\n    # Set adapter if provided\n    if adapter:\n        self._adapter = adapter\n        self._first_chunk_processed = True\n\n    async for chunk in stream:\n        # Auto-detection on first chunk\n        self._ensure_adapter(chunk, None)\n\n        # Emit original chunk (passthrough)\n        if self.config.emit_original_events and not isinstance(self._adapter, IdentityInputAdapter):\n            yield chunk\n\n        # Extract text from chunk\n        if self._adapter is None:\n            msg = \"Adapter should be set after first chunk processing\"\n            raise RuntimeError(msg)\n        text = self._adapter.extract_text(chunk)  # type: ignore[arg-type]\n\n        if not text:\n            continue\n\n        # Log stream processing start on first chunk with text\n        if self._line_accumulator.line_number == 0 and not self._line_accumulator.has_pending_text:\n            self.logger.debug(\n                \"stream_processing_started\",\n                syntax=get_syntax_name(self.syntax),\n                lines_buffer=self.config.lines_buffer,\n                max_block_size=self.config.max_block_size,\n            )\n\n        # Emit text delta for real-time streaming\n        if self.config.emit_text_deltas:\n            yield self._create_text_delta_event(text)\n\n        # Process text through line accumulator and block state machine\n        for line_number, line in self._line_accumulator.add_text(text):\n            for event in self._block_machine.process_line(line, line_number):\n                self._update_stats([event])\n                yield event\n\n    # Process any remaining accumulated text as a final line\n    final_line = self._line_accumulator.finalize()\n    if final_line:\n        line_number, line = final_line\n        for event in self._block_machine.process_line(line, line_number):\n            self._update_stats([event])\n            yield event\n\n    # Flush remaining candidates at stream end\n    for event in self._block_machine.flush(self._line_accumulator.line_number):\n        self._update_stats([event])\n        yield event\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_stream--plain-text","title":"Plain text","text":"<p>async for event in processor.process_stream(text_stream): ...     if isinstance(event, BlockEndEvent): ...         print(f\"Extracted: {event.block_id}\")</p>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.AgentStreamProcessor.process_stream--with-gemini-adapter-auto-detected","title":"With Gemini adapter (auto-detected)","text":"<p>async for event in processor.process_stream(gemini_stream): ...     if hasattr(event, 'usage_metadata'): ...         print(f\"Tokens: {event.usage_metadata}\") ...     elif isinstance(event, BlockEndEvent): ...         print(f\"Extracted: {event.block_id}\")</p>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent","title":"BlockAwareAgent","text":"<p>PydanticAI agent that generates StreamBlocks-compatible output.</p> <p>This wrapper makes a PydanticAI agent aware of StreamBlocks syntaxes, allowing it to generate structured blocks that can be extracted in real-time.</p> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/agent.py</code> <pre><code>class BlockAwareAgent:\n    \"\"\"PydanticAI agent that generates StreamBlocks-compatible output.\n\n    This wrapper makes a PydanticAI agent aware of StreamBlocks syntaxes,\n    allowing it to generate structured blocks that can be extracted in real-time.\n    \"\"\"\n\n    def __init__(\n        self,\n        registry: Registry,\n        model: str | Agent | None = None,\n        system_prompt: str | None = None,\n        **agent_kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Initialize a block-aware agent.\n\n        Args:\n            registry: StreamBlocks registry containing syntax definitions\n            model: Model name (e.g., 'openai:gpt-4o') or existing Agent instance\n            system_prompt: System prompt for the agent (required if creating new agent)\n            **agent_kwargs: Additional arguments to pass to Agent constructor\n        \"\"\"\n        # Create or use existing agent\n        if isinstance(model, Agent):\n            self.agent = model\n        else:\n            # Use provided system_prompt\n            if system_prompt:\n                agent_kwargs[\"system_prompt\"] = system_prompt\n            self.agent = Agent(model or \"openai:gpt-4o\", **agent_kwargs)\n\n        # Setup registry and processor\n        self.registry = registry\n        self.processor = AgentStreamProcessor(registry)\n\n    async def run_with_blocks(\n        self,\n        user_prompt: str,\n        message_history: Any = None,\n        deps: Any = None,\n        **kwargs: Any,\n    ) -&gt; AsyncGenerator[str | BaseEvent]:\n        \"\"\"Run the agent and stream blocks in real-time.\n\n        Args:\n            user_prompt: The user's prompt to the agent\n            message_history: Optional conversation history\n            deps: Optional dependencies for the agent\n            **kwargs: Additional arguments for agent.run_stream()\n\n        Yields:\n            Mixed stream of:\n            - Original text chunks (if emit_original_events=True)\n            - Event objects as blocks are detected and extracted\n        \"\"\"\n\n        # Start agent streaming\n        async with self.agent.run_stream(\n            user_prompt, message_history=message_history, deps=deps, **kwargs\n        ) as stream_result:\n            # Create text stream from agent\n            # Use PydanticAI's native delta streaming feature\n            async def agent_text_stream() -&gt; AsyncIterator[str]:\n                async for delta_text in stream_result.stream_text(delta=True):\n                    yield delta_text\n\n            # Process through StreamBlocks\n            async for event in self.processor.process_agent_stream(agent_text_stream()):\n                yield event\n\n    async def run(\n        self,\n        user_prompt: str,\n        message_history: Any = None,\n        deps: Any = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Run the agent without block extraction (standard PydanticAI interface).\n\n        This method provides compatibility with the standard PydanticAI Agent interface.\n\n        Args:\n            user_prompt: The user's prompt to the agent\n            message_history: Optional conversation history\n            deps: Optional dependencies for the agent\n            **kwargs: Additional arguments for agent.run()\n\n        Returns:\n            The agent's response\n        \"\"\"\n        return await self.agent.run(user_prompt, message_history=message_history, deps=deps, **kwargs)\n\n    def run_sync(\n        self,\n        user_prompt: str,\n        message_history: Any = None,\n        deps: Any = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Run the agent synchronously without block extraction.\n\n        This method provides compatibility with the standard PydanticAI Agent interface.\n\n        Args:\n            user_prompt: The user's prompt to the agent\n            message_history: Optional conversation history\n            deps: Optional dependencies for the agent\n            **kwargs: Additional arguments for agent.run_sync()\n\n        Returns:\n            The agent's response\n        \"\"\"\n        return self.agent.run_sync(user_prompt, message_history=message_history, deps=deps, **kwargs)\n\n    def __getattr__(self, name: str) -&gt; Any:\n        \"\"\"Forward unknown attributes to the underlying agent.\n\n        This allows the BlockAwareAgent to act as a transparent wrapper.\n\n        Args:\n            name: Attribute name\n\n        Returns:\n            The attribute from the underlying agent\n        \"\"\"\n        return getattr(self.agent, name)\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.agent","title":"agent  <code>instance-attribute</code>","text":"<pre><code>agent = model\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.processor","title":"processor  <code>instance-attribute</code>","text":"<pre><code>processor = AgentStreamProcessor(registry)\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.registry","title":"registry  <code>instance-attribute</code>","text":"<pre><code>registry = registry\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.run","title":"run  <code>async</code>","text":"<pre><code>run(\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; Any\n</code></pre> <p>Run the agent without block extraction (standard PydanticAI interface).</p> <p>This method provides compatibility with the standard PydanticAI Agent interface.</p> <p>Parameters:</p> Name Type Description Default <code>user_prompt</code> <code>str</code> <p>The user's prompt to the agent</p> required <code>message_history</code> <code>Any</code> <p>Optional conversation history</p> <code>None</code> <code>deps</code> <code>Any</code> <p>Optional dependencies for the agent</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for agent.run()</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The agent's response</p> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/agent.py</code> <pre><code>async def run(\n    self,\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Run the agent without block extraction (standard PydanticAI interface).\n\n    This method provides compatibility with the standard PydanticAI Agent interface.\n\n    Args:\n        user_prompt: The user's prompt to the agent\n        message_history: Optional conversation history\n        deps: Optional dependencies for the agent\n        **kwargs: Additional arguments for agent.run()\n\n    Returns:\n        The agent's response\n    \"\"\"\n    return await self.agent.run(user_prompt, message_history=message_history, deps=deps, **kwargs)\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.run_sync","title":"run_sync","text":"<pre><code>run_sync(\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; Any\n</code></pre> <p>Run the agent synchronously without block extraction.</p> <p>This method provides compatibility with the standard PydanticAI Agent interface.</p> <p>Parameters:</p> Name Type Description Default <code>user_prompt</code> <code>str</code> <p>The user's prompt to the agent</p> required <code>message_history</code> <code>Any</code> <p>Optional conversation history</p> <code>None</code> <code>deps</code> <code>Any</code> <p>Optional dependencies for the agent</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for agent.run_sync()</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The agent's response</p> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/agent.py</code> <pre><code>def run_sync(\n    self,\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Run the agent synchronously without block extraction.\n\n    This method provides compatibility with the standard PydanticAI Agent interface.\n\n    Args:\n        user_prompt: The user's prompt to the agent\n        message_history: Optional conversation history\n        deps: Optional dependencies for the agent\n        **kwargs: Additional arguments for agent.run_sync()\n\n    Returns:\n        The agent's response\n    \"\"\"\n    return self.agent.run_sync(user_prompt, message_history=message_history, deps=deps, **kwargs)\n</code></pre>"},{"location":"integrations/pydantic_ai/#hother.streamblocks.integrations.pydantic_ai.BlockAwareAgent.run_with_blocks","title":"run_with_blocks  <code>async</code>","text":"<pre><code>run_with_blocks(\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; AsyncGenerator[str | BaseEvent]\n</code></pre> <p>Run the agent and stream blocks in real-time.</p> <p>Parameters:</p> Name Type Description Default <code>user_prompt</code> <code>str</code> <p>The user's prompt to the agent</p> required <code>message_history</code> <code>Any</code> <p>Optional conversation history</p> <code>None</code> <code>deps</code> <code>Any</code> <p>Optional dependencies for the agent</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for agent.run_stream()</p> <code>{}</code> <p>Yields:</p> Type Description <code>AsyncGenerator[str | BaseEvent]</code> <p>Mixed stream of:</p> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Original text chunks (if emit_original_events=True)</li> </ul> <code>AsyncGenerator[str | BaseEvent]</code> <ul> <li>Event objects as blocks are detected and extracted</li> </ul> Source code in <code>src/hother/streamblocks/integrations/pydantic_ai/agent.py</code> <pre><code>async def run_with_blocks(\n    self,\n    user_prompt: str,\n    message_history: Any = None,\n    deps: Any = None,\n    **kwargs: Any,\n) -&gt; AsyncGenerator[str | BaseEvent]:\n    \"\"\"Run the agent and stream blocks in real-time.\n\n    Args:\n        user_prompt: The user's prompt to the agent\n        message_history: Optional conversation history\n        deps: Optional dependencies for the agent\n        **kwargs: Additional arguments for agent.run_stream()\n\n    Yields:\n        Mixed stream of:\n        - Original text chunks (if emit_original_events=True)\n        - Event objects as blocks are detected and extracted\n    \"\"\"\n\n    # Start agent streaming\n    async with self.agent.run_stream(\n        user_prompt, message_history=message_history, deps=deps, **kwargs\n    ) as stream_result:\n        # Create text stream from agent\n        # Use PydanticAI's native delta streaming feature\n        async def agent_text_stream() -&gt; AsyncIterator[str]:\n            async for delta_text in stream_result.stream_text(delta=True):\n                yield delta_text\n\n        # Process through StreamBlocks\n        async for event in self.processor.process_agent_stream(agent_text_stream()):\n            yield event\n</code></pre>"},{"location":"reference/","title":"Overview","text":""},{"location":"reference/#api-reference","title":"API Reference","text":"<p>Complete API documentation for Streamblocks.</p>"},{"location":"reference/#module-overview","title":"Module Overview","text":"<pre><code>flowchart TB\n    subgraph Public[\"Public API (streamblocks)\"]\n        Processor[StreamBlockProcessor]\n        Registry[Registry]\n        Events[Event Types]\n        Blocks[Block Models]\n        Syntaxes[Syntaxes]\n        Adapters[Adapters]\n    end\n\n    subgraph Extensions[\"Extensions\"]\n        Gemini[gemini]\n        OpenAI[openai]\n        Anthropic[anthropic]\n        AGUI[agui]\n    end\n\n    Processor --&gt; Registry\n    Processor --&gt; Events\n    Registry --&gt; Blocks\n    Processor --&gt; Syntaxes\n    Processor --&gt; Adapters\n\n    Extensions --&gt; Adapters</code></pre>"},{"location":"reference/#core-modules","title":"Core Modules","text":""},{"location":"reference/#core-components","title":"Core Components","text":"<p>The main processing engine and core types:</p> Class Description <code>StreamBlockProcessor</code> Main processing engine for extracting blocks <code>Registry</code> Block type registry with validation <code>StreamState</code> Processing state enumeration <code>ValidationResult</code> Validation outcome with errors"},{"location":"reference/#event-types","title":"Event Types","text":"<p>All events emitted during stream processing:</p> Event Description <code>StreamStartedEvent</code> Stream processing began <code>StreamFinishedEvent</code> Stream processing completed <code>BlockStartEvent</code> Block opening detected <code>BlockEndEvent</code> Block successfully extracted <code>BlockErrorEvent</code> Block extraction failed <code>TextDeltaEvent</code> Real-time text chunk"},{"location":"reference/#block-models","title":"Block Models","text":"<p>Block structure and models:</p> Class Description <code>Block</code> Generic block type definition <code>ExtractedBlock</code> Extracted block with typed content <code>BlockCandidate</code> Block during parsing <code>BaseMetadata</code> Base metadata model <code>BaseContent</code> Base content model"},{"location":"reference/#syntaxes","title":"Syntaxes","text":"<p>Block syntax definitions:</p> Class Description <code>DelimiterPreambleSyntax</code> <code>!!id:type</code> inline syntax <code>DelimiterFrontmatterSyntax</code> Delimiter with YAML frontmatter <code>MarkdownFrontmatterSyntax</code> Markdown <code>---</code> frontmatter"},{"location":"reference/#adapters","title":"Adapters","text":"<p>Stream adapters for AI providers:</p> Class Description <code>InputProtocolAdapter</code> Protocol for input adapters <code>OutputProtocolAdapter</code> Protocol for output adapters <code>BidirectionalAdapter</code> Combined input/output adapter <code>EventCategory</code> Event classification enum"},{"location":"reference/#extensions","title":"Extensions","text":"<p>Provider-specific extensions:</p> Module Description <code>hother.streamblocks.extensions.gemini</code> Google Gemini adapter <code>hother.streamblocks.extensions.openai</code> OpenAI adapter <code>hother.streamblocks.extensions.anthropic</code> Anthropic adapter <code>hother.streamblocks.extensions.agui</code> AG-UI protocol adapters"},{"location":"reference/#import-patterns","title":"Import Patterns","text":""},{"location":"reference/#standard-import","title":"Standard Import","text":"<pre><code>from hother.streamblocks import (\n    StreamBlockProcessor,\n    Registry,\n    EventType,\n    BlockEndEvent,\n    DelimiterPreambleSyntax,\n)\n</code></pre>"},{"location":"reference/#extension-import","title":"Extension Import","text":"<pre><code># Gemini adapter\nfrom hother.streamblocks.extensions.gemini import GeminiInputAdapter\n\n# AG-UI adapters\nfrom hother.streamblocks.extensions.agui import AGUIInputAdapter, AGUIOutputAdapter\n</code></pre>"},{"location":"reference/#type-only-import","title":"Type-Only Import","text":"<pre><code>from typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from hother.streamblocks import Event, ExtractedBlock\n</code></pre>"},{"location":"reference/#quick-reference","title":"Quick Reference","text":""},{"location":"reference/#basic-usage","title":"Basic Usage","text":"<pre><code>from hother.streamblocks import (\n    StreamBlockProcessor,\n    Registry,\n    DelimiterPreambleSyntax,\n    EventType,\n)\n\n# Create registry and processor\nregistry = Registry()\nprocessor = StreamBlockProcessor(\n    registry=registry,\n    syntaxes=[DelimiterPreambleSyntax()],\n)\n\n# Process stream\nasync for event in processor.process_stream(stream):\n    if event.type == EventType.BLOCK_END:\n        print(f\"Block: {event.block_type}\")\n</code></pre>"},{"location":"reference/#with-provider-adapter","title":"With Provider Adapter","text":"<pre><code>from hother.streamblocks import StreamBlockProcessor, Registry, DelimiterPreambleSyntax\nfrom hother.streamblocks.extensions.gemini import GeminiInputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=GeminiInputAdapter(),\n)\n</code></pre>"},{"location":"reference/#type-system","title":"Type System","text":"<p>Streamblocks uses Python 3.13+ type system extensively:</p> <pre><code>from hother.streamblocks import Block, BaseMetadata, BaseContent\nfrom typing import Literal\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\nclass TaskContent(BaseContent):\n    pass\n\n# Generic block type\nTaskBlock = Block[TaskMetadata, TaskContent]\n</code></pre>"},{"location":"reference/#related-documentation","title":"Related Documentation","text":"<ul> <li>Basics - Core concepts</li> <li>Events - Event handling</li> <li>Blocks - Block types</li> <li>Patterns - Common patterns</li> </ul>"},{"location":"reference/adapters/","title":"Adapters","text":""},{"location":"reference/adapters/#adapters","title":"Adapters","text":"<p>Stream adapters for converting provider-specific formats.</p>"},{"location":"reference/adapters/#overview","title":"Overview","text":"<p>Adapters convert provider-specific stream formats into text chunks that Streamblocks can process. Each adapter implements a callable interface that transforms the input stream.</p>"},{"location":"reference/adapters/#provider-adapters","title":"Provider Adapters","text":""},{"location":"reference/adapters/#geminiadapter","title":"GeminiAdapter","text":"<p>Adapter for Google Gemini streams.</p> <pre><code>from hother.streamblocks.adapters import GeminiAdapter\n\nadapter = GeminiAdapter()\nasync for event in processor.process_stream(adapter(gemini_response)):\n    ...\n</code></pre>"},{"location":"reference/adapters/#openaiadapter","title":"OpenAIAdapter","text":"<p>Adapter for OpenAI streams.</p> <pre><code>from hother.streamblocks.adapters import OpenAIAdapter\n\nadapter = OpenAIAdapter()\nasync for event in processor.process_stream(adapter(openai_response)):\n    ...\n</code></pre>"},{"location":"reference/adapters/#anthropicadapter","title":"AnthropicAdapter","text":"<p>Adapter for Anthropic streams.</p> <pre><code>from hother.streamblocks.adapters import AnthropicAdapter\n\nadapter = AnthropicAdapter()\nasync for event in processor.process_stream(adapter(anthropic_stream)):\n    ...\n</code></pre>"},{"location":"reference/adapters/#auto-detection","title":"Auto-Detection","text":"<p>Streamblocks can automatically detect the appropriate adapter:</p> <pre><code>from hother.streamblocks.adapters import auto_detect_adapter\n\nadapter = auto_detect_adapter(response)\nif adapter:\n    async for event in processor.process_stream(adapter(response)):\n        ...\n</code></pre>"},{"location":"reference/adapters/#creating-custom-adapters","title":"Creating Custom Adapters","text":"<p>Create custom adapters by implementing a callable that yields text chunks:</p> <pre><code>class MyProviderAdapter:\n    def __call__(self, stream):\n        for chunk in stream:\n            # Extract text from provider-specific format\n            yield chunk.text\n</code></pre>"},{"location":"reference/adapters/#api-reference","title":"API Reference","text":""},{"location":"reference/adapters/#hother.streamblocks.adapters","title":"hother.streamblocks.adapters","text":"<p>Stream adapters for bidirectional protocol transformation.</p> <p>This module provides the adapter system for transforming between different input and output protocols.</p> <p>Key Components: - EventCategory: Categorize events for routing (TEXT_CONTENT, PASSTHROUGH, SKIP) - InputProtocolAdapter: Protocol for input transformation - OutputProtocolAdapter: Protocol for output transformation - InputAdapterRegistry: Auto-detection of input adapters</p> Example <p>from hother.streamblocks.adapters import EventCategory, InputAdapterRegistry from hother.streamblocks.adapters.input import IdentityInputAdapter from hother.streamblocks.adapters.output import StreamBlocksOutputAdapter</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.EventCategory","title":"EventCategory","text":"<p>               Bases: <code>StrEnum</code></p> <p>Semantic categorization of protocol events.</p> <p>These three categories are EXHAUSTIVE - every protocol event falls into one:</p> <ul> <li>TEXT_CONTENT: Event contains text that should be processed by StreamBlocks</li> <li>PASSTHROUGH: Event should pass through unchanged to output</li> <li>SKIP: Event should not be emitted in output at all</li> </ul>"},{"location":"reference/adapters/#hother.streamblocks.adapters.EventCategory.TEXT_CONTENT","title":"TEXT_CONTENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_CONTENT = 'text_content'\n</code></pre> <p>Event contains text content that should be processed by StreamBlocks.</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.EventCategory.PASSTHROUGH","title":"PASSTHROUGH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PASSTHROUGH = 'passthrough'\n</code></pre> <p>Event has no text content and should pass through unchanged to output.</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.EventCategory.SKIP","title":"SKIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIP = 'skip'\n</code></pre> <p>Event should not be included in output at all.</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry","title":"InputAdapterRegistry","text":"<p>Registry for input adapter auto-detection.</p> <p>Uses module prefix matching and attribute-based fallback detection. Extensions register themselves when imported.</p> Example"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry--register-via-decorator","title":"Register via decorator","text":"<p>@InputAdapterRegistry.register(module_prefix=\"openai.\") ... class OpenAIInputAdapter: ...     def categorize(self, event) -&gt; EventCategory: ...         return EventCategory.TEXT_CONTENT ...     def extract_text(self, event) -&gt; str | None: ...         return event.choices[0].delta.content</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry--register-via-method","title":"Register via method","text":"<p>InputAdapterRegistry.register_module(\"mycompany.api\", MyCustomAdapter)</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry--detect-adapter-from-sample","title":"Detect adapter from sample","text":"<p>adapter = InputAdapterRegistry.detect(sample_chunk)</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.register","title":"register  <code>classmethod</code>","text":"<pre><code>register(\n    *,\n    module_prefix: str | None = None,\n    attributes: list[str] | None = None,\n) -&gt; Callable[\n    [type[InputProtocolAdapter[Any]]],\n    type[InputProtocolAdapter[Any]],\n]\n</code></pre> <p>Decorator to register an adapter for auto-detection.</p> <p>Parameters:</p> Name Type Description Default <code>module_prefix</code> <code>str | None</code> <p>Module path prefix to match (e.g., \"openai.types\")</p> <code>None</code> <code>attributes</code> <code>list[str] | None</code> <p>Required attributes for attribute-based detection</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[type[InputProtocolAdapter[Any]]], type[InputProtocolAdapter[Any]]]</code> <p>Decorator function</p> Example <p>@InputAdapterRegistry.register(module_prefix=\"openai.\") ... class OpenAIInputAdapter: ...     ...</p> <p>@InputAdapterRegistry.register(attributes=[\"text\", \"candidates\"]) ... class GeminiInputAdapter: ...     ...</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.register_module","title":"register_module  <code>classmethod</code>","text":"<pre><code>register_module(\n    prefix: str,\n    adapter_class: type[InputProtocolAdapter[Any]],\n) -&gt; None\n</code></pre> <p>Register adapter by module prefix (non-decorator form).</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Module path prefix to match</p> required <code>adapter_class</code> <code>type[InputProtocolAdapter[Any]]</code> <p>Adapter class to instantiate when matched</p> required"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.register_pattern","title":"register_pattern  <code>classmethod</code>","text":"<pre><code>register_pattern(\n    attrs: list[str],\n    adapter_class: type[InputProtocolAdapter[Any]],\n) -&gt; None\n</code></pre> <p>Register adapter by attribute pattern (non-decorator form).</p> <p>Parameters:</p> Name Type Description Default <code>attrs</code> <code>list[str]</code> <p>Required attributes for detection</p> required <code>adapter_class</code> <code>type[InputProtocolAdapter[Any]]</code> <p>Adapter class to instantiate when matched</p> required"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.detect","title":"detect  <code>classmethod</code>","text":"<pre><code>detect(chunk: Any) -&gt; InputProtocolAdapter[Any] | None\n</code></pre> <p>Detect and instantiate appropriate adapter from chunk.</p> <p>Detection order: 1. String \u2192 IdentityInputAdapter 2. Module prefix match 3. Attribute pattern match 4. Fallback to text/content attribute 5. None if no match</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>Any</code> <p>Sample chunk from stream</p> required <p>Returns:</p> Type Description <code>InputProtocolAdapter[Any] | None</code> <p>Adapter instance if detected, None otherwise</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.get_registered_modules","title":"get_registered_modules  <code>classmethod</code>","text":"<pre><code>get_registered_modules() -&gt; dict[\n    str, type[InputProtocolAdapter[Any]]\n]\n</code></pre> <p>Get all registered module prefixes.</p> <p>Returns:</p> Type Description <code>dict[str, type[InputProtocolAdapter[Any]]]</code> <p>Copy of module prefix registry</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.get_registered_patterns","title":"get_registered_patterns  <code>classmethod</code>","text":"<pre><code>get_registered_patterns() -&gt; list[\n    tuple[list[str], type[InputProtocolAdapter[Any]]]\n]\n</code></pre> <p>Get all registered attribute patterns.</p> <p>Returns:</p> Type Description <code>list[tuple[list[str], type[InputProtocolAdapter[Any]]]]</code> <p>Copy of attribute pattern registry</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputAdapterRegistry.clear","title":"clear  <code>classmethod</code>","text":"<pre><code>clear() -&gt; None\n</code></pre> <p>Clear all registered adapters (useful for testing).</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.BidirectionalAdapter","title":"BidirectionalAdapter","text":"<p>               Bases: <code>Protocol[TInput, TOutput]</code></p> <p>Combined bidirectional adapter for full protocol transformation.</p> <p>This is a convenience pattern - users can also use separate adapters.</p> Example <p>class MyBidirectionalAdapter: ...     def init(self): ...         self._input = MyInputAdapter() ...         self._output = MyOutputAdapter() ... ...     @property ...     def input_adapter(self) -&gt; MyInputAdapter: ...         return self._input ... ...     @property ...     def output_adapter(self) -&gt; MyOutputAdapter: ...         return self._output</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.BidirectionalAdapter.input_adapter","title":"input_adapter  <code>property</code>","text":"<pre><code>input_adapter: InputProtocolAdapter[TInput]\n</code></pre> <p>Input protocol adapter.</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.BidirectionalAdapter.output_adapter","title":"output_adapter  <code>property</code>","text":"<pre><code>output_adapter: OutputProtocolAdapter[TOutput]\n</code></pre> <p>Output protocol adapter.</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputProtocolAdapter","title":"InputProtocolAdapter","text":"<p>               Bases: <code>Protocol[TInput]</code></p> <p>Protocol for transforming input events for StreamBlocks processing.</p> <p>Handles any input format: chunks (OpenAI), events (AG-UI), or custom.</p> Example <p>class MyInputAdapter: ...     def categorize(self, event: MyEvent) -&gt; EventCategory: ...         if event.has_text: ...             return EventCategory.TEXT_CONTENT ...         return EventCategory.PASSTHROUGH ... ...     def extract_text(self, event: MyEvent) -&gt; str | None: ...         return event.text</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputProtocolAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: TInput) -&gt; EventCategory\n</code></pre> <p>Categorize event for routing.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>TInput</code> <p>Input event to categorize</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <ul> <li>TEXT_CONTENT: Event contains text, process with StreamBlocks</li> </ul> <code>EventCategory</code> <ul> <li>PASSTHROUGH: Pass through to output unchanged</li> </ul> <code>EventCategory</code> <ul> <li>SKIP: Don't include in output</li> </ul>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputProtocolAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: TInput) -&gt; str | None\n</code></pre> <p>Extract text content from TEXT_CONTENT events.</p> <p>Only called for events categorized as TEXT_CONTENT.</p> <p>This method can perform any complex extraction/computation: - Simple field access: return event.text - Nested extraction: return event.data.content.text - Multiple fields: return f\"{event.prefix}{event.body}\" - Decoding: return base64.decode(event.encoded_text) - JSON extraction: return json.loads(event.payload)[\"message\"]</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>TInput</code> <p>Input event to extract text from</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Extracted text, or None if no text available</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputProtocolAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(event: TInput) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract protocol-specific metadata from event (optional).</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>TInput</code> <p>Input event to extract metadata from</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary of metadata, or None</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.InputProtocolAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: TInput) -&gt; bool\n</code></pre> <p>Check if this event signals stream completion (optional).</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>TInput</code> <p>Input event to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this is the final event in the stream</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.OutputProtocolAdapter","title":"OutputProtocolAdapter","text":"<p>               Bases: <code>Protocol[TOutput]</code></p> <p>Protocol for transforming StreamBlocks events to output format.</p> <p>Can emit to any protocol: AG-UI, custom events, plain text, etc.</p> Example <p>class MyOutputAdapter: ...     def to_protocol_event(self, event: BaseEvent) -&gt; MyEvent | None: ...         if isinstance(event, BlockEndEvent): ...             return MyEvent(type=\"block\", data=event.get_block()) ...         return None ... ...     def passthrough(self, original_event: Any) -&gt; MyEvent | None: ...         return MyEvent(type=\"passthrough\", data=original_event)</p>"},{"location":"reference/adapters/#hother.streamblocks.adapters.OutputProtocolAdapter.to_protocol_event","title":"to_protocol_event","text":"<pre><code>to_protocol_event(\n    event: BaseEvent,\n) -&gt; TOutput | list[TOutput] | None\n</code></pre> <p>Convert a StreamBlocks event to output protocol event(s).</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>StreamBlocks event to convert</p> required <p>Returns:</p> Type Description <code>TOutput | list[TOutput] | None</code> <ul> <li>Single event</li> </ul> <code>TOutput | list[TOutput] | None</code> <ul> <li>List of events (for protocols requiring start/content/end pattern)</li> </ul> <code>TOutput | list[TOutput] | None</code> <ul> <li>None to skip emission</li> </ul>"},{"location":"reference/adapters/#hother.streamblocks.adapters.OutputProtocolAdapter.passthrough","title":"passthrough","text":"<pre><code>passthrough(original_event: Any) -&gt; TOutput | None\n</code></pre> <p>Handle passthrough events.</p> <p>Called for events categorized as PASSTHROUGH by the input adapter.</p> <p>Parameters:</p> Name Type Description Default <code>original_event</code> <code>Any</code> <p>Original input event to pass through</p> required <p>Returns:</p> Type Description <code>TOutput | None</code> <ul> <li>The event in output protocol format</li> </ul> <code>TOutput | None</code> <ul> <li>None if this adapter can't handle the event type</li> </ul>"},{"location":"reference/adapters/#hother.streamblocks.adapters.detect_input_adapter","title":"detect_input_adapter","text":"<pre><code>detect_input_adapter(\n    sample: Any,\n) -&gt; InputProtocolAdapter[Any]\n</code></pre> <p>Detect input adapter from sample event.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Any</code> <p>A sample event from the stream</p> required <p>Returns:</p> Type Description <code>InputProtocolAdapter[Any]</code> <p>Detected adapter instance</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no adapter matches the sample</p>"},{"location":"reference/blocks/","title":"Blocks","text":""},{"location":"reference/blocks/#blocks","title":"Blocks","text":"<p>Block type definitions and models.</p>"},{"location":"reference/blocks/#core-models","title":"Core Models","text":""},{"location":"reference/blocks/#block","title":"Block","text":"<p>The main block model representing extracted content:</p> <pre><code>from hother.streamblocks.core.models import Block\n\nblock = Block(\n    block_type=\"message\",\n    metadata={\"author\": \"assistant\"},\n    content=\"Hello, how can I help you?\"\n)\n\n# Access properties\nprint(block.block_type)  # \"message\"\nprint(block.content)     # \"Hello, how can I help you?\"\nprint(block.metadata)    # {\"author\": \"assistant\"}\n</code></pre>"},{"location":"reference/blocks/#blockcandidate","title":"BlockCandidate","text":"<p>Represents a potential block during parsing:</p> <pre><code>from hother.streamblocks.core.models import BlockCandidate\n\ncandidate = BlockCandidate(\n    syntax=syntax,\n    start_line=1,\n)\n</code></pre>"},{"location":"reference/blocks/#block-types","title":"Block Types","text":"<p>Streamblocks supports various block types for different content:</p>"},{"location":"reference/blocks/#message-blocks","title":"Message Blocks","text":"<p>For text messages and responses:</p> <pre><code>block = Block(\n    block_type=\"message\",\n    metadata={\"author\": \"assistant\"},\n    content=\"Hello, how can I help you?\"\n)\n</code></pre>"},{"location":"reference/blocks/#tool-call-blocks","title":"Tool Call Blocks","text":"<p>For function/tool invocations:</p> <pre><code>block = Block(\n    block_type=\"tool_call\",\n    metadata={\"name\": \"search\", \"id\": \"call_123\"},\n    content='{\"query\": \"weather today\"}'\n)\n</code></pre>"},{"location":"reference/blocks/#code-blocks","title":"Code Blocks","text":"<p>For code snippets:</p> <pre><code>block = Block(\n    block_type=\"code\",\n    metadata={\"language\": \"python\"},\n    content=\"print('Hello, World!')\"\n)\n</code></pre>"},{"location":"reference/blocks/#custom-block-types","title":"Custom Block Types","text":"<p>Define custom block types for your application:</p> <pre><code>from hother.streamblocks.core.models import Block\n\nclass ConfigBlock(Block):\n    block_type = \"config\"\n\n    def validate(self) -&gt; bool:\n        import json\n        try:\n            json.loads(self.content)\n            return True\n        except json.JSONDecodeError:\n            return False\n</code></pre>"},{"location":"reference/blocks/#api-reference","title":"API Reference","text":""},{"location":"reference/blocks/#hother.streamblocks.core.models","title":"hother.streamblocks.core.models","text":"<p>Core models for StreamBlocks.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.Block","title":"Block","text":"<p>               Bases: <code>BaseModel</code></p> <p>User-facing base class for defining block types.</p> <p>This minimal class contains only the essential fields (metadata and content). Users inherit from this to define their block types.</p> Usage <p>class YesNo(Block[YesNoMetadata, YesNoContent]):     pass</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.Block--access-fields","title":"Access fields","text":"<p>block: Block[YesNoMetadata, YesNoContent] block.metadata.prompt  # Type-safe access to metadata fields block.content.response  # Type-safe access to content fields</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.Block.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: TContent = Field(\n    ..., description=\"Parsed block content\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.Block.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: TMetadata = Field(\n    ..., description=\"Parsed block metadata\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate","title":"BlockCandidate","text":"<p>Tracks a potential block being accumulated.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.content_lines","title":"content_lines  <code>instance-attribute</code>","text":"<pre><code>content_lines: list[str] = []\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.content_validation_error","title":"content_validation_error  <code>instance-attribute</code>","text":"<pre><code>content_validation_error: str | None = None\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.content_validation_passed","title":"content_validation_passed  <code>instance-attribute</code>","text":"<pre><code>content_validation_passed: bool = True\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.current_section","title":"current_section  <code>instance-attribute</code>","text":"<pre><code>current_section: SectionType = HEADER\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.lines","title":"lines  <code>instance-attribute</code>","text":"<pre><code>lines: list[str] = []\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.metadata_lines","title":"metadata_lines  <code>instance-attribute</code>","text":"<pre><code>metadata_lines: list[str] = []\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.metadata_validation_error","title":"metadata_validation_error  <code>instance-attribute</code>","text":"<pre><code>metadata_validation_error: str | None = None\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.metadata_validation_passed","title":"metadata_validation_passed  <code>instance-attribute</code>","text":"<pre><code>metadata_validation_passed: bool = True\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.parsed_content","title":"parsed_content  <code>instance-attribute</code>","text":"<pre><code>parsed_content: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.parsed_metadata","title":"parsed_metadata  <code>instance-attribute</code>","text":"<pre><code>parsed_metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.raw_text","title":"raw_text  <code>property</code>","text":"<pre><code>raw_text: str\n</code></pre> <p>Get the raw text of all accumulated lines.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.start_line","title":"start_line  <code>instance-attribute</code>","text":"<pre><code>start_line = start_line\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.state","title":"state  <code>instance-attribute</code>","text":"<pre><code>state = HEADER_DETECTED\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax = syntax\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.add_line","title":"add_line","text":"<pre><code>add_line(line: str) -&gt; None\n</code></pre> <p>Add a line to the candidate.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.cache_content_validation","title":"cache_content_validation","text":"<pre><code>cache_content_validation(\n    passed: bool, error: str | None\n) -&gt; None\n</code></pre> <p>Cache content validation result.</p> <p>This method encapsulates validation result storage, providing a clear interface for the state machine to cache validation state.</p> <p>Parameters:</p> Name Type Description Default <code>passed</code> <code>bool</code> <p>Whether content validation passed</p> required <code>error</code> <code>str | None</code> <p>Error message if validation failed, None otherwise</p> required"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.cache_metadata_validation","title":"cache_metadata_validation","text":"<pre><code>cache_metadata_validation(\n    passed: bool, error: str | None\n) -&gt; None\n</code></pre> <p>Cache metadata validation result.</p> <p>This method encapsulates validation result storage, providing a clear interface for the state machine to cache validation state.</p> <p>Parameters:</p> Name Type Description Default <code>passed</code> <code>bool</code> <p>Whether metadata validation passed</p> required <code>error</code> <code>str | None</code> <p>Error message if validation failed, None otherwise</p> required"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.compute_hash","title":"compute_hash","text":"<pre><code>compute_hash() -&gt; str\n</code></pre> <p>Compute hash of first N chars for ID (N defined in constants).</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.transition_to_content","title":"transition_to_content","text":"<pre><code>transition_to_content() -&gt; None\n</code></pre> <p>Transition from metadata/header to content section.</p> <p>This method encapsulates the section state transition logic, making the state change explicit and centralized.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.BlockCandidate.transition_to_metadata","title":"transition_to_metadata","text":"<pre><code>transition_to_metadata() -&gt; None\n</code></pre> <p>Transition from header to metadata section.</p> <p>This method encapsulates the section state transition logic, making the state change explicit and centralized.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock","title":"ExtractedBlock","text":"<p>               Bases: <code>Block[TMetadata, TContent]</code></p> <p>Full runtime representation of an extracted block.</p> <p>This class extends the minimal Block with extraction metadata like line numbers, syntax name, and hash ID. The processor creates instances of this class when blocks are successfully extracted.</p> <p>The metadata and content fields are typed generics, allowing type-safe access to block-specific fields.</p>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: TContent = Field(\n    ..., description=\"Parsed block content\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.hash_id","title":"hash_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash_id: str = Field(\n    ..., description=\"Hash-based ID for the block\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.line_end","title":"line_end  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>line_end: int = Field(..., description=\"Ending line number\")\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.line_start","title":"line_start  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>line_start: int = Field(\n    ..., description=\"Starting line number\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: TMetadata = Field(\n    ..., description=\"Parsed block metadata\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.raw_text","title":"raw_text  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_text: str = Field(\n    ..., description=\"Original raw text of the block\"\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.ExtractedBlock.syntax_name","title":"syntax_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>syntax_name: str = Field(\n    ...,\n    description=\"Name of the syntax that extracted this block\",\n)\n</code></pre>"},{"location":"reference/blocks/#hother.streamblocks.core.models.extract_block_types","title":"extract_block_types","text":"<pre><code>extract_block_types(\n    block_class: type[Any],\n) -&gt; tuple[type[BaseMetadata], type[BaseContent]]\n</code></pre> <p>Extract metadata and content type parameters from a Block class.</p> <p>Works with both generic Block[M, C] classes and concrete subclasses. Uses typing.get_args() for more idiomatic type extraction.</p> <p>Parameters:</p> Name Type Description Default <code>block_class</code> <code>type[Any]</code> <p>The block class to extract types from</p> required <p>Returns:</p> Type Description <code>tuple[type[BaseMetadata], type[BaseContent]]</code> <p>Tuple of (metadata_class, content_class)</p>"},{"location":"reference/core/","title":"Core","text":""},{"location":"reference/core/#core-components","title":"Core Components","text":"<p>Core Streamblocks components and the main processor.</p>"},{"location":"reference/core/#streamblockprocessor","title":"StreamBlockProcessor","text":"<p>The main processing engine for extracting blocks from streams.</p> <pre><code>from hother.streamblocks import StreamBlockProcessor, Registry, DelimiterPreambleSyntax\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    emit_text_delta=True,\n    emit_block_content_delta=True,\n)\n\nasync for event in processor.process_stream(stream):\n    print(event)\n</code></pre>"},{"location":"reference/core/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Default Description <code>registry</code> <code>Registry</code> Required Block type registry <code>syntaxes</code> <code>list[BaseSyntax]</code> Required Syntax definitions to use <code>input_adapter</code> <code>InputProtocolAdapter \\| None</code> <code>None</code> Input stream adapter <code>output_adapter</code> <code>OutputProtocolAdapter \\| None</code> <code>None</code> Output event adapter <code>emit_text_delta</code> <code>bool</code> <code>False</code> Emit TEXT_DELTA events <code>emit_text_content</code> <code>bool</code> <code>True</code> Emit TEXT_CONTENT events <code>emit_block_start</code> <code>bool</code> <code>True</code> Emit BLOCK_START events <code>emit_block_content_delta</code> <code>bool</code> <code>False</code> Emit delta events <code>emit_block_metadata_end</code> <code>bool</code> <code>False</code> Emit metadata end events <code>emit_block_content_end</code> <code>bool</code> <code>False</code> Emit content end events <code>max_block_size</code> <code>int</code> <code>1048576</code> Maximum block size in bytes"},{"location":"reference/core/#methods","title":"Methods","text":""},{"location":"reference/core/#process_stream","title":"process_stream","text":"<pre><code>async def process_stream(\n    self,\n    stream: AsyncIterable[Any],\n) -&gt; AsyncIterator[Event]:\n    \"\"\"Process a stream and yield events.\"\"\"\n</code></pre>"},{"location":"reference/core/#process_chunk","title":"process_chunk","text":"<pre><code>async def process_chunk(self, chunk: str) -&gt; list[Event]:\n    \"\"\"Process a single text chunk and return events.\"\"\"\n</code></pre>"},{"location":"reference/core/#finalize","title":"finalize","text":"<pre><code>async def finalize(self) -&gt; list[Event]:\n    \"\"\"Finalize processing and return any remaining events.\"\"\"\n</code></pre>"},{"location":"reference/core/#registry","title":"Registry","text":"<p>Block type registry with validation support.</p> <pre><code>from hother.streamblocks import Registry, Block, BaseMetadata, BaseContent\nfrom typing import Literal\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n\nclass TaskContent(BaseContent):\n    pass\n\nTaskBlock = Block[TaskMetadata, TaskContent]\n\n# Create registry and register block types\nregistry = Registry()\nregistry.register(\"task\", TaskBlock)\n</code></pre>"},{"location":"reference/core/#constructor-parameters_1","title":"Constructor Parameters","text":"Parameter Type Default Description <code>name</code> <code>str \\| None</code> <code>None</code> Registry name <code>failure_mode</code> <code>MetadataValidationFailureMode</code> <code>REJECT</code> Validation failure behavior"},{"location":"reference/core/#methods_1","title":"Methods","text":""},{"location":"reference/core/#register","title":"register","text":"<pre><code>def register(\n    self,\n    block_type: str,\n    block_class: type[Block],\n) -&gt; None:\n    \"\"\"Register a block type with its class.\"\"\"\n</code></pre>"},{"location":"reference/core/#get","title":"get","text":"<pre><code>def get(self, block_type: str) -&gt; type[Block] | None:\n    \"\"\"Get the block class for a type.\"\"\"\n</code></pre>"},{"location":"reference/core/#validate","title":"validate","text":"<pre><code>def validate(\n    self,\n    block_type: str,\n    metadata: dict,\n    content: str,\n) -&gt; ValidationResult:\n    \"\"\"Validate block data against registered type.\"\"\"\n</code></pre>"},{"location":"reference/core/#streamstate","title":"StreamState","text":"<p>Processing state enumeration.</p> <pre><code>from hother.streamblocks import StreamState\n\nStreamState.IDLE       # Not processing\nStreamState.STREAMING  # Processing stream\nStreamState.FINALIZING # Finalizing stream\nStreamState.COMPLETED  # Stream completed\nStreamState.ERROR      # Error occurred\n</code></pre>"},{"location":"reference/core/#validationresult","title":"ValidationResult","text":"<p>Validation outcome with errors.</p> <pre><code>from hother.streamblocks import ValidationResult\n\nresult = registry.validate(\"task\", metadata, content)\n\nif result.success:\n    print(\"Validation passed\")\nelse:\n    print(f\"Errors: {result.errors}\")\n</code></pre>"},{"location":"reference/core/#fields","title":"Fields","text":"Field Type Description <code>success</code> <code>bool</code> Whether validation passed <code>errors</code> <code>list[str]</code> List of error messages <code>metadata</code> <code>BaseMetadata \\| None</code> Validated metadata <code>content</code> <code>BaseContent \\| None</code> Validated content"},{"location":"reference/core/#metadatavalidationfailuremode","title":"MetadataValidationFailureMode","text":"<p>Validation failure behavior enumeration.</p> <pre><code>from hother.streamblocks import MetadataValidationFailureMode\n\nMetadataValidationFailureMode.REJECT    # Reject block on failure\nMetadataValidationFailureMode.FALLBACK  # Use fallback metadata\nMetadataValidationFailureMode.SKIP      # Skip validation\n</code></pre>"},{"location":"reference/core/#base-types","title":"Base Types","text":""},{"location":"reference/core/#basemetadata","title":"BaseMetadata","text":"<p>Base metadata model with standard fields.</p> <pre><code>from hother.streamblocks import BaseMetadata\n\nclass TaskMetadata(BaseMetadata):\n    block_type: Literal[\"task\"] = \"task\"\n    priority: str = \"normal\"\n    tags: list[str] = []\n</code></pre> <p>Required fields:</p> Field Type Description <code>id</code> <code>str</code> Block identifier <code>block_type</code> <code>str</code> Type of the block"},{"location":"reference/core/#basecontent","title":"BaseContent","text":"<p>Base content model with raw content field.</p> <pre><code>from hother.streamblocks import BaseContent\n\nclass TaskContent(BaseContent):\n    @classmethod\n    def parse(cls, raw_text: str) -&gt; \"TaskContent\":\n        \"\"\"Custom parsing logic.\"\"\"\n        return cls(raw_content=raw_text.strip())\n</code></pre> <p>Required fields:</p> Field Type Description <code>raw_content</code> <code>str</code> Raw unparsed content"},{"location":"reference/core/#detection-and-parse-results","title":"Detection and Parse Results","text":""},{"location":"reference/core/#detectionresult","title":"DetectionResult","text":"<p>Result from syntax detection attempt.</p> <pre><code>from hother.streamblocks import DetectionResult\n\nresult = DetectionResult(\n    is_opening=True,\n    is_closing=False,\n    is_metadata_boundary=False,\n    metadata={\"id\": \"task01\", \"block_type\": \"task\"},\n)\n</code></pre>"},{"location":"reference/core/#parseresult","title":"ParseResult","text":"<p>Result from parsing attempt.</p> <pre><code>from hother.streamblocks import ParseResult\n\nresult = ParseResult(\n    success=True,\n    metadata=metadata,\n    content=content,\n    error=None,\n)\n</code></pre>"},{"location":"reference/core/#api-reference","title":"API Reference","text":""},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor","title":"hother.streamblocks.core.processor.StreamBlockProcessor","text":"<p>Main stream processing engine for a single syntax type.</p> <p>This processor works with exactly one syntax and coordinates: - Adapter detection and text extraction - Line accumulation via LineAccumulator - Block detection and extraction via BlockStateMachine - Event emission (TextDeltaEvent, block events, etc.)</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.registry","title":"registry  <code>instance-attribute</code>","text":"<pre><code>registry = registry\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax = syntax\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or StdlibLoggerAdapter(getLogger(__name__))\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config or ProcessorConfig()\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.process_chunk","title":"process_chunk","text":"<pre><code>process_chunk(\n    chunk: TChunk,\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; list[TChunk | Event]\n</code></pre> <p>Process a single chunk and return resulting events.</p> <p>This method is stateful - it maintains internal state between calls. Call finalize() after processing all chunks to flush incomplete blocks.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>TChunk</code> <p>Single chunk to process</p> required <code>adapter</code> <code>InputProtocolAdapter[TChunk] | None</code> <p>Optional adapter for extracting text. If not provided and     auto_detect_adapter=True, will auto-detect on first chunk.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[TChunk | Event]</code> <p>List of events generated from this chunk. May be empty if chunk only</p> <code>list[TChunk | Event]</code> <p>accumulates text without completing any lines.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If adapter is not set after first chunk processing (internal state error, should not occur in normal usage).</p> Example <p>processor = StreamBlockProcessor(registry) response = await client.generate_content_stream(...) async for chunk in response: ...     events = processor.process_chunk(chunk) ...     for event in events: ...         if isinstance(event, BlockEndEvent): ...             print(f\"Block: {event.block_id}\") ...</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.process_chunk--finalize-at-stream-end","title":"Finalize at stream end","text":"<p>final_events = processor.finalize() for event in final_events: ...     if isinstance(event, BlockErrorEvent): ...         print(f\"Incomplete block: {event.reason}\")</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.finalize","title":"finalize","text":"<pre><code>finalize() -&gt; list[Event]\n</code></pre> <p>Finalize processing and flush any incomplete blocks.</p> <p>Call this method after processing all chunks to get rejection events for any blocks that were opened but never closed.</p> <p>This method processes any accumulated text as a final line before flushing candidates, ensuring the last line is processed even if it doesn't end with a newline.</p> <p>Returns:</p> Type Description <code>list[Event]</code> <p>List of events including processed final line and rejection events</p> <code>list[Event]</code> <p>for incomplete blocks</p> Example <p>processor = StreamBlockProcessor(registry) async for chunk in stream: ...     events = processor.process_chunk(chunk) ...     # ... handle events ...</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.finalize--stream-ended-process-remaining-text-and-flush-incomplete-blocks","title":"Stream ended, process remaining text and flush incomplete blocks","text":"<p>final_events = processor.finalize() for event in final_events: ...     if isinstance(event, BlockErrorEvent): ...         print(f\"Incomplete block: {event.reason}\")</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.is_native_event","title":"is_native_event","text":"<pre><code>is_native_event(event: Any) -&gt; bool\n</code></pre> <p>Check if event is a native provider event (not a StreamBlocks event).</p> <p>This method provides provider-agnostic detection of native events. It checks if the event originates from the AI provider (Gemini, OpenAI, Anthropic, etc.) versus being a StreamBlocks event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>Event to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if event is from the native provider, False if it's a StreamBlocks</p> <code>bool</code> <p>event or if detection is not possible</p> Example <p>processor = StreamBlockProcessor(registry) async for event in processor.process_stream(gemini_stream): ...     if processor.is_native_event(event): ...         # Handle Gemini event (provider-agnostic!) ...         usage = getattr(event, 'usage_metadata', None) ...     elif isinstance(event, BlockEndEvent): ...         # Handle StreamBlocks event ...         print(f\"Block: {event.block_id}\")</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.process_stream","title":"process_stream  <code>async</code>","text":"<pre><code>process_stream(\n    stream: AsyncIterator[TChunk],\n    adapter: InputProtocolAdapter[TChunk] | None = None,\n) -&gt; AsyncGenerator[TChunk | Event]\n</code></pre> <p>Process stream and yield mixed events.</p> <p>This method processes chunks from any stream format, extracting text via an adapter and emitting both original chunks (if enabled) and StreamBlocks events.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <code>AsyncIterator[TChunk]</code> <p>Async iterator yielding chunks (text or objects)</p> required <code>adapter</code> <code>InputProtocolAdapter[TChunk] | None</code> <p>Optional adapter for extracting text from chunks.     If None and auto_detect_adapter=True, will auto-detect from first chunk.</p> <code>None</code> <p>Yields:</p> Type Description <code>AsyncGenerator[TChunk | Event]</code> <p>Mixed stream of:</p> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>Original chunks (if emit_original_events=True)</li> </ul> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>TextDeltaEvent (if emit_text_deltas=True)</li> </ul> <code>AsyncGenerator[TChunk | Event]</code> <ul> <li>TextContentEvent, BlockStartEvent, BlockEndEvent, BlockErrorEvent, and section delta events</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If adapter is not set after first chunk processing (internal state error, should not occur in normal usage).</p> Example"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.process_stream--plain-text","title":"Plain text","text":"<p>async for event in processor.process_stream(text_stream): ...     if isinstance(event, BlockEndEvent): ...         print(f\"Extracted: {event.block_id}\")</p>"},{"location":"reference/core/#hother.streamblocks.core.processor.StreamBlockProcessor.process_stream--with-gemini-adapter-auto-detected","title":"With Gemini adapter (auto-detected)","text":"<p>async for event in processor.process_stream(gemini_stream): ...     if hasattr(event, 'usage_metadata'): ...         print(f\"Tokens: {event.usage_metadata}\") ...     elif isinstance(event, BlockEndEvent): ...         print(f\"Extracted: {event.block_id}\")</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry","title":"hother.streamblocks.core.registry.Registry","text":"<p>Type-specific registry for a single syntax type.</p> <p>This registry holds exactly one syntax instance and maps block types to block classes.</p> Example <p>syntax = DelimiterPreambleSyntax(name=\"my_syntax\") registry = Registry(syntax) registry.register(\"files_operations\", FileOperations, validators=[my_validator]) registry.register(\"patch\", Patch)</p> <p>Or with bulk registration:</p> <p>registry = Registry( ...     syntax=syntax, ...     blocks={ ...         \"files_operations\": FileOperations, ...         \"patch\": Patch, ...     } ... ) registry.add_validator(\"files_operations\", my_validator)</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.logger","title":"logger  <code>instance-attribute</code>","text":"<pre><code>logger = logger or StdlibLoggerAdapter(getLogger(__name__))\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.syntax","title":"syntax  <code>property</code>","text":"<pre><code>syntax: BaseSyntax\n</code></pre> <p>Get the syntax instance.</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.metadata_failure_mode","title":"metadata_failure_mode  <code>property</code>","text":"<pre><code>metadata_failure_mode: MetadataValidationFailureMode\n</code></pre> <p>Get the metadata validation failure mode.</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.register","title":"register","text":"<pre><code>register(\n    name: str,\n    block_class: type[Block[Any, Any]],\n    validators: list[ValidatorFunc] | None = None,\n) -&gt; None\n</code></pre> <p>Register a block class for a block type.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Block type name (e.g., \"files_operations\", \"patch\")</p> required <code>block_class</code> <code>type[Block[Any, Any]]</code> <p>Block class inheriting from Block[M, C]</p> required <code>validators</code> <code>list[ValidatorFunc] | None</code> <p>Optional list of validator functions for this block type</p> <code>None</code>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.get_block_class","title":"get_block_class","text":"<pre><code>get_block_class(\n    block_type: str,\n) -&gt; type[Block[Any, Any]] | None\n</code></pre> <p>Get the block class for a given block type.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>str</code> <p>The block type to look up</p> required <p>Returns:</p> Type Description <code>type[Block[Any, Any]] | None</code> <p>The registered block class, or None if not found</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.add_validator","title":"add_validator","text":"<pre><code>add_validator(\n    block_type: BlockType, validator: ValidatorFunc\n) -&gt; None\n</code></pre> <p>Add a validator for a block type.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>BlockType</code> <p>Type of block to validate</p> required <code>validator</code> <code>ValidatorFunc</code> <p>Function that validates a block</p> required"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.validate_block","title":"validate_block","text":"<pre><code>validate_block(block: ExtractedBlock[Any, Any]) -&gt; bool\n</code></pre> <p>Run all validators for a block.</p> <p>Parameters:</p> Name Type Description Default <code>block</code> <code>ExtractedBlock[Any, Any]</code> <p>Extracted block to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all validators pass</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.add_metadata_validator","title":"add_metadata_validator","text":"<pre><code>add_metadata_validator(\n    block_type: BlockType, validator: MetadataValidatorFunc\n) -&gt; None\n</code></pre> <p>Add an early metadata validator for a block type.</p> <p>Metadata validators are called when the metadata section completes, before content accumulation begins. They receive the raw metadata string and the parsed metadata dict.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>BlockType</code> <p>Type of block to validate</p> required <code>validator</code> <code>MetadataValidatorFunc</code> <p>Function that validates metadata and returns ValidationResult</p> required"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.add_content_validator","title":"add_content_validator","text":"<pre><code>add_content_validator(\n    block_type: BlockType, validator: ContentValidatorFunc\n) -&gt; None\n</code></pre> <p>Add an early content validator for a block type.</p> <p>Content validators are called when the content section completes, before the final BlockEndEvent. They receive the raw content string and the parsed content dict.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>BlockType</code> <p>Type of block to validate</p> required <code>validator</code> <code>ContentValidatorFunc</code> <p>Function that validates content and returns ValidationResult</p> required"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.validate_metadata","title":"validate_metadata","text":"<pre><code>validate_metadata(\n    block_type: str,\n    raw_metadata: str,\n    parsed_metadata: dict[str, Any] | None,\n) -&gt; ValidationResult\n</code></pre> <p>Run all metadata validators for a block type.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>str</code> <p>Type of block being validated</p> required <code>raw_metadata</code> <code>str</code> <p>Raw metadata string</p> required <code>parsed_metadata</code> <code>dict[str, Any] | None</code> <p>Parsed metadata dict (if available)</p> required <p>Returns:</p> Type Description <code>ValidationResult</code> <p>ValidationResult with combined results from all validators</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.Registry.validate_content","title":"validate_content","text":"<pre><code>validate_content(\n    block_type: str,\n    raw_content: str,\n    parsed_content: dict[str, Any] | None,\n) -&gt; ValidationResult\n</code></pre> <p>Run all content validators for a block type.</p> <p>Parameters:</p> Name Type Description Default <code>block_type</code> <code>str</code> <p>Type of block being validated</p> required <code>raw_content</code> <code>str</code> <p>Raw content string</p> required <code>parsed_content</code> <code>dict[str, Any] | None</code> <p>Parsed content dict (if available)</p> required <p>Returns:</p> Type Description <code>ValidationResult</code> <p>ValidationResult with combined results from all validators</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.ValidationResult","title":"hother.streamblocks.core.registry.ValidationResult  <code>dataclass</code>","text":"<p>Result from section validation.</p> <p>Attributes:</p> Name Type Description <code>passed</code> <code>bool</code> <p>Whether validation succeeded</p> <code>error</code> <code>str | None</code> <p>Error message if validation failed</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.ValidationResult.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error: str | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.registry.ValidationResult.passed","title":"passed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>passed: bool = True\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.registry.ValidationResult.failure","title":"failure  <code>classmethod</code>","text":"<pre><code>failure(error: str) -&gt; ValidationResult\n</code></pre> <p>Create a failed validation result.</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.ValidationResult.success","title":"success  <code>classmethod</code>","text":"<pre><code>success() -&gt; ValidationResult\n</code></pre> <p>Create a successful validation result.</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.MetadataValidationFailureMode","title":"hother.streamblocks.core.registry.MetadataValidationFailureMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Behavior when metadata validation fails.</p>"},{"location":"reference/core/#hother.streamblocks.core.registry.MetadataValidationFailureMode.ABORT_BLOCK","title":"ABORT_BLOCK  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABORT_BLOCK = 'abort_block'\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.registry.MetadataValidationFailureMode.CONTINUE","title":"CONTINUE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CONTINUE = 'continue'\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.registry.MetadataValidationFailureMode.SKIP_CONTENT","title":"SKIP_CONTENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIP_CONTENT = 'skip_content'\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseMetadata","title":"hother.streamblocks.core.types.BaseMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base metadata model with standard fields.</p> <p>All custom metadata models should inherit from this class and add their domain-specific fields.</p> Example"},{"location":"reference/core/#hother.streamblocks.core.types.BaseMetadata--define-custom-metadata-for-a-patch-block","title":"Define custom metadata for a patch block","text":"<p>class PatchMetadata(BaseMetadata): ...     file_path: str ...     operation: Literal[\"create\", \"update\", \"delete\"] ...</p>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseMetadata--create-instance-with-required-base-fields","title":"Create instance with required base fields","text":"<p>metadata = PatchMetadata( ...     id=\"patch_001\", ...     block_type=\"patch\", ...     file_path=\"src/main.py\", ...     operation=\"update\" ... ) metadata.id 'patch_001' metadata.file_path 'src/main.py'</p>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseMetadata.block_type","title":"block_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>block_type: str = Field(\n    ..., description=\"Type of the block\"\n)\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseMetadata.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: str = Field(..., description='Block identifier')\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseContent","title":"hother.streamblocks.core.types.BaseContent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base content model with raw content field.</p> <p>All custom content models should inherit from this class and optionally override the parse() method to add custom parsing logic. The raw_content field always preserves the original unparsed text.</p> Example"},{"location":"reference/core/#hother.streamblocks.core.types.BaseContent--simple-content-model-that-just-stores-raw-text","title":"Simple content model that just stores raw text","text":"<p>class SimpleContent(BaseContent): ...     pass ... content = SimpleContent.parse(\"Hello, world!\") content.raw_content 'Hello, world!'</p>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseContent--content-model-with-custom-parsing","title":"Content model with custom parsing","text":"<p>class ItemsContent(BaseContent): ...     items: list[str] = [] ... ...     @classmethod ...     def parse(cls, raw_text: str) -&gt; Self: ...         items = [line.strip() for line in raw_text.split(\"\\n\") if line.strip()] ...         return cls(raw_content=raw_text, items=items) ... content = ItemsContent.parse(\"apple\\nbanana\\norange\") content.items ['apple', 'banana', 'orange'] content.raw_content  # Original text preserved 'apple\\nbanana\\norange'</p>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseContent.raw_content","title":"raw_content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_content: str = Field(\n    ..., description=\"Raw unparsed content from the block\"\n)\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.BaseContent.parse","title":"parse  <code>classmethod</code>","text":"<pre><code>parse(raw_text: str) -&gt; Self\n</code></pre> <p>Default parse method that just stores raw content.</p> <p>Override this in subclasses to add custom parsing logic.</p>"},{"location":"reference/core/#hother.streamblocks.core.types.DetectionResult","title":"hother.streamblocks.core.types.DetectionResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result from syntax detection attempt.</p>"},{"location":"reference/core/#hother.streamblocks.core.types.DetectionResult.is_closing","title":"is_closing  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_closing: bool = False\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.DetectionResult.is_metadata_boundary","title":"is_metadata_boundary  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_metadata_boundary: bool = False\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.DetectionResult.is_opening","title":"is_opening  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_opening: bool = False\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.DetectionResult.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult","title":"hother.streamblocks.core.types.ParseResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result from parsing attempt.</p>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.content","title":"content  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>content: TContent | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error: str | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.exception","title":"exception  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>exception: Exception | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: TMetadata | None = None\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"reference/core/#hother.streamblocks.core.types.ParseResult.success","title":"success  <code>instance-attribute</code>","text":"<pre><code>success: bool\n</code></pre>"},{"location":"reference/events/","title":"Events","text":""},{"location":"reference/events/#event-types-reference","title":"Event Types Reference","text":"<p>Complete reference for all Streamblocks event types.</p>"},{"location":"reference/events/#event-hierarchy","title":"Event Hierarchy","text":"<pre><code>classDiagram\n    BaseEvent &lt;|-- StreamStartedEvent\n    BaseEvent &lt;|-- StreamFinishedEvent\n    BaseEvent &lt;|-- StreamErrorEvent\n    BaseEvent &lt;|-- TextContentEvent\n    BaseEvent &lt;|-- TextDeltaEvent\n    BaseEvent &lt;|-- BlockStartEvent\n    BaseEvent &lt;|-- BlockHeaderDeltaEvent\n    BaseEvent &lt;|-- BlockMetadataDeltaEvent\n    BaseEvent &lt;|-- BlockContentDeltaEvent\n    BaseEvent &lt;|-- BlockMetadataEndEvent\n    BaseEvent &lt;|-- BlockContentEndEvent\n    BaseEvent &lt;|-- BlockEndEvent\n    BaseEvent &lt;|-- BlockErrorEvent\n    BaseEvent &lt;|-- CustomEvent\n\n    class BaseEvent {\n        +timestamp: int\n        +event_id: str\n        +raw_event: Any\n    }</code></pre>"},{"location":"reference/events/#eventtype-enumeration","title":"EventType Enumeration","text":"<p>All event types as string enumeration:</p> <pre><code>from hother.streamblocks import EventType\n\n# Lifecycle events\nEventType.STREAM_STARTED    # Stream processing began\nEventType.STREAM_FINISHED   # Stream processing completed\nEventType.STREAM_ERROR      # Stream processing failed\n\n# Text events\nEventType.TEXT_CONTENT      # Complete line outside blocks\nEventType.TEXT_DELTA        # Real-time text chunk\n\n# Block lifecycle events\nEventType.BLOCK_START          # Block opening detected\nEventType.BLOCK_HEADER_DELTA   # Header content delta\nEventType.BLOCK_METADATA_DELTA # Metadata section delta\nEventType.BLOCK_CONTENT_DELTA  # Content section delta\nEventType.BLOCK_METADATA_END   # Metadata section completed\nEventType.BLOCK_CONTENT_END    # Content section completed\nEventType.BLOCK_END            # Block successfully extracted\nEventType.BLOCK_ERROR          # Block extraction failed\n\n# Custom events\nEventType.CUSTOM            # Application-specific event\n</code></pre>"},{"location":"reference/events/#lifecycle-events","title":"Lifecycle Events","text":""},{"location":"reference/events/#streamstartedevent","title":"StreamStartedEvent","text":"<p>Emitted when stream processing begins.</p> <pre><code>from hother.streamblocks import StreamStartedEvent\n\n# Fields\nevent.type          # EventType.STREAM_STARTED\nevent.stream_id     # Unique stream identifier\nevent.registry_name # Registry name (optional)\nevent.timestamp     # Unix timestamp in milliseconds\nevent.event_id      # Unique event identifier\n</code></pre>"},{"location":"reference/events/#streamfinishedevent","title":"StreamFinishedEvent","text":"<p>Emitted when stream processing completes successfully.</p> <pre><code>from hother.streamblocks import StreamFinishedEvent\n\n# Fields\nevent.type              # EventType.STREAM_FINISHED\nevent.stream_id         # Unique stream identifier\nevent.blocks_extracted  # Number of successfully extracted blocks\nevent.blocks_rejected   # Number of rejected blocks\nevent.total_events      # Total events emitted\nevent.duration_ms       # Processing duration in milliseconds\n</code></pre>"},{"location":"reference/events/#streamerrorevent","title":"StreamErrorEvent","text":"<p>Emitted when stream processing fails.</p> <pre><code>from hother.streamblocks import StreamErrorEvent\n\n# Fields\nevent.type       # EventType.STREAM_ERROR\nevent.stream_id  # Unique stream identifier\nevent.error      # Error message\nevent.error_code # Error code (optional)\n</code></pre>"},{"location":"reference/events/#text-events","title":"Text Events","text":""},{"location":"reference/events/#textcontentevent","title":"TextContentEvent","text":"<p>Complete line of text outside any block.</p> <pre><code>from hother.streamblocks import TextContentEvent\n\n# Fields\nevent.type        # EventType.TEXT_CONTENT\nevent.content     # Complete line content\nevent.line_number # Line number in stream\n</code></pre>"},{"location":"reference/events/#textdeltaevent","title":"TextDeltaEvent","text":"<p>Real-time text chunk (character/token level).</p> <pre><code>from hother.streamblocks import TextDeltaEvent\n\n# Fields\nevent.type        # EventType.TEXT_DELTA\nevent.delta       # Text chunk\nevent.inside_block # Whether inside a block\nevent.block_id    # Block ID if inside block\nevent.section     # \"header\", \"metadata\", or \"content\"\n</code></pre>"},{"location":"reference/events/#block-events","title":"Block Events","text":""},{"location":"reference/events/#blockstartevent","title":"BlockStartEvent","text":"<p>Block opening detected - begins block lifecycle.</p> <pre><code>from hother.streamblocks import BlockStartEvent\n\n# Fields\nevent.type            # EventType.BLOCK_START\nevent.block_id        # Unique block identifier\nevent.block_type      # Block type (may be None until parsed)\nevent.syntax          # Syntax name\nevent.start_line      # Starting line number\nevent.inline_metadata # Parsed inline metadata (optional)\n</code></pre>"},{"location":"reference/events/#blockheaderdeltaevent","title":"BlockHeaderDeltaEvent","text":"<p>Delta event for block header section.</p> <pre><code>from hother.streamblocks import BlockHeaderDeltaEvent\n\n# Fields\nevent.type             # EventType.BLOCK_HEADER_DELTA\nevent.block_id         # Block identifier\nevent.delta            # Header content chunk\nevent.syntax           # Syntax name\nevent.current_line     # Current line number\nevent.accumulated_size # Total accumulated bytes\nevent.inline_metadata  # Parsed inline metadata (optional)\n</code></pre>"},{"location":"reference/events/#blockmetadatadeltaevent","title":"BlockMetadataDeltaEvent","text":"<p>Delta event for block metadata section.</p> <pre><code>from hother.streamblocks import BlockMetadataDeltaEvent\n\n# Fields\nevent.type             # EventType.BLOCK_METADATA_DELTA\nevent.block_id         # Block identifier\nevent.delta            # Metadata content chunk\nevent.syntax           # Syntax name\nevent.current_line     # Current line number\nevent.accumulated_size # Total accumulated bytes\nevent.is_boundary      # Whether contains section boundary\n</code></pre>"},{"location":"reference/events/#blockcontentdeltaevent","title":"BlockContentDeltaEvent","text":"<p>Delta event for block content section.</p> <pre><code>from hother.streamblocks import BlockContentDeltaEvent\n\n# Fields\nevent.type             # EventType.BLOCK_CONTENT_DELTA\nevent.block_id         # Block identifier\nevent.delta            # Content chunk\nevent.syntax           # Syntax name\nevent.current_line     # Current line number\nevent.accumulated_size # Total accumulated bytes\n</code></pre>"},{"location":"reference/events/#blockmetadataendevent","title":"BlockMetadataEndEvent","text":"<p>Emitted when metadata section completes.</p> <pre><code>from hother.streamblocks import BlockMetadataEndEvent\n\n# Fields\nevent.type             # EventType.BLOCK_METADATA_END\nevent.block_id         # Block identifier\nevent.syntax           # Syntax name\nevent.start_line       # Metadata start line\nevent.end_line         # Metadata end line\nevent.raw_metadata     # Raw metadata string\nevent.parsed_metadata  # Parsed metadata dict (optional)\nevent.validation_passed # Whether validation passed\nevent.validation_error # Validation error message (optional)\n</code></pre>"},{"location":"reference/events/#blockcontentendevent","title":"BlockContentEndEvent","text":"<p>Emitted when content section completes.</p> <pre><code>from hother.streamblocks import BlockContentEndEvent\n\n# Fields\nevent.type             # EventType.BLOCK_CONTENT_END\nevent.block_id         # Block identifier\nevent.syntax           # Syntax name\nevent.start_line       # Content start line\nevent.end_line         # Content end line\nevent.raw_content      # Raw content string\nevent.parsed_content   # Parsed content dict (optional)\nevent.validation_passed # Whether validation passed\nevent.validation_error # Validation error message (optional)\n</code></pre>"},{"location":"reference/events/#blockendevent","title":"BlockEndEvent","text":"<p>Block successfully extracted and validated.</p> <pre><code>from hother.streamblocks import BlockEndEvent\n\n# Fields\nevent.type        # EventType.BLOCK_END\nevent.block_id    # Block identifier\nevent.block_type  # Block type string\nevent.syntax      # Syntax name\nevent.start_line  # Block start line\nevent.end_line    # Block end line\nevent.metadata    # Metadata as dict\nevent.content     # Content as dict\nevent.raw_content # Raw content string\nevent.hash_id     # Content hash for deduplication\n\n# Methods\nevent.get_block() # Get typed ExtractedBlock\n</code></pre>"},{"location":"reference/events/#blockerrorevent","title":"BlockErrorEvent","text":"<p>Block extraction failed.</p> <pre><code>from hother.streamblocks import BlockErrorEvent, BlockErrorCode\n\n# Fields\nevent.type       # EventType.BLOCK_ERROR\nevent.block_id   # Block identifier (optional)\nevent.reason     # Error reason message\nevent.error_code # BlockErrorCode enum value\nevent.syntax     # Syntax name\nevent.start_line # Block start line\nevent.end_line   # Block end line (optional)\nevent.exception  # Exception object (excluded from serialization)\n</code></pre>"},{"location":"reference/events/#blockerrorcode-enumeration","title":"BlockErrorCode Enumeration","text":"<p>Standard error codes for <code>BlockErrorEvent</code>:</p> <pre><code>from hother.streamblocks import BlockErrorCode\n\nBlockErrorCode.VALIDATION_FAILED  # Pydantic validation failed\nBlockErrorCode.SIZE_EXCEEDED      # Block exceeded size limit\nBlockErrorCode.UNCLOSED_BLOCK     # Missing closing marker\nBlockErrorCode.UNKNOWN_TYPE       # Unregistered block type\nBlockErrorCode.PARSE_FAILED       # Content parsing failed\nBlockErrorCode.MISSING_METADATA   # Required metadata missing\nBlockErrorCode.MISSING_CONTENT    # Required content missing\nBlockErrorCode.SYNTAX_ERROR       # Syntax detection error\n</code></pre>"},{"location":"reference/events/#custom-events","title":"Custom Events","text":""},{"location":"reference/events/#customevent","title":"CustomEvent","text":"<p>Application-specific custom events.</p> <pre><code>from hother.streamblocks import CustomEvent\n\n# Fields\nevent.type   # EventType.CUSTOM\nevent.name   # Custom event name\nevent.value  # Custom event data dict\n</code></pre>"},{"location":"reference/events/#event-union-type","title":"Event Union Type","text":"<p>The <code>Event</code> type is a discriminated union of all event types:</p> <pre><code>from hother.streamblocks import Event\n\ndef handle_event(event: Event) -&gt; None:\n    match event.type:\n        case EventType.BLOCK_END:\n            print(f\"Block extracted: {event.block_type}\")\n        case EventType.BLOCK_ERROR:\n            print(f\"Block failed: {event.reason}\")\n        case EventType.TEXT_DELTA:\n            print(event.delta, end=\"\")\n</code></pre>"},{"location":"reference/events/#api-reference","title":"API Reference","text":""},{"location":"reference/events/#hother.streamblocks.core.types.EventType","title":"hother.streamblocks.core.types.EventType","text":"<p>               Bases: <code>StrEnum</code></p> <p>Event types emitted during stream processing.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_CONTENT_DELTA","title":"BLOCK_CONTENT_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_CONTENT_DELTA = 'BLOCK_CONTENT_DELTA'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_CONTENT_END","title":"BLOCK_CONTENT_END  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_CONTENT_END = 'BLOCK_CONTENT_END'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_END","title":"BLOCK_END  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_END = 'BLOCK_END'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_ERROR","title":"BLOCK_ERROR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_ERROR = 'BLOCK_ERROR'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_HEADER_DELTA","title":"BLOCK_HEADER_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_HEADER_DELTA = 'BLOCK_HEADER_DELTA'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_METADATA_DELTA","title":"BLOCK_METADATA_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_METADATA_DELTA = 'BLOCK_METADATA_DELTA'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_METADATA_END","title":"BLOCK_METADATA_END  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_METADATA_END = 'BLOCK_METADATA_END'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.BLOCK_START","title":"BLOCK_START  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_START = 'BLOCK_START'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.CUSTOM","title":"CUSTOM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CUSTOM = 'CUSTOM'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.STREAM_ERROR","title":"STREAM_ERROR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STREAM_ERROR = 'STREAM_ERROR'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.STREAM_FINISHED","title":"STREAM_FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STREAM_FINISHED = 'STREAM_FINISHED'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.STREAM_STARTED","title":"STREAM_STARTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STREAM_STARTED = 'STREAM_STARTED'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.TEXT_CONTENT","title":"TEXT_CONTENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_CONTENT = 'TEXT_CONTENT'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.EventType.TEXT_DELTA","title":"TEXT_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_DELTA = 'TEXT_DELTA'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState","title":"hother.streamblocks.core.types.BlockState","text":"<p>               Bases: <code>StrEnum</code></p> <p>Internal state of block detection.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.ACCUMULATING_CONTENT","title":"ACCUMULATING_CONTENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACCUMULATING_CONTENT = 'accumulating_content'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.ACCUMULATING_METADATA","title":"ACCUMULATING_METADATA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACCUMULATING_METADATA = 'accumulating_metadata'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.CLOSING_DETECTED","title":"CLOSING_DETECTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CLOSING_DETECTED = 'closing_detected'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.COMPLETED","title":"COMPLETED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMPLETED = 'completed'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.HEADER_DETECTED","title":"HEADER_DETECTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HEADER_DETECTED = 'header_detected'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.REJECTED","title":"REJECTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REJECTED = 'rejected'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockState.SEARCHING","title":"SEARCHING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SEARCHING = 'searching'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode","title":"hother.streamblocks.core.types.BlockErrorCode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Standard error codes for BlockErrorEvent.</p> <p>These codes categorize why a block extraction failed, enabling appropriate error handling and recovery strategies.</p> Values Example"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode--handle-different-error-codes-appropriately","title":"Handle different error codes appropriately","text":"<p>async for event in processor.process_stream(stream): ...     if isinstance(event, BlockErrorEvent): ...         if event.error_code == BlockErrorCode.SIZE_EXCEEDED: ...             logger.warning(f\"Block too large: {event.reason}\") ...         elif event.error_code == BlockErrorCode.VALIDATION_FAILED: ...             logger.error(f\"Validation failed: {event.reason}\") ...         elif event.error_code == BlockErrorCode.UNCLOSED_BLOCK: ...             logger.info(f\"Incomplete block at stream end: {event.reason}\")</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.MISSING_CONTENT","title":"MISSING_CONTENT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MISSING_CONTENT = 'MISSING_CONTENT'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.MISSING_METADATA","title":"MISSING_METADATA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MISSING_METADATA = 'MISSING_METADATA'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.PARSE_FAILED","title":"PARSE_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PARSE_FAILED = 'PARSE_FAILED'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.SIZE_EXCEEDED","title":"SIZE_EXCEEDED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SIZE_EXCEEDED = 'SIZE_EXCEEDED'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.SYNTAX_ERROR","title":"SYNTAX_ERROR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SYNTAX_ERROR = 'SYNTAX_ERROR'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.UNCLOSED_BLOCK","title":"UNCLOSED_BLOCK  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNCLOSED_BLOCK = 'UNCLOSED_BLOCK'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.UNKNOWN_TYPE","title":"UNKNOWN_TYPE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN_TYPE = 'UNKNOWN_TYPE'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorCode.VALIDATION_FAILED","title":"VALIDATION_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VALIDATION_FAILED = 'VALIDATION_FAILED'\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BaseEvent","title":"hother.streamblocks.core.types.BaseEvent","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for all StreamBlocks events.</p> <p>Attributes:</p> Name Type Description <code>type</code> <p>Event type discriminator (defined in subclasses)</p> <code>timestamp</code> <code>int</code> <p>Unix timestamp in milliseconds (auto-generated)</p> <code>event_id</code> <code>str</code> <p>Unique event identifier (auto-generated)</p> <code>raw_event</code> <code>Any | None</code> <p>Original provider event (preserved by adapters)</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BaseEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BaseEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BaseEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BaseEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent","title":"hother.streamblocks.core.types.StreamStartedEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Emitted when stream processing begins.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.registry_name","title":"registry_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>registry_name: str | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.stream_id","title":"stream_id  <code>instance-attribute</code>","text":"<pre><code>stream_id: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamStartedEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[STREAM_STARTED] = STREAM_STARTED\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent","title":"hother.streamblocks.core.types.StreamFinishedEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Emitted when stream processing completes successfully.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.blocks_extracted","title":"blocks_extracted  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>blocks_extracted: int = 0\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.blocks_rejected","title":"blocks_rejected  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>blocks_rejected: int = 0\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.duration_ms","title":"duration_ms  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>duration_ms: int | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.stream_id","title":"stream_id  <code>instance-attribute</code>","text":"<pre><code>stream_id: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.total_events","title":"total_events  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>total_events: int = 0\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.StreamFinishedEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[STREAM_FINISHED] = STREAM_FINISHED\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent","title":"hother.streamblocks.core.types.BlockStartEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Block opening detected - begins block lifecycle.</p> <p>Emitted when a block opening marker is detected, before content accumulation. Useful for UIs to prepare display elements.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.block_id","title":"block_id  <code>instance-attribute</code>","text":"<pre><code>block_id: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.block_type","title":"block_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>block_type: str | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.inline_metadata","title":"inline_metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inline_metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.start_line","title":"start_line  <code>instance-attribute</code>","text":"<pre><code>start_line: int\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockStartEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[BLOCK_START] = BLOCK_START\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent","title":"hother.streamblocks.core.types.BlockEndEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Block successfully extracted and validated.</p> <p>Emitted when a block is fully parsed, validated, and ready for use. Contains the complete extracted content.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.block_id","title":"block_id  <code>instance-attribute</code>","text":"<pre><code>block_id: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.block_type","title":"block_type  <code>instance-attribute</code>","text":"<pre><code>block_type: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.content","title":"content  <code>instance-attribute</code>","text":"<pre><code>content: dict[str, Any]\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.end_line","title":"end_line  <code>instance-attribute</code>","text":"<pre><code>end_line: int\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.hash_id","title":"hash_id  <code>instance-attribute</code>","text":"<pre><code>hash_id: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, arbitrary_types_allowed=True\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.raw_content","title":"raw_content  <code>instance-attribute</code>","text":"<pre><code>raw_content: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.start_line","title":"start_line  <code>instance-attribute</code>","text":"<pre><code>start_line: int\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[BLOCK_END] = BLOCK_END\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockEndEvent.get_block","title":"get_block","text":"<pre><code>get_block() -&gt; ExtractedBlock[Any, Any] | None\n</code></pre> <p>Get the typed ExtractedBlock if available.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent","title":"hother.streamblocks.core.types.BlockErrorEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Block extraction failed.</p> <p>Emitted when a block cannot be extracted due to validation failure, size limits, missing closing marker, or other errors.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.block_id","title":"block_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>block_id: str | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.end_line","title":"end_line  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_line: int | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.error_code","title":"error_code  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error_code: BlockErrorCode | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.exception","title":"exception  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>exception: Exception | None = Field(\n    default=None, exclude=True\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    frozen=True, arbitrary_types_allowed=True\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.reason","title":"reason  <code>instance-attribute</code>","text":"<pre><code>reason: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.start_line","title":"start_line  <code>instance-attribute</code>","text":"<pre><code>start_line: int\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.syntax","title":"syntax  <code>instance-attribute</code>","text":"<pre><code>syntax: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.BlockErrorEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[BLOCK_ERROR] = BLOCK_ERROR\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent","title":"hother.streamblocks.core.types.TextDeltaEvent","text":"<p>               Bases: <code>BaseEvent</code></p> <p>Real-time text chunk (character/token level).</p> <p>Emitted immediately when text is received from stream, before line completion. Enables live streaming UIs and real-time text display.</p>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.block_id","title":"block_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>block_id: str | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.delta","title":"delta  <code>instance-attribute</code>","text":"<pre><code>delta: str\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.event_id","title":"event_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_id: str = Field(default_factory=lambda: str(uuid4()))\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.inside_block","title":"inside_block  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inside_block: bool = False\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.raw_event","title":"raw_event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>raw_event: Any | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.section","title":"section  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>section: str | None = None\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp: int = Field(\n    default_factory=lambda: int(time() * 1000)\n)\n</code></pre>"},{"location":"reference/events/#hother.streamblocks.core.types.TextDeltaEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Literal[TEXT_DELTA] = TEXT_DELTA\n</code></pre>"},{"location":"reference/extensions/","title":"Extensions","text":""},{"location":"reference/extensions/#extensions-reference","title":"Extensions Reference","text":"<p>Provider-specific extensions for Streamblocks.</p>"},{"location":"reference/extensions/#overview","title":"Overview","text":"<p>Extensions provide adapters for different LLM providers. Each extension implements the adapter protocol to convert provider-specific stream formats.</p> <pre><code>flowchart TB\n    subgraph Extensions[\"Provider Extensions\"]\n        Gemini[gemini]\n        OpenAI[openai]\n        Anthropic[anthropic]\n        AGUI[agui]\n    end\n\n    subgraph Protocol[\"Adapter Protocol\"]\n        Input[InputProtocolAdapter]\n        Output[OutputProtocolAdapter]\n    end\n\n    Gemini --&gt; Input\n    OpenAI --&gt; Input\n    Anthropic --&gt; Input\n    AGUI --&gt; Input\n    AGUI --&gt; Output</code></pre>"},{"location":"reference/extensions/#installation","title":"Installation","text":"<p>Extensions are installed as optional dependencies:</p> uvpip <pre><code># Individual providers\nuv add \"streamblocks[gemini]\"\nuv add \"streamblocks[openai]\"\nuv add \"streamblocks[anthropic]\"\n\n# All providers\nuv add \"streamblocks[all-providers]\"\n</code></pre> <pre><code># Individual providers\npip install \"streamblocks[gemini]\"\npip install \"streamblocks[openai]\"\npip install \"streamblocks[anthropic]\"\n\n# All providers\npip install \"streamblocks[all-providers]\"\n</code></pre>"},{"location":"reference/extensions/#gemini-extension","title":"Gemini Extension","text":"<p>Google Gemini adapter for processing Gemini API responses.</p>"},{"location":"reference/extensions/#installation_1","title":"Installation","text":"uvpip <pre><code>uv add \"streamblocks[gemini]\"\n</code></pre> <pre><code>pip install \"streamblocks[gemini]\"\n</code></pre>"},{"location":"reference/extensions/#usage","title":"Usage","text":"<pre><code>from hother.streamblocks.extensions.gemini import GeminiInputAdapter\n\nadapter = GeminiInputAdapter()\n\n# Use with processor\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=adapter,\n)\n</code></pre>"},{"location":"reference/extensions/#auto-detection","title":"Auto-Detection","text":"<p>The Gemini adapter is automatically detected when processing Gemini responses:</p> <pre><code>import google.generativeai as genai\nfrom hother.streamblocks import StreamBlockProcessor, detect_input_adapter\n\ngenai.configure(api_key=\"...\")  # pragma: allowlist secret\nmodel = genai.GenerativeModel(\"gemini-pro\")\nresponse = model.generate_content(\"...\", stream=True)\n\n# Auto-detect adapter\nadapter = detect_input_adapter(response)\n</code></pre>"},{"location":"reference/extensions/#openai-extension","title":"OpenAI Extension","text":"<p>OpenAI adapter for processing OpenAI API responses.</p>"},{"location":"reference/extensions/#installation_2","title":"Installation","text":"uvpip <pre><code>uv add \"streamblocks[openai]\"\n</code></pre> <pre><code>pip install \"streamblocks[openai]\"\n</code></pre>"},{"location":"reference/extensions/#usage_1","title":"Usage","text":"<pre><code>from hother.streamblocks.extensions.openai import OpenAIInputAdapter\n\nadapter = OpenAIInputAdapter()\n\n# Use with processor\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=adapter,\n)\n</code></pre>"},{"location":"reference/extensions/#with-openai-client","title":"With OpenAI Client","text":"<pre><code>from openai import OpenAI\nfrom hother.streamblocks import StreamBlockProcessor, Registry, DelimiterPreambleSyntax\nfrom hother.streamblocks.extensions.openai import OpenAIInputAdapter\n\nclient = OpenAI()\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": \"...\"}],\n    stream=True,\n)\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=OpenAIInputAdapter(),\n)\n\nasync for event in processor.process_stream(stream):\n    handle_event(event)\n</code></pre>"},{"location":"reference/extensions/#anthropic-extension","title":"Anthropic Extension","text":"<p>Anthropic adapter for processing Claude API responses.</p>"},{"location":"reference/extensions/#installation_3","title":"Installation","text":"uvpip <pre><code>uv add \"streamblocks[anthropic]\"\n</code></pre> <pre><code>pip install \"streamblocks[anthropic]\"\n</code></pre>"},{"location":"reference/extensions/#usage_2","title":"Usage","text":"<pre><code>from hother.streamblocks.extensions.anthropic import AnthropicInputAdapter\n\nadapter = AnthropicInputAdapter()\n\n# Use with processor\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=adapter,\n)\n</code></pre>"},{"location":"reference/extensions/#with-anthropic-client","title":"With Anthropic Client","text":"<pre><code>import anthropic\nfrom hother.streamblocks import StreamBlockProcessor, Registry, DelimiterPreambleSyntax\nfrom hother.streamblocks.extensions.anthropic import AnthropicInputAdapter\n\nclient = anthropic.Anthropic()\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=AnthropicInputAdapter(),\n)\n\nwith client.messages.stream(\n    model=\"claude-3-opus\",\n    max_tokens=1024,\n    messages=[{\"role\": \"user\", \"content\": \"...\"}],\n) as stream:\n    async for event in processor.process_stream(stream):\n        handle_event(event)\n</code></pre>"},{"location":"reference/extensions/#ag-ui-extension","title":"AG-UI Extension","text":"<p>AG-UI protocol adapters for bidirectional streaming.</p>"},{"location":"reference/extensions/#installation_4","title":"Installation","text":"<p>The AG-UI extension is included in the base installation.</p>"},{"location":"reference/extensions/#input-adapter","title":"Input Adapter","text":"<p>Process incoming AG-UI events:</p> <pre><code>from hother.streamblocks.extensions.agui import AGUIInputAdapter\n\nadapter = AGUIInputAdapter()\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=adapter,\n)\n\nasync for event in processor.process_stream(agui_stream):\n    handle_event(event)\n</code></pre>"},{"location":"reference/extensions/#output-adapter","title":"Output Adapter","text":"<p>Convert Streamblocks events to AG-UI protocol:</p> <pre><code>from hother.streamblocks.extensions.agui import AGUIOutputAdapter\n\nadapter = AGUIOutputAdapter()\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    output_adapter=adapter,\n)\n\n# Events are now AG-UI formatted\nasync for event in processor.process_stream(llm_stream):\n    yield event  # AG-UI protocol event\n</code></pre>"},{"location":"reference/extensions/#bidirectional-usage","title":"Bidirectional Usage","text":"<pre><code>from hother.streamblocks.extensions.agui import AGUIInputAdapter, AGUIOutputAdapter\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[DelimiterPreambleSyntax()],\n    input_adapter=AGUIInputAdapter(),\n    output_adapter=AGUIOutputAdapter(),\n)\n</code></pre>"},{"location":"reference/extensions/#event-filtering","title":"Event Filtering","text":"<p>Configure which events are converted:</p> <pre><code>from hother.streamblocks.extensions.agui import AGUIOutputAdapter\n\nadapter = AGUIOutputAdapter(\n    include_text_deltas=True,\n    include_block_content=False,\n    include_metadata=True,\n)\n</code></pre>"},{"location":"reference/extensions/#custom-event-mapping","title":"Custom Event Mapping","text":"<p>Map block types to AG-UI events:</p> <pre><code>adapter = AGUIOutputAdapter(\n    block_type_mapping={\n        \"task\": \"CustomTaskEvent\",\n        \"code\": \"CodeBlockEvent\",\n        \"message\": \"TextMessageContent\",\n    }\n)\n</code></pre>"},{"location":"reference/extensions/#creating-custom-extensions","title":"Creating Custom Extensions","text":"<p>Implement the adapter protocol for custom providers:</p> <pre><code>from hother.streamblocks import InputProtocolAdapter, EventCategory\n\nclass MyProviderAdapter(InputProtocolAdapter):\n    \"\"\"Adapter for MyProvider streams.\"\"\"\n\n    def categorize(self, event) -&gt; EventCategory:\n        \"\"\"Categorize the event type.\"\"\"\n        if hasattr(event, \"text\"):\n            return EventCategory.TEXT_CONTENT\n        if hasattr(event, \"tool_call\"):\n            return EventCategory.PASSTHROUGH\n        return EventCategory.SKIP\n\n    def extract_text(self, event) -&gt; str:\n        \"\"\"Extract text content from event.\"\"\"\n        return event.text\n\n    def get_original_event(self, event):\n        \"\"\"Get the original event for passthrough.\"\"\"\n        return event\n</code></pre>"},{"location":"reference/extensions/#extension-api-reference","title":"Extension API Reference","text":""},{"location":"reference/extensions/#gemini","title":"Gemini","text":""},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini","title":"hother.streamblocks.extensions.gemini","text":"<p>Gemini extension for StreamBlocks.</p> <p>This extension provides input adapters for Google GenAI streams.</p> <p>Importing this module registers the GeminiInputAdapter for auto-detection.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini--import-to-enable-auto-detection","title":"Import to enable auto-detection","text":"<p>import hother.streamblocks.extensions.gemini</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini--auto-detect-from-gemini-stream","title":"Auto-detect from Gemini stream","text":"<p>processor = ProtocolStreamProcessor(registry) async for event in processor.process_stream(gemini_stream): ...     print(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini--or-use-convenience-factory","title":"Or use convenience factory","text":"<p>from hother.streamblocks.extensions.gemini import create_gemini_processor processor = create_gemini_processor(registry)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter","title":"GeminiInputAdapter","text":"<p>Input adapter for Google GenAI streams.</p> <p>Handles chunks from google.genai.models.generate_content_stream() and google.ai.generativelanguage clients.</p> <p>Extracts: - Text from chunk.text attribute - Usage metadata (token counts) - Model version information</p> Example <p>from google import genai adapter = GeminiInputAdapter()</p> <p>async for chunk in client.aio.models.generate_content_stream(...): ...     text = adapter.extract_text(chunk) ...     metadata = adapter.get_metadata(chunk) ...     if metadata: ...         print(f\"Tokens: {metadata['usage']}\")</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter.native_module_prefix","title":"native_module_prefix  <code>class-attribute</code>","text":"<pre><code>native_module_prefix: str = 'google.genai'\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: GenerateContentResponse) -&gt; EventCategory\n</code></pre> <p>Categorize event - all Gemini chunks are text content.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>GenerateContentResponse</code> <p>Gemini GenerateContentResponse chunk</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <p>TEXT_CONTENT for all chunks</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: GenerateContentResponse) -&gt; str | None\n</code></pre> <p>Extract text from chunk.text attribute.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>GenerateContentResponse</code> <p>Gemini GenerateContentResponse chunk</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Text content, or None if not present</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: GenerateContentResponse) -&gt; bool\n</code></pre> <p>Gemini doesn't have explicit finish markers in each chunk.</p> <p>Completion is typically detected by the stream ending.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>GenerateContentResponse</code> <p>Gemini GenerateContentResponse chunk</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Always False - Gemini streams end naturally</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.GeminiInputAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(\n    event: GenerateContentResponse,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract usage metadata and model information.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>GenerateContentResponse</code> <p>Gemini GenerateContentResponse chunk</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary with usage and/or model if present</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.gemini.create_gemini_processor","title":"create_gemini_processor","text":"<pre><code>create_gemini_processor(\n    registry: Registry,\n) -&gt; ProtocolStreamProcessor[Any, BaseEvent]\n</code></pre> <p>Create processor pre-configured for Gemini streams.</p> <p>This is a convenience factory that creates a ProtocolStreamProcessor with GeminiInputAdapter and StreamBlocksOutputAdapter.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>Registry with syntax and block definitions</p> required <p>Returns:</p> Type Description <code>ProtocolStreamProcessor[Any, BaseEvent]</code> <p>Pre-configured processor for Gemini streams</p> Example <p>from hother.streamblocks.extensions.gemini import create_gemini_processor processor = create_gemini_processor(registry) async for event in processor.process_stream(gemini_stream): ...     if isinstance(event, BlockExtractedEvent): ...         print(f\"Block: {event.block.metadata.id}\")</p>"},{"location":"reference/extensions/#openai","title":"OpenAI","text":""},{"location":"reference/extensions/#hother.streamblocks.extensions.openai","title":"hother.streamblocks.extensions.openai","text":"<p>OpenAI extension for StreamBlocks.</p> <p>This extension provides input adapters for OpenAI ChatCompletionChunk streams.</p> <p>Importing this module registers the OpenAIInputAdapter for auto-detection.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai--import-to-enable-auto-detection","title":"Import to enable auto-detection","text":"<p>import hother.streamblocks.extensions.openai</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai--auto-detect-from-openai-stream","title":"Auto-detect from OpenAI stream","text":"<p>processor = ProtocolStreamProcessor(registry) async for event in processor.process_stream(openai_stream): ...     print(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai--or-use-convenience-factory","title":"Or use convenience factory","text":"<p>from hother.streamblocks.extensions.openai import create_openai_processor processor = create_openai_processor(registry)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter","title":"OpenAIInputAdapter","text":"<p>Input adapter for OpenAI ChatCompletionChunk streams.</p> <p>Handles streams from openai.AsyncStream[ChatCompletionChunk].</p> <p>Extracts: - Delta content from choices[0].delta.content - Finish reasons - Model information</p> Example <p>from openai import AsyncOpenAI adapter = OpenAIInputAdapter()</p> <p>client = AsyncOpenAI() stream = await client.chat.completions.create( ...     model=\"gpt-4\", ...     messages=[...], ...     stream=True ... )</p> <p>async for chunk in stream: ...     text = adapter.extract_text(chunk) ...     if adapter.is_complete(chunk): ...         print(\"Stream complete!\")</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter.native_module_prefix","title":"native_module_prefix  <code>class-attribute</code>","text":"<pre><code>native_module_prefix: str = 'openai.types'\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: ChatCompletionChunk) -&gt; EventCategory\n</code></pre> <p>Categorize event - all OpenAI chunks are text content.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>ChatCompletionChunk</code> <p>OpenAI ChatCompletionChunk</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <p>TEXT_CONTENT for all chunks</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: ChatCompletionChunk) -&gt; str | None\n</code></pre> <p>Extract text from choices[0].delta.content.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>ChatCompletionChunk</code> <p>OpenAI ChatCompletionChunk</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Delta content text, or None if not present</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: ChatCompletionChunk) -&gt; bool\n</code></pre> <p>Check if finish_reason is set.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>ChatCompletionChunk</code> <p>OpenAI ChatCompletionChunk</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this is the final chunk</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.OpenAIInputAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(\n    event: ChatCompletionChunk,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract model and finish reason.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>ChatCompletionChunk</code> <p>OpenAI ChatCompletionChunk</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary with model and/or finish_reason if present</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.openai.create_openai_processor","title":"create_openai_processor","text":"<pre><code>create_openai_processor(\n    registry: Registry,\n) -&gt; ProtocolStreamProcessor[Any, BaseEvent]\n</code></pre> <p>Create processor pre-configured for OpenAI streams.</p> <p>This is a convenience factory that creates a ProtocolStreamProcessor with OpenAIInputAdapter and StreamBlocksOutputAdapter.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>Registry with syntax and block definitions</p> required <p>Returns:</p> Type Description <code>ProtocolStreamProcessor[Any, BaseEvent]</code> <p>Pre-configured processor for OpenAI streams</p> Example <p>from hother.streamblocks.extensions.openai import create_openai_processor processor = create_openai_processor(registry) async for event in processor.process_stream(openai_stream): ...     if isinstance(event, BlockExtractedEvent): ...         print(f\"Block: {event.block.metadata.id}\")</p>"},{"location":"reference/extensions/#anthropic","title":"Anthropic","text":""},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic","title":"hother.streamblocks.extensions.anthropic","text":"<p>Anthropic extension for StreamBlocks.</p> <p>This extension provides input adapters for Anthropic message streams.</p> <p>Importing this module registers the AnthropicInputAdapter for auto-detection.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic--import-to-enable-auto-detection","title":"Import to enable auto-detection","text":"<p>import hother.streamblocks.extensions.anthropic</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic--auto-detect-from-anthropic-stream","title":"Auto-detect from Anthropic stream","text":"<p>processor = ProtocolStreamProcessor(registry) async for event in processor.process_stream(anthropic_stream): ...     print(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic--or-use-convenience-factory","title":"Or use convenience factory","text":"<p>from hother.streamblocks.extensions.anthropic import create_anthropic_processor processor = create_anthropic_processor(registry)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicEvent","title":"AnthropicEvent  <code>module-attribute</code>","text":"<pre><code>AnthropicEvent = (\n    ContentBlockDeltaEvent\n    | MessageDeltaEvent\n    | MessageStopEvent\n)\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter","title":"AnthropicInputAdapter","text":"<p>Input adapter for Anthropic message streams.</p> <p>Handles event-based streaming from anthropic.MessageStream.</p> <p>Anthropic uses different event types: - content_block_delta: Contains text deltas (TEXT_CONTENT) - message_delta: Contains usage information (PASSTHROUGH) - message_stop: Signals stream completion (PASSTHROUGH) - Other events: PASSTHROUGH</p> Example <p>from anthropic import AsyncAnthropic adapter = AnthropicInputAdapter()</p> <p>client = AsyncAnthropic() async with client.messages.stream(...) as stream: ...     async for event in stream: ...         text = adapter.extract_text(event) ...         if text: ...             print(text, end='', flush=True) ...         if adapter.is_complete(event): ...             print(\"\\nDone!\")</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter.native_module_prefix","title":"native_module_prefix  <code>class-attribute</code>","text":"<pre><code>native_module_prefix: str = 'anthropic.'\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: AnthropicEvent) -&gt; EventCategory\n</code></pre> <p>Categorize event based on type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AnthropicEvent</code> <p>Anthropic event</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <p>TEXT_CONTENT for content_block_delta events, PASSTHROUGH for others</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: AnthropicEvent) -&gt; str | None\n</code></pre> <p>Extract text from content_block_delta events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AnthropicEvent</code> <p>Anthropic event</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Delta text if present, None otherwise</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: AnthropicEvent) -&gt; bool\n</code></pre> <p>Check for message_stop event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AnthropicEvent</code> <p>Anthropic event</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this is the message_stop event</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.AnthropicInputAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(\n    event: AnthropicEvent,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract stop reason and usage information.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>AnthropicEvent</code> <p>Anthropic event</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary with stop_reason or usage if present</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.anthropic.create_anthropic_processor","title":"create_anthropic_processor","text":"<pre><code>create_anthropic_processor(\n    registry: Registry,\n) -&gt; ProtocolStreamProcessor[Any, BaseEvent]\n</code></pre> <p>Create processor pre-configured for Anthropic streams.</p> <p>This is a convenience factory that creates a ProtocolStreamProcessor with AnthropicInputAdapter and StreamBlocksOutputAdapter.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>Registry with syntax and block definitions</p> required <p>Returns:</p> Type Description <code>ProtocolStreamProcessor[Any, BaseEvent]</code> <p>Pre-configured processor for Anthropic streams</p> Example <p>from hother.streamblocks.extensions.anthropic import create_anthropic_processor processor = create_anthropic_processor(registry) async for event in processor.process_stream(anthropic_stream): ...     if isinstance(event, BlockExtractedEvent): ...         print(f\"Block: {event.block.metadata.id}\")</p>"},{"location":"reference/extensions/#ag-ui","title":"AG-UI","text":""},{"location":"reference/extensions/#hother.streamblocks.extensions.agui","title":"hother.streamblocks.extensions.agui","text":"<p>AG-UI extension for StreamBlocks.</p> <p>This extension provides bidirectional adapters for the AG-UI protocol.</p> <p>AG-UI is an event-based protocol for agent-to-frontend communication with event types for lifecycle, text messages, tool calls, and state management.</p> <p>Importing this module registers the AGUIInputAdapter for auto-detection.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui--import-to-enable-auto-detection","title":"Import to enable auto-detection","text":"<p>import hother.streamblocks.extensions.agui</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui--auto-detect-from-ag-ui-stream","title":"Auto-detect from AG-UI stream","text":"<p>processor = ProtocolStreamProcessor(registry) async for event in processor.process_stream(agui_stream): ...     print(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui--bidirectional-ag-ui-in-ag-ui-out","title":"Bidirectional: AG-UI in, AG-UI out","text":"<p>from hother.streamblocks.extensions.agui import ( ...     create_agui_bidirectional_processor, ...     AGUIEventFilter, ... ) processor = create_agui_bidirectional_processor( ...     registry, ...     event_filter=AGUIEventFilter.BLOCKS_WITH_PROGRESS, ... ) async for event in processor.process_stream(agui_stream): ...     # event is an AG-UI event (dict format) ...     if event[\"type\"] == \"CUSTOM\": ...         handle_streamblocks_event(event) ...     else: ...         forward_to_frontend(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter","title":"AGUIEventFilter","text":"<p>               Bases: <code>Flag</code></p> <p>Configurable event filtering for AG-UI output adapter.</p> <p>Use these flags to control which StreamBlocks events are emitted when using AGUIOutputAdapter.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter--only-emit-block-related-events","title":"Only emit block-related events","text":"<p>filter = AGUIEventFilter.BLOCKS_ONLY</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter--emit-blocks-with-progress-updates","title":"Emit blocks with progress updates","text":"<p>filter = AGUIEventFilter.BLOCKS_WITH_PROGRESS</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter--custom-combination","title":"Custom combination","text":"<p>filter = AGUIEventFilter.TEXT_DELTA | AGUIEventFilter.BLOCK_EXTRACTED</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 0\n</code></pre> <p>Emit no StreamBlocks events.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.RAW_TEXT","title":"RAW_TEXT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RAW_TEXT = auto()\n</code></pre> <p>Emit RawTextEvent as TextMessageContentEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.TEXT_DELTA","title":"TEXT_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_DELTA = auto()\n</code></pre> <p>Emit TextDeltaEvent as TextMessageContentEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCK_OPENED","title":"BLOCK_OPENED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_OPENED = auto()\n</code></pre> <p>Emit BlockOpenedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCK_DELTA","title":"BLOCK_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_DELTA = auto()\n</code></pre> <p>Emit section delta events (BlockHeaderDeltaEvent, BlockMetadataDeltaEvent, BlockContentDeltaEvent) as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCK_EXTRACTED","title":"BLOCK_EXTRACTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_EXTRACTED = auto()\n</code></pre> <p>Emit BlockExtractedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCK_REJECTED","title":"BLOCK_REJECTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_REJECTED = auto()\n</code></pre> <p>Emit BlockRejectedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.ALL","title":"ALL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ALL = (\n    RAW_TEXT\n    | TEXT_DELTA\n    | BLOCK_OPENED\n    | BLOCK_DELTA\n    | BLOCK_EXTRACTED\n    | BLOCK_REJECTED\n)\n</code></pre> <p>Emit all StreamBlocks events.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCKS_ONLY","title":"BLOCKS_ONLY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCKS_ONLY = (\n    BLOCK_OPENED | BLOCK_EXTRACTED | BLOCK_REJECTED\n)\n</code></pre> <p>Emit only block lifecycle events (opened, extracted, rejected).</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.BLOCKS_WITH_PROGRESS","title":"BLOCKS_WITH_PROGRESS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCKS_WITH_PROGRESS = (\n    BLOCK_OPENED\n    | BLOCK_DELTA\n    | BLOCK_EXTRACTED\n    | BLOCK_REJECTED\n)\n</code></pre> <p>Emit block lifecycle events plus progress updates.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIEventFilter.TEXT_AND_FINAL","title":"TEXT_AND_FINAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_AND_FINAL = (\n    TEXT_DELTA | BLOCK_EXTRACTED | BLOCK_REJECTED\n)\n</code></pre> <p>Emit text streaming plus final block results.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter","title":"AGUIInputAdapter","text":"<p>Input adapter for AG-UI protocol events.</p> <p>Handles event-based streaming from AG-UI protocol.</p> <p>AG-UI Event Categories: - TEXT_MESSAGE_CONTENT, TEXT_MESSAGE_CHUNK: TEXT_CONTENT (has text) - All other events: PASSTHROUGH (lifecycle, tool calls, state)</p> Example <p>adapter = AGUIInputAdapter()</p> <p>async for event in agui_stream: ...     category = adapter.categorize(event) ...     if category == EventCategory.TEXT_CONTENT: ...         text = adapter.extract_text(event) ...         print(text, end='', flush=True)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter.native_module_prefix","title":"native_module_prefix  <code>class-attribute</code>","text":"<pre><code>native_module_prefix: str = 'ag_ui.'\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: BaseEvent) -&gt; EventCategory\n</code></pre> <p>Categorize event based on type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <p>TEXT_CONTENT for text message events, PASSTHROUGH for others</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: BaseEvent) -&gt; str | None\n</code></pre> <p>Extract text from TEXT_CONTENT events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Delta text if TEXT_MESSAGE_CONTENT or TEXT_MESSAGE_CHUNK</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: BaseEvent) -&gt; bool\n</code></pre> <p>Check for RUN_FINISHED event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this is the RUN_FINISHED event</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIInputAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(event: BaseEvent) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract protocol metadata.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary with event_type and timestamp if available</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter","title":"AGUIOutputAdapter","text":"<p>Output adapter for AG-UI protocol events.</p> <p>Transforms StreamBlocks events into AG-UI CustomEvent format.</p> <p>StreamBlocks events are mapped to AG-UI as follows: - TextDeltaEvent, TextContentEvent \u2192 TextMessageContentEvent - BlockStartEvent \u2192 CustomEvent(name=\"streamblocks.block_start\") - BlockHeaderDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockMetadataDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockContentDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockEndEvent \u2192 CustomEvent(name=\"streamblocks.block_end\") - BlockErrorEvent \u2192 CustomEvent(name=\"streamblocks.block_error\")</p> <p>Passthrough events (AG-UI events from input) are passed through unchanged.</p> Example <p>adapter = AGUIOutputAdapter(event_filter=AGUIEventFilter.BLOCKS_WITH_PROGRESS)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter--convert-streamblocks-event-to-ag-ui-event","title":"Convert StreamBlocks event to AG-UI event","text":"<p>agui_event = adapter.to_protocol_event(block_extracted_event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter--pass-through-ag-ui-events","title":"Pass through AG-UI events","text":"<p>original = adapter.passthrough(run_started_event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter.event_filter","title":"event_filter  <code>instance-attribute</code>","text":"<pre><code>event_filter = event_filter\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter.to_protocol_event","title":"to_protocol_event","text":"<pre><code>to_protocol_event(\n    event: BaseEvent,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Convert StreamBlocks event to AG-UI event format.</p> <p>Returns a dictionary representation of the AG-UI event that can be serialized or converted to the actual AG-UI event type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>StreamBlocks event</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary representing AG-UI event, or None if filtered out</p> Note <p>Returns dict rather than actual AG-UI types to avoid requiring ag-ui-protocol as a runtime dependency.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter.passthrough","title":"passthrough","text":"<pre><code>passthrough(original_event: Any) -&gt; Any\n</code></pre> <p>Handle passthrough events.</p> <p>For AG-UI events, passes them through unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>original_event</code> <code>Any</code> <p>Original input event</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The original event unchanged</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.AGUIOutputAdapter.reset_message_id","title":"reset_message_id","text":"<pre><code>reset_message_id() -&gt; None\n</code></pre> <p>Reset message ID for new conversation turn.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.create_agui_processor","title":"create_agui_processor","text":"<pre><code>create_agui_processor(\n    registry: Registry,\n) -&gt; ProtocolStreamProcessor[Any, BaseEvent]\n</code></pre> <p>Create processor for AG-UI \u2192 StreamBlocks (unidirectional).</p> <p>This processor takes AG-UI events as input and emits native StreamBlocks events.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>Registry with syntax and block definitions</p> required <p>Returns:</p> Type Description <code>ProtocolStreamProcessor[Any, BaseEvent]</code> <p>Pre-configured processor for AG-UI input, StreamBlocks output</p> Example <p>from hother.streamblocks.extensions.agui import create_agui_processor processor = create_agui_processor(registry) async for event in processor.process_stream(agui_stream): ...     if isinstance(event, BlockExtractedEvent): ...         print(f\"Block: {event.block.metadata.id}\")</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.create_agui_bidirectional_processor","title":"create_agui_bidirectional_processor","text":"<pre><code>create_agui_bidirectional_processor(\n    registry: Registry, event_filter: AGUIEventFilter = ALL\n) -&gt; ProtocolStreamProcessor[Any, dict[str, Any]]\n</code></pre> <p>Create processor for AG-UI \u2192 AG-UI (bidirectional).</p> <p>This processor takes AG-UI events as input and emits AG-UI events as output. StreamBlocks events are converted to AG-UI CustomEvent format.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Registry</code> <p>Registry with syntax and block definitions</p> required <code>event_filter</code> <code>AGUIEventFilter</code> <p>Filter to control which StreamBlocks events are emitted</p> <code>ALL</code> <p>Returns:</p> Type Description <code>ProtocolStreamProcessor[Any, dict[str, Any]]</code> <p>Pre-configured processor for AG-UI input and output</p> Example <p>from hother.streamblocks.extensions.agui import ( ...     create_agui_bidirectional_processor, ...     AGUIEventFilter, ... ) processor = create_agui_bidirectional_processor( ...     registry, ...     event_filter=AGUIEventFilter.BLOCKS_WITH_PROGRESS, ... ) async for event in processor.process_stream(agui_stream): ...     if event[\"type\"] == \"CUSTOM\": ...         if event[\"name\"] == \"streamblocks.block_extracted\": ...             handle_block(event[\"value\"]) ...     else: ...         # Passthrough: lifecycle, tool calls, state ...         forward_to_frontend(event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter","title":"hother.streamblocks.extensions.agui.input_adapter","text":"<p>AG-UI input adapter for StreamBlocks.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUITextEvent","title":"AGUITextEvent  <code>module-attribute</code>","text":"<pre><code>AGUITextEvent = (\n    TextMessageContentEvent | TextMessageChunkEvent\n)\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter","title":"AGUIInputAdapter","text":"<p>Input adapter for AG-UI protocol events.</p> <p>Handles event-based streaming from AG-UI protocol.</p> <p>AG-UI Event Categories: - TEXT_MESSAGE_CONTENT, TEXT_MESSAGE_CHUNK: TEXT_CONTENT (has text) - All other events: PASSTHROUGH (lifecycle, tool calls, state)</p> Example <p>adapter = AGUIInputAdapter()</p> <p>async for event in agui_stream: ...     category = adapter.categorize(event) ...     if category == EventCategory.TEXT_CONTENT: ...         text = adapter.extract_text(event) ...         print(text, end='', flush=True)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter.native_module_prefix","title":"native_module_prefix  <code>class-attribute</code>","text":"<pre><code>native_module_prefix: str = 'ag_ui.'\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter.categorize","title":"categorize","text":"<pre><code>categorize(event: BaseEvent) -&gt; EventCategory\n</code></pre> <p>Categorize event based on type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>EventCategory</code> <p>TEXT_CONTENT for text message events, PASSTHROUGH for others</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter.extract_text","title":"extract_text","text":"<pre><code>extract_text(event: BaseEvent) -&gt; str | None\n</code></pre> <p>Extract text from TEXT_CONTENT events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Delta text if TEXT_MESSAGE_CONTENT or TEXT_MESSAGE_CHUNK</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter.get_metadata","title":"get_metadata","text":"<pre><code>get_metadata(event: BaseEvent) -&gt; dict[str, Any] | None\n</code></pre> <p>Extract protocol metadata.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary with event_type and timestamp if available</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.input_adapter.AGUIInputAdapter.is_complete","title":"is_complete","text":"<pre><code>is_complete(event: BaseEvent) -&gt; bool\n</code></pre> <p>Check for RUN_FINISHED event.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>AG-UI BaseEvent</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this is the RUN_FINISHED event</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter","title":"hother.streamblocks.extensions.agui.output_adapter","text":"<p>AG-UI output adapter for StreamBlocks.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter","title":"AGUIOutputAdapter","text":"<p>Output adapter for AG-UI protocol events.</p> <p>Transforms StreamBlocks events into AG-UI CustomEvent format.</p> <p>StreamBlocks events are mapped to AG-UI as follows: - TextDeltaEvent, TextContentEvent \u2192 TextMessageContentEvent - BlockStartEvent \u2192 CustomEvent(name=\"streamblocks.block_start\") - BlockHeaderDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockMetadataDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockContentDeltaEvent \u2192 CustomEvent(name=\"streamblocks.block_delta\") - BlockEndEvent \u2192 CustomEvent(name=\"streamblocks.block_end\") - BlockErrorEvent \u2192 CustomEvent(name=\"streamblocks.block_error\")</p> <p>Passthrough events (AG-UI events from input) are passed through unchanged.</p> Example <p>adapter = AGUIOutputAdapter(event_filter=AGUIEventFilter.BLOCKS_WITH_PROGRESS)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter--convert-streamblocks-event-to-ag-ui-event","title":"Convert StreamBlocks event to AG-UI event","text":"<p>agui_event = adapter.to_protocol_event(block_extracted_event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter--pass-through-ag-ui-events","title":"Pass through AG-UI events","text":"<p>original = adapter.passthrough(run_started_event)</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter.event_filter","title":"event_filter  <code>instance-attribute</code>","text":"<pre><code>event_filter = event_filter\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter.passthrough","title":"passthrough","text":"<pre><code>passthrough(original_event: Any) -&gt; Any\n</code></pre> <p>Handle passthrough events.</p> <p>For AG-UI events, passes them through unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>original_event</code> <code>Any</code> <p>Original input event</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The original event unchanged</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter.reset_message_id","title":"reset_message_id","text":"<pre><code>reset_message_id() -&gt; None\n</code></pre> <p>Reset message ID for new conversation turn.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.AGUIOutputAdapter.to_protocol_event","title":"to_protocol_event","text":"<pre><code>to_protocol_event(\n    event: BaseEvent,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Convert StreamBlocks event to AG-UI event format.</p> <p>Returns a dictionary representation of the AG-UI event that can be serialized or converted to the actual AG-UI event type.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>BaseEvent</code> <p>StreamBlocks event</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Dictionary representing AG-UI event, or None if filtered out</p> Note <p>Returns dict rather than actual AG-UI types to avoid requiring ag-ui-protocol as a runtime dependency.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.HasEventType","title":"HasEventType","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for events with a type attribute.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.output_adapter.HasEventType.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Any\n</code></pre>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters","title":"hother.streamblocks.extensions.agui.filters","text":"<p>Event filter for AG-UI output adapter.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter","title":"AGUIEventFilter","text":"<p>               Bases: <code>Flag</code></p> <p>Configurable event filtering for AG-UI output adapter.</p> <p>Use these flags to control which StreamBlocks events are emitted when using AGUIOutputAdapter.</p> Example"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter--only-emit-block-related-events","title":"Only emit block-related events","text":"<p>filter = AGUIEventFilter.BLOCKS_ONLY</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter--emit-blocks-with-progress-updates","title":"Emit blocks with progress updates","text":"<p>filter = AGUIEventFilter.BLOCKS_WITH_PROGRESS</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter--custom-combination","title":"Custom combination","text":"<p>filter = AGUIEventFilter.TEXT_DELTA | AGUIEventFilter.BLOCK_EXTRACTED</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.ALL","title":"ALL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ALL = (\n    RAW_TEXT\n    | TEXT_DELTA\n    | BLOCK_OPENED\n    | BLOCK_DELTA\n    | BLOCK_EXTRACTED\n    | BLOCK_REJECTED\n)\n</code></pre> <p>Emit all StreamBlocks events.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCKS_ONLY","title":"BLOCKS_ONLY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCKS_ONLY = (\n    BLOCK_OPENED | BLOCK_EXTRACTED | BLOCK_REJECTED\n)\n</code></pre> <p>Emit only block lifecycle events (opened, extracted, rejected).</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCKS_WITH_PROGRESS","title":"BLOCKS_WITH_PROGRESS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCKS_WITH_PROGRESS = (\n    BLOCK_OPENED\n    | BLOCK_DELTA\n    | BLOCK_EXTRACTED\n    | BLOCK_REJECTED\n)\n</code></pre> <p>Emit block lifecycle events plus progress updates.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCK_DELTA","title":"BLOCK_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_DELTA = auto()\n</code></pre> <p>Emit section delta events (BlockHeaderDeltaEvent, BlockMetadataDeltaEvent, BlockContentDeltaEvent) as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCK_EXTRACTED","title":"BLOCK_EXTRACTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_EXTRACTED = auto()\n</code></pre> <p>Emit BlockExtractedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCK_OPENED","title":"BLOCK_OPENED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_OPENED = auto()\n</code></pre> <p>Emit BlockOpenedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.BLOCK_REJECTED","title":"BLOCK_REJECTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BLOCK_REJECTED = auto()\n</code></pre> <p>Emit BlockRejectedEvent as CustomEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 0\n</code></pre> <p>Emit no StreamBlocks events.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.RAW_TEXT","title":"RAW_TEXT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RAW_TEXT = auto()\n</code></pre> <p>Emit RawTextEvent as TextMessageContentEvent.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.TEXT_AND_FINAL","title":"TEXT_AND_FINAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_AND_FINAL = (\n    TEXT_DELTA | BLOCK_EXTRACTED | BLOCK_REJECTED\n)\n</code></pre> <p>Emit text streaming plus final block results.</p>"},{"location":"reference/extensions/#hother.streamblocks.extensions.agui.filters.AGUIEventFilter.TEXT_DELTA","title":"TEXT_DELTA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TEXT_DELTA = auto()\n</code></pre> <p>Emit TextDeltaEvent as TextMessageContentEvent.</p>"},{"location":"reference/syntaxes/","title":"Syntaxes","text":""},{"location":"reference/syntaxes/#syntaxes-reference","title":"Syntaxes Reference","text":"<p>Block syntax definitions for parsing different formats.</p>"},{"location":"reference/syntaxes/#overview","title":"Overview","text":"<p>Syntaxes define how blocks are detected and parsed in text streams. Streamblocks includes three built-in syntaxes.</p> <pre><code>classDiagram\n    class BaseSyntax {\n        &lt;&lt;abstract&gt;&gt;\n        +detect(line: str) DetectionResult\n        +parse_metadata(text: str) dict\n        +parse_content(text: str) str\n    }\n\n    BaseSyntax &lt;|-- DelimiterPreambleSyntax\n    BaseSyntax &lt;|-- DelimiterFrontmatterSyntax\n    BaseSyntax &lt;|-- MarkdownFrontmatterSyntax</code></pre>"},{"location":"reference/syntaxes/#delimiterpreamblesyntax","title":"DelimiterPreambleSyntax","text":"<p>Compact inline syntax with metadata in the opening marker.</p>"},{"location":"reference/syntaxes/#format","title":"Format","text":"<pre><code>!!block_id:block_type\nBlock content here\n!!end\n</code></pre>"},{"location":"reference/syntaxes/#usage","title":"Usage","text":"<pre><code>from hother.streamblocks import DelimiterPreambleSyntax\n\nsyntax = DelimiterPreambleSyntax()\n\n# Custom delimiters\nsyntax = DelimiterPreambleSyntax(\n    start_pattern=r\"^&lt;&lt;(\\w+):(\\w+)$\",\n    end_marker=\"&lt;&lt;end\",\n)\n</code></pre>"},{"location":"reference/syntaxes/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>start_pattern</code> <code>str</code> <code>r\"^!!(\\w+):(\\w+)$\"</code> Regex for opening marker <code>end_marker</code> <code>str</code> <code>\"!!end\"</code> Closing marker string"},{"location":"reference/syntaxes/#example","title":"Example","text":"<pre><code>!!task01:task\nReview the pull request\nAdd comments for improvement\n!!end\n\n!!code01:code\ndef hello():\n    print(\"Hello!\")\n!!end\n</code></pre>"},{"location":"reference/syntaxes/#delimiterfrontmattersyntax","title":"DelimiterFrontmatterSyntax","text":"<p>Delimiter syntax with YAML frontmatter metadata section.</p>"},{"location":"reference/syntaxes/#format_1","title":"Format","text":"<pre><code>&lt;&lt;&lt;BLOCK\nid: block01\ntype: task\npriority: high\n&gt;&gt;&gt;\nBlock content here\n&lt;&lt;&lt;END&gt;&gt;&gt;\n</code></pre>"},{"location":"reference/syntaxes/#usage_1","title":"Usage","text":"<pre><code>from hother.streamblocks import DelimiterFrontmatterSyntax\n\nsyntax = DelimiterFrontmatterSyntax()\n\n# Custom delimiters\nsyntax = DelimiterFrontmatterSyntax(\n    start_delimiter=\"[[START]]\",\n    metadata_end=\"[[META]]\",\n    end_delimiter=\"[[END]]\",\n)\n</code></pre>"},{"location":"reference/syntaxes/#parameters_1","title":"Parameters","text":"Parameter Type Default Description <code>start_delimiter</code> <code>str</code> <code>\"&lt;&lt;&lt;BLOCK\"</code> Opening marker <code>metadata_end</code> <code>str</code> <code>\"&gt;&gt;&gt;\"</code> Metadata section end <code>end_delimiter</code> <code>str</code> <code>\"&lt;&lt;&lt;END&gt;&gt;&gt;\"</code> Closing marker"},{"location":"reference/syntaxes/#example_1","title":"Example","text":"<pre><code>&lt;&lt;&lt;BLOCK\nid: message01\ntype: message\nauthor: assistant\n&gt;&gt;&gt;\nHello! How can I help you today?\n&lt;&lt;&lt;END&gt;&gt;&gt;\n</code></pre>"},{"location":"reference/syntaxes/#markdownfrontmattersyntax","title":"MarkdownFrontmatterSyntax","text":"<p>Standard Markdown frontmatter with YAML metadata.</p>"},{"location":"reference/syntaxes/#format_2","title":"Format","text":"<pre><code>---\nid: block01\ntype: task\npriority: high\n---\nBlock content here\n---\n</code></pre>"},{"location":"reference/syntaxes/#usage_2","title":"Usage","text":"<pre><code>from hother.streamblocks import MarkdownFrontmatterSyntax\n\nsyntax = MarkdownFrontmatterSyntax()\n\n# Custom delimiters\nsyntax = MarkdownFrontmatterSyntax(\n    delimiter=\"+++\",  # TOML-style\n)\n</code></pre>"},{"location":"reference/syntaxes/#parameters_2","title":"Parameters","text":"Parameter Type Default Description <code>delimiter</code> <code>str</code> <code>\"---\"</code> Frontmatter delimiter"},{"location":"reference/syntaxes/#example_2","title":"Example","text":"<pre><code>---\nid: article01\ntype: article\nauthor: John Doe\ntags:\n  - python\n  - tutorial\n---\n# Introduction\n\nThis is the article content.\n\n---\n</code></pre>"},{"location":"reference/syntaxes/#syntax-selection","title":"Syntax Selection","text":"<p>Choose syntax based on your use case:</p> Syntax Best For Pros Cons <code>DelimiterPreambleSyntax</code> LLM output, tool calls Compact, easy to generate Limited metadata <code>DelimiterFrontmatterSyntax</code> Structured documents Full YAML metadata More verbose <code>MarkdownFrontmatterSyntax</code> Markdown documents Standard format Conflicts with content"},{"location":"reference/syntaxes/#creating-custom-syntaxes","title":"Creating Custom Syntaxes","text":"<p>Extend <code>BaseSyntax</code> for custom formats:</p> <pre><code>from hother.streamblocks.syntaxes.base import BaseSyntax\nfrom hother.streamblocks import DetectionResult\n\nclass XMLBlockSyntax(BaseSyntax):\n    \"\"\"XML-style block syntax.\"\"\"\n\n    def detect(self, line: str) -&gt; DetectionResult:\n        \"\"\"Detect block markers in a line.\"\"\"\n        if line.startswith(\"&lt;block\"):\n            # Parse attributes\n            import re\n            match = re.match(r'&lt;block\\s+id=\"(\\w+)\"\\s+type=\"(\\w+)\"&gt;', line)\n            if match:\n                return DetectionResult(\n                    is_opening=True,\n                    metadata={\n                        \"id\": match.group(1),\n                        \"block_type\": match.group(2),\n                    },\n                )\n        if line == \"&lt;/block&gt;\":\n            return DetectionResult(is_closing=True)\n        return DetectionResult()\n\n    def parse_metadata(self, text: str) -&gt; dict:\n        \"\"\"Parse metadata from text.\"\"\"\n        return {}  # Metadata parsed in detect()\n\n    def parse_content(self, text: str) -&gt; str:\n        \"\"\"Parse content from text.\"\"\"\n        return text.strip()\n\n    @property\n    def name(self) -&gt; str:\n        return \"xml_block\"\n</code></pre>"},{"location":"reference/syntaxes/#required-methods","title":"Required Methods","text":"Method Description <code>detect(line)</code> Detect block markers, return <code>DetectionResult</code> <code>parse_metadata(text)</code> Parse metadata section to dict <code>parse_content(text)</code> Parse content section <code>name</code> Syntax name property"},{"location":"reference/syntaxes/#detectionresult-fields","title":"DetectionResult Fields","text":"Field Type Description <code>is_opening</code> <code>bool</code> Line is block opening marker <code>is_closing</code> <code>bool</code> Line is block closing marker <code>is_metadata_boundary</code> <code>bool</code> Line ends metadata section <code>metadata</code> <code>dict \\| None</code> Inline metadata from marker"},{"location":"reference/syntaxes/#multiple-syntaxes","title":"Multiple Syntaxes","text":"<p>Use multiple syntaxes in a single processor:</p> <pre><code>from hother.streamblocks import (\n    StreamBlockProcessor,\n    Registry,\n    DelimiterPreambleSyntax,\n    MarkdownFrontmatterSyntax,\n)\n\nprocessor = StreamBlockProcessor(\n    registry=Registry(),\n    syntaxes=[\n        DelimiterPreambleSyntax(),\n        MarkdownFrontmatterSyntax(),\n    ],\n)\n\n# Both formats are detected\ntext = \"\"\"\n!!task01:task\nDo something\n!!end\n\n---\nid: article01\ntype: article\n---\nArticle content\n---\n\"\"\"\n</code></pre>"},{"location":"reference/syntaxes/#api-reference","title":"API Reference","text":""},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax","title":"hother.streamblocks.syntaxes.DelimiterPreambleSyntax","text":"<p>               Bases: <code>BaseSyntax</code></p> <p>This syntax uses delimiter markers with inline metadata in the opening line. Metadata is extracted from the delimiter preamble, and all lines between opening and closing delimiters become the content.</p> Format <p>!!:[:param1:param2:...] Content lines here !!end</p> The opening delimiter must include <ul> <li>Block ID (alphanumeric, required)</li> <li>Block type (alphanumeric, required)</li> <li>Additional parameters (optional, colon-separated)</li> </ul> <p>Additional parameters are stored as param_0, param_1, etc. in metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple block with just ID and type\n&gt;&gt;&gt; '''\n... !!patch001:patch\n... Fix the login bug\n... !!end\n... '''\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Block with parameters\n&gt;&gt;&gt; '''\n... !!file123:operation:create:urgent\n... Create new config file\n... !!end\n... '''\n&gt;&gt;&gt; # Metadata will be: {\n&gt;&gt;&gt; #     \"id\": \"file123\",\n&gt;&gt;&gt; #     \"block_type\": \"operation\",\n&gt;&gt;&gt; #     \"param_0\": \"create\",\n&gt;&gt;&gt; #     \"param_1\": \"urgent\"\n&gt;&gt;&gt; # }\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>delimiter</code> <code>str</code> <p>Opening delimiter string (default: \"!!\")</p> <code>'!!'</code>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.delimiter","title":"delimiter  <code>instance-attribute</code>","text":"<pre><code>delimiter = delimiter\n</code></pre>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.detect_line","title":"detect_line","text":"<pre><code>detect_line(\n    line: str, candidate: BlockCandidate | None = None\n) -&gt; DetectionResult\n</code></pre> <p>Detect delimiter-based markers.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.should_accumulate_metadata","title":"should_accumulate_metadata","text":"<pre><code>should_accumulate_metadata(\n    candidate: BlockCandidate,\n) -&gt; bool\n</code></pre> <p>No separate metadata section for this syntax.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.extract_block_type","title":"extract_block_type","text":"<pre><code>extract_block_type(candidate: BlockCandidate) -&gt; str | None\n</code></pre> <p>Extract block_type from opening line.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.parse_block","title":"parse_block","text":"<pre><code>parse_block(\n    candidate: BlockCandidate,\n    block_class: type[Any] | None = None,\n) -&gt; ParseResult[BaseMetadata, BaseContent]\n</code></pre> <p>Parse the complete block using the specified block class.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.validate_block","title":"validate_block","text":"<pre><code>validate_block(\n    _block: ExtractedBlock[BaseMetadata, BaseContent],\n) -&gt; bool\n</code></pre> <p>Additional validation after parsing.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.parse_metadata_early","title":"parse_metadata_early","text":"<pre><code>parse_metadata_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse metadata from inline preamble.</p> <p>For this syntax, metadata is extracted from the opening line (e.g., !!id:type:param1:param2).</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterPreambleSyntax.parse_content_early","title":"parse_content_early","text":"<pre><code>parse_content_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse content section early.</p> <p>Returns raw content dict with the content text.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax","title":"hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax","text":"<p>               Bases: <code>BaseSyntax</code>, <code>YAMLFrontmatterMixin</code></p> <p>This syntax uses simple delimiter markers with YAML frontmatter for metadata. The frontmatter section is delimited by --- markers and must be valid YAML.</p> Format The YAML frontmatter should include <ul> <li>id: Block identifier (required if using BaseMetadata)</li> <li>block_type: Block type (required if using BaseMetadata)</li> <li>Any additional custom fields defined in your metadata class</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple block with minimal metadata\n&gt;&gt;&gt; '''\n... !!start\n... ---\n... id: msg001\n... block_type: message\n... ---\n... Hello, world!\n... !!end\n... '''\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Block with nested YAML metadata\n&gt;&gt;&gt; '''\n... !!start\n... ---\n... id: task001\n... block_type: task\n... priority: high\n... tags:\n...   - urgent\n...   - backend\n... ---\n... Implement user authentication\n... !!end\n... '''\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>start_delimiter</code> <code>str</code> <p>Opening delimiter string (default: \"!!start\")</p> <code>'!!start'</code> <code>end_delimiter</code> <code>str</code> <p>Closing delimiter string (default: \"!!end\")</p> <code>'!!end'</code>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax--start","title":"!!start","text":"<p>id: block_001 block_type: example custom_field: value</p> <p>Content lines here !!end</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.start_delimiter","title":"start_delimiter  <code>instance-attribute</code>","text":"<pre><code>start_delimiter = start_delimiter\n</code></pre>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.end_delimiter","title":"end_delimiter  <code>instance-attribute</code>","text":"<pre><code>end_delimiter = end_delimiter\n</code></pre>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.detect_line","title":"detect_line","text":"<pre><code>detect_line(\n    line: str, candidate: BlockCandidate | None = None\n) -&gt; DetectionResult\n</code></pre> <p>Detect delimiter markers and frontmatter boundaries.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.should_accumulate_metadata","title":"should_accumulate_metadata","text":"<pre><code>should_accumulate_metadata(\n    candidate: BlockCandidate,\n) -&gt; bool\n</code></pre> <p>Check if we're still in metadata section.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.extract_block_type","title":"extract_block_type","text":"<pre><code>extract_block_type(candidate: BlockCandidate) -&gt; str | None\n</code></pre> <p>Extract block_type from YAML frontmatter.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.parse_block","title":"parse_block","text":"<pre><code>parse_block(\n    candidate: BlockCandidate,\n    block_class: type[Any] | None = None,\n) -&gt; ParseResult[BaseMetadata, BaseContent]\n</code></pre> <p>Parse the complete block using the specified block class.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.validate_block","title":"validate_block","text":"<pre><code>validate_block(\n    _block: ExtractedBlock[BaseMetadata, BaseContent],\n) -&gt; bool\n</code></pre> <p>Additional validation after parsing.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.parse_metadata_early","title":"parse_metadata_early","text":"<pre><code>parse_metadata_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse YAML metadata section early.</p> <p>Returns parsed YAML frontmatter as a dict.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.DelimiterFrontmatterSyntax.parse_content_early","title":"parse_content_early","text":"<pre><code>parse_content_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse content section early.</p> <p>Returns raw content dict with the content text.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax","title":"hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax","text":"<p>               Bases: <code>BaseSyntax</code>, <code>YAMLFrontmatterMixin</code></p> <p>This syntax uses Markdown-style fenced code blocks with optional YAML frontmatter for metadata. The info_string after the opening fence can be used as a fallback block_type when no frontmatter is present.</p> Format <p>The info_string is optional. When provided, it's used as the block_type if no YAML frontmatter is present. The YAML frontmatter is also optional - if omitted, all content becomes the block content.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Block with frontmatter\n&gt;&gt;&gt; '''\n... ```python\n... ---\n... id: code001\n... block_type: code\n... language: python\n... ---\n... def hello():\n...     print(\"Hello, world!\")\n... ```\n... '''\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Block without frontmatter (info_string becomes block_type)\n&gt;&gt;&gt; '''\n... ```patch\n... diff --git a/file.py b/file.py\n... - old line\n... + new line\n... ```\n... '''\n&gt;&gt;&gt; # block_type will be \"patch\" from info_string\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Block with nested YAML\n&gt;&gt;&gt; '''\n... ```task\n... ---\n... id: task001\n... block_type: task\n... assignees:\n...   - alice\n...   - bob\n... ---\n... Implement user authentication\n... ```\n... '''\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fence</code> <code>str</code> <p>Fence string (default: \"```\")</p> <code>'```'</code> <code>info_string</code> <code>str | None</code> <p>Optional info string used as fallback block_type</p> <code>None</code>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax--info_string","title":"```[info_string]","text":"<p>id: block_001 block_type: example custom_field: value</p> <p>Content lines here ```</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.fence","title":"fence  <code>instance-attribute</code>","text":"<pre><code>fence = fence\n</code></pre>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.info_string","title":"info_string  <code>instance-attribute</code>","text":"<pre><code>info_string = info_string\n</code></pre>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.parse_metadata_early","title":"parse_metadata_early","text":"<pre><code>parse_metadata_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse metadata section early, before content accumulation.</p> <p>This method is called when the metadata section completes, allowing early validation and processing. The result can be cached in the candidate for reuse during full block parsing.</p> <p>Default implementation returns None (no early parsing). Override in subclasses to provide early metadata parsing.</p> <p>Parameters:</p> Name Type Description Default <code>candidate</code> <code>BlockCandidate</code> <p>The current block candidate with metadata accumulated</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Parsed metadata dict if successful, None if parsing not supported</p> <code>dict[str, Any] | None</code> <p>or failed</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.parse_content_early","title":"parse_content_early","text":"<pre><code>parse_content_early(\n    candidate: BlockCandidate,\n) -&gt; dict[str, Any] | None\n</code></pre> <p>Parse content section early, before final block extraction.</p> <p>This method is called when the content section completes (block closes), allowing early validation. The result can be cached in the candidate for reuse during full block parsing.</p> <p>Default implementation returns None (no early parsing). Override in subclasses to provide early content parsing.</p> <p>Parameters:</p> Name Type Description Default <code>candidate</code> <code>BlockCandidate</code> <p>The complete block candidate with content accumulated</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Parsed content dict if successful, None if parsing not supported</p> <code>dict[str, Any] | None</code> <p>or failed</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.detect_line","title":"detect_line","text":"<pre><code>detect_line(\n    line: str, candidate: BlockCandidate | None = None\n) -&gt; DetectionResult\n</code></pre> <p>Detect markdown fence markers and frontmatter boundaries.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.should_accumulate_metadata","title":"should_accumulate_metadata","text":"<pre><code>should_accumulate_metadata(\n    candidate: BlockCandidate,\n) -&gt; bool\n</code></pre> <p>Check if we're still in metadata section.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.extract_block_type","title":"extract_block_type","text":"<pre><code>extract_block_type(candidate: BlockCandidate) -&gt; str | None\n</code></pre> <p>Extract block_type from YAML frontmatter.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.parse_block","title":"parse_block","text":"<pre><code>parse_block(\n    candidate: BlockCandidate,\n    block_class: type[Any] | None = None,\n) -&gt; ParseResult[BaseMetadata, BaseContent]\n</code></pre> <p>Parse the complete block using the specified block class.</p>"},{"location":"reference/syntaxes/#hother.streamblocks.syntaxes.MarkdownFrontmatterSyntax.validate_block","title":"validate_block","text":"<pre><code>validate_block(\n    _block: ExtractedBlock[BaseMetadata, BaseContent],\n) -&gt; bool\n</code></pre> <p>Additional validation after parsing.</p>"}]}